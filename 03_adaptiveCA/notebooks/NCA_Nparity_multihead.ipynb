{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-04T20:05:44.553143300Z",
     "start_time": "2024-03-04T20:05:44.471142700Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.color import rgba2rgb\n",
    "import cv2\n",
    "from IPython.display import display, clear_output\n",
    "from math import *\n",
    "import time\n",
    "\n",
    "from os import makedirs, path\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# brush properties\n",
    "r = 5\n",
    "s = 1\n",
    "\n",
    "def LMB_make(state, r=5, s=1):\n",
    "    '''\n",
    "    left click to make\n",
    "    r: radius of brush\n",
    "    s: smoothing / sigma\n",
    "    '''\n",
    "    xcl, ycl = pygame.mouse.get_pos()\n",
    "    xcl, ycl = int(xcl/UPSCALE), int(ycl/UPSCALE)\n",
    "\n",
    "    # radial blur\n",
    "    xm, ym = torch.meshgrid(torch.linspace(-1, 1, 2*r), torch.linspace(-1, 1, 2*r))\n",
    "    rm = torch.sqrt(xm**2 + ym**2).type(torch.double)\n",
    "    blur = torch.exp(-rm**2 / s**2)\n",
    "    blur = torch.where(rm <= 1., blur, 0.) # circular mask\n",
    "\n",
    "    xslice = range(xcl - r, xcl + r)\n",
    "    yslice = range(ycl - r, ycl + r)\n",
    "    for count_i, i in enumerate(xslice):\n",
    "        for count_j, j in enumerate(yslice):\n",
    "            i = i % RESX\n",
    "            j = j % RESY\n",
    "            state[:, 1, i, j] = state[:, 1, i, j] + 5.\n",
    "    return state\n",
    "\n",
    "\n",
    "def RMB_del(state, r=5, s=1):\n",
    "    '''\n",
    "    right click to erase\n",
    "    r: radius of eraser\n",
    "    s: smoothing / sigma\n",
    "    '''\n",
    "    xcl, ycl = pygame.mouse.get_pos()\n",
    "    xcl, ycl = int(xcl/UPSCALE), int(ycl/UPSCALE)\n",
    "\n",
    "    # radial blur\n",
    "    xm, ym = torch.meshgrid(torch.linspace(-1, 1, 2*r), torch.linspace(-1, 1, 2*r))\n",
    "    rm = torch.sqrt(xm**2 + ym**2).type(torch.double)\n",
    "    blur = (1 - torch.exp(-rm**2 / s**2))\n",
    "    blur = torch.where(rm <= 1., blur, 1.) # circular mask\n",
    "\n",
    "    xslice = range(xcl - r, xcl + r)\n",
    "    yslice = range(ycl - r, ycl + r)\n",
    "    for count_i, i in enumerate(xslice):\n",
    "        for count_j, j in enumerate(yslice):\n",
    "            i = i % RESX\n",
    "            j = j % RESY\n",
    "            state[:, 1, i, j] = state[:, 1, i, j] - 0.2\n",
    "    return state\n",
    "\n",
    "def print_something(something):\n",
    "    fps = f'{something:.3f}'\n",
    "    fps_text = font.render(fps, 1, pygame.Color(\"white\"))\n",
    "    fps_bg = pygame.Surface((fps_text.get_height(),fps_text.get_width()))  # the size of your rect\n",
    "    fps_bg.set_alpha(50)                # alpha level\n",
    "    fps_bg.fill((255,255,255))           # this fills the entire surface\n",
    "\n",
    "    fps_surf = pygame.Surface((fps_bg.get_height(), fps_bg.get_width()))\n",
    "    fps_surf.blit(fps_bg, (0, 0))\n",
    "    fps_surf.blit(fps_text, (0, 0))\n",
    "    return fps_surf\n",
    "\n",
    "def plot_classification_scores(class_scores, correct_classes, width=100, height=400):\n",
    "    num_samples = class_scores.shape[0]\n",
    "    BAR_WIDTH = width\n",
    "    BAR_HEIGHT = int( 0.8 * height / (4 * num_samples))\n",
    "    BAR_SPACING = BAR_HEIGHT // 2\n",
    "    BAR_Y_OFFSET = int(0.1 * height)\n",
    "\n",
    "    CLASS_SPACING = 3*BAR_HEIGHT\n",
    "\n",
    "    # Create a surface for drawing the graph\n",
    "    graph_surface = pygame.Surface((width, height), pygame.SRCALPHA)\n",
    "    graph_surface.fill((255, 255, 255, 63))  # Fill with transparent color\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        score1 = class_scores[i][0]\n",
    "        score2 = class_scores[i][1]\n",
    "        correct_class = correct_classes[i]\n",
    "\n",
    "        # # Normalize scores to fit in the graph\n",
    "        # score1 = max(min(score1, 1), -1)  # Clamp scores to be within [-1, 1]\n",
    "        # score2 = max(min(score2, 1), -1)\n",
    "\n",
    "        # Draw the bars\n",
    "        predicted = np.argmax([score1, score2])\n",
    "        bar_colors = np.zeros((2, 3))\n",
    "        GREEN = np.array([0, 255, 0])\n",
    "        RED = np.array([255, 0, 0])\n",
    "\n",
    "        if predicted == correct_class:\n",
    "            # Highlight the correct class\n",
    "            bar_colors[predicted] = GREEN\n",
    "        else:\n",
    "            bar_colors[predicted] = RED\n",
    "\n",
    "        # Draw left bar\n",
    "        # rect(left, top, width, height)\n",
    "        bar1_top = i * (2 * BAR_HEIGHT + CLASS_SPACING) + BAR_Y_OFFSET\n",
    "        bar1_width = int(score1 * BAR_WIDTH)\n",
    "        pygame.draw.rect(graph_surface, bar_colors[0], (0, bar1_top, bar1_width, BAR_HEIGHT))\n",
    "\n",
    "        # Draw right bar\n",
    "        # bar2_top = (i + 1) * BAR_HEIGHT + i * CLASS_SPACING + BAR_SPACING + BAR_Y_OFFSET\n",
    "        bar2_top = bar1_top + BAR_HEIGHT + BAR_SPACING\n",
    "        bar2_width = int(score2 * BAR_WIDTH)\n",
    "        pygame.draw.rect(graph_surface, bar_colors[1], (0, bar2_top, bar2_width, BAR_HEIGHT))\n",
    "\n",
    "        # Add text label\n",
    "        text = font.render(f'N={i + 2}', True, (0, 0, 0))\n",
    "        text_rect = text.get_rect(center=(width//2, int(bar1_top-0.5*BAR_Y_OFFSET)))\n",
    "        graph_surface.blit(text, text_rect)\n",
    "\n",
    "    return graph_surface\n",
    "\n",
    "def WHEEL_permute(cdim_order, direction):\n",
    "    cdim_order = np.mod(np.add(cdim_order, direction), len(cdim_order))\n",
    "\n",
    "    return cdim_order\n",
    "\n",
    "def min_max(mat):\n",
    "    return (mat - mat.min()) / (mat.max() - mat.min())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T20:05:44.573143200Z",
     "start_time": "2024-03-04T20:05:44.535142Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "class Rule(nn.Module):\n",
    "    def __init__(self,\n",
    "                 CHANNELS=8,\n",
    "                 FILTERS=1,\n",
    "                 NET_SIZE=[16],\n",
    "                 RES=50,\n",
    "                 READIN_CHANNELS=1,\n",
    "                 READOUT_CHANNELS=1,\n",
    "                 READIN_SCALE=1,\n",
    "                 READOUT_SCALE=1,\n",
    "                 NUM_READOUT_HEADS=10):\n",
    "        super().__init__()\n",
    "        self.channels = CHANNELS\n",
    "        self.filters = FILTERS\n",
    "        self.net_size = NET_SIZE\n",
    "        # self.alpha = torch.nn.Parameter(torch.tensor([0.]))\n",
    "        self.alpha = torch.nn.Parameter(torch.randn(CHANNELS))\n",
    "        \n",
    "        self.res = RES\n",
    "        self.rin_channels = READIN_CHANNELS\n",
    "        self.rout_channels = READOUT_CHANNELS\n",
    "        self.rin_scale = READIN_SCALE\n",
    "        self.rout_scale = READOUT_SCALE\n",
    "        # total\n",
    "        self.readin_res = int(READIN_SCALE*RES)\n",
    "        self.readout_res = int(READOUT_SCALE*RES)\n",
    "\n",
    "        # for forward_perception\n",
    "        self.ident = torch.tensor([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 0.0]]).cuda()\n",
    "        self.sobel_x = torch.tensor([[-1.0, 0.0, 1.0], [-2.0, 0.0, 2.0], [-1.0, 0.0, 1.0]]).cuda() / 8.0\n",
    "        self.lap = torch.tensor([[1.0, 2.0, 1.0], [2.0, -12, 2.0], [1.0, 2.0, 1.0]]).cuda() / 16.0\n",
    "\n",
    "        self.filters = [nn.Parameter(0 * torch.randn(3, 3).cuda())\n",
    "                        for i in range(FILTERS)]\n",
    "        \n",
    "        self.afunc = nn.LeakyReLU()\n",
    "        self.ws = [torch.nn.Conv2d(CHANNELS * (4 + FILTERS), NET_SIZE[0], 1),\n",
    "                   self.afunc]\n",
    "        for i in range(len(NET_SIZE) - 1):\n",
    "            self.ws.append(torch.nn.Conv2d(NET_SIZE[i], NET_SIZE[i + 1], 1))\n",
    "            self.ws.append(self.afunc)\n",
    "        self.ws += [torch.nn.Conv2d(NET_SIZE[-1], CHANNELS, 1)]\n",
    "        self.ws = nn.Sequential(*self.ws)\n",
    "\n",
    "\n",
    "        # self.w1 = torch.nn.Conv2d(CHANNELS * (4 + FILTERS), HIDDEN, 1)\n",
    "        # self.w1.bias.data.zero_()\n",
    "        # self.w2 = torch.nn.Conv2d(HIDDEN, HIDDEN, 1)\n",
    "        # self.w3 = torch.nn.Conv2d(HIDDEN, CHANNELS, 1)\n",
    "\n",
    "        # read in layer is used to project from 1D -> CA grid via 3 input channels\n",
    "        # readout layer is used to project from CA grid via 3 output channels -> num_classes (2)\n",
    "        \n",
    "        self.readin = torch.nn.Linear(1, int(self.readin_res*self.readin_res*READIN_CHANNELS))\n",
    "        self.readouts = nn.ModuleList([torch.nn.Linear(int(self.readout_res*self.readout_res*READOUT_CHANNELS), 2, bias=True).cuda() for i in range(NUM_READOUT_HEADS)])\n",
    "\n",
    "        # self.module_list = torch.nn.ModuleList(self.ws + self.readouts)\n",
    "        # self.module_dict = nn.ModuleDict({''})\n",
    "        self.parameter_list = torch.nn.ParameterList(self.filters)\n",
    "        # self.w2.weight.data.zero_()\n",
    "        ###########################################\n",
    "\n",
    "class CA(nn.Module):\n",
    "    def __init__(self,\n",
    "                 CHANNELS=8,\n",
    "                 FILTERS=1,\n",
    "                 NET_SIZE=[16],\n",
    "                 RES=50,\n",
    "                 READIN_CHANNELS=1,\n",
    "                 READOUT_CHANNELS=1,\n",
    "                 READIN_SCALE=1,\n",
    "                 READOUT_SCALE=1,\n",
    "                 NUM_READOUT_HEADS=10):\n",
    "        super().__init__()\n",
    "        self.channels = CHANNELS\n",
    "        self.filters = FILTERS\n",
    "        self.net_size = NET_SIZE\n",
    "        self.res = RES\n",
    "        \n",
    "        self.rule = Rule(\n",
    "            CHANNELS=CHANNELS,\n",
    "            FILTERS=FILTERS,\n",
    "            NET_SIZE=NET_SIZE,\n",
    "            RES=RES,\n",
    "            READIN_CHANNELS=READIN_CHANNELS,\n",
    "            READOUT_CHANNELS=READOUT_CHANNELS,\n",
    "            READIN_SCALE=READIN_SCALE,\n",
    "            READOUT_SCALE=READOUT_SCALE,\n",
    "            NUM_READOUT_HEADS=NUM_READOUT_HEADS,\n",
    "        )\n",
    "\n",
    "    def initGrid(self, BS):\n",
    "        grid = torch.cuda.FloatTensor(2 * np.random.rand(BS, self.channels, self.res, self.res) - 1)\n",
    "        # first channel is input channel\n",
    "        # grid[:, -1, ...] *= 0.\n",
    "        return grid * 0.\n",
    "\n",
    "    def seed(self, RES, n):\n",
    "        seed = torch.randn(n, self.channels, RES, RES)\n",
    "        return seed\n",
    "\n",
    "    def perchannel_conv(self, x, filters):\n",
    "        '''filters: [filter_n, h, w]'''\n",
    "        b, ch, h, w = x.shape\n",
    "        y = x.reshape(b * ch, 1, h, w)\n",
    "        y = torch.nn.functional.pad(y, [1, 1, 1, 1], 'circular')\n",
    "        y = torch.nn.functional.conv2d(y, filters[:, None])\n",
    "        return y.reshape(b, -1, h, w)\n",
    "\n",
    "    def perception(self, x):\n",
    "        filters = [self.rule.ident, self.rule.sobel_x, self.rule.sobel_x.T, self.rule.lap]\n",
    "        filters = filters + self.rule.filters\n",
    "        return self.perchannel_conv(x, torch.stack(filters))\n",
    "\n",
    "    def get_living_mask(self, x, alive_thres=0):\n",
    "        alpha_channel = x[:, 0:1, :, :]\n",
    "        R = 1\n",
    "        d = 2*R+1\n",
    "        alpha_channel = F.pad(alpha_channel, (R, R, R, R), mode='circular')\n",
    "\n",
    "        alive_mask = F.max_pool2d(alpha_channel, kernel_size=d, stride=1, padding=R).abs() > alive_thres\n",
    "        alive_mask = alive_mask[:, :, R:-R, R:-R]\n",
    "\n",
    "        return alive_mask\n",
    "\n",
    "    def forward(self, x, dt=1, update_rate=1.):\n",
    "        b, ch, h, w = x.shape\n",
    "        pre_mask = self.get_living_mask(x)\n",
    "        y = self.perception(x)\n",
    "        y = self.rule.ws(y)\n",
    "        # for layer_i in self.rule.ws[:-1]:\n",
    "        #     y = F.leaky_relu(layer_i(y))\n",
    "        #     # y = F.tanh(layer_i(y))\n",
    "        # y = self.rule.ws[-1](y)\n",
    "        # y = self.rule.w3(y)\n",
    "\n",
    "\n",
    "        update_mask = (torch.rand(b, 1, h, w) + update_rate).floor().cuda()\n",
    "        y = dt * y * update_mask\n",
    "        y = y * pre_mask\n",
    "        \n",
    "        # y = dt * y\n",
    "        # keep the first channel empty for inputs\n",
    "        # y[:, -1, ...] *= 0.\n",
    "        # res = torch.clamp(x + y, 0, 1)\n",
    "        alpha = torch.sigmoid(self.rule.alpha).reshape(1, -1, 1, 1)\n",
    "        res = (1 - alpha) * x + alpha * y\n",
    "        post_mask = self.get_living_mask(res)\n",
    "        res = res*post_mask\n",
    "        # res = F.leaky_relu(x + y)\n",
    "        return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T20:05:44.607143600Z",
     "start_time": "2024-03-04T20:05:44.574143300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's train the model now in the N-Parity task. We will project the 1-D timeseries in 3 of the 8 channel dimensions of all the cells in the grid (size=1 x RESxRESx3). We will then read out from 3 different channels from the entire grid to get a classification (size=RESxRESx3 x 1)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "def generate_binary_sequence(M):\n",
    "    return (torch.rand(M) < 0.5) * 2. - 1.\n",
    "\n",
    "def make_batch_Nbit_pair_parity(Ns, M, bs):\n",
    "    with torch.no_grad():\n",
    "        sequences = [generate_binary_sequence(M).unsqueeze(-1) for i in range(bs)]\n",
    "        labels = [torch.stack([get_parity(s, N, DELAY_TIME) for s in sequences]) for N in Ns]\n",
    "\n",
    "    return torch.stack(sequences), labels\n",
    "\n",
    "def get_parity(vec, N, delta_t=0):\n",
    "    # delta_t is a \"thinking time\", so if delta_t=2, then we calculate the parity with a 2 time_step shift\n",
    "    start_time = len(vec) - N - delta_t\n",
    "    end_time = start_time + N\n",
    "    return  (((vec + 1)/2)[start_time:end_time].sum() % 2).long()\n",
    "\n",
    "def pad_to(mat, shape_to):\n",
    "    shape = mat.shape\n",
    "    # shape diff\n",
    "    shd = [shape_to[0]-shape[2], shape_to[1]-shape[3]]\n",
    "\n",
    "    pad = [shd[0]//2, shd[0] - shd[0]//2, shd[1]//2, shd[1] - shd[1]//2]\n",
    "    return F.pad(mat, pad, mode='constant')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T20:05:44.630143500Z",
     "start_time": "2024-03-04T20:05:44.601150900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T20:05:44.681143400Z",
     "start_time": "2024-03-04T20:05:44.612143500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "CHANNELS=9\n",
    "FILTERS=0\n",
    "NET_SIZE=[16]\n",
    "NUM_READOUT_HEADS=100\n",
    "\n",
    "READIN_CHANNELS = 1\n",
    "READIN_SCALE = 0.5\n",
    "READOUT_CHANNELS = 3\n",
    "READOUT_SCALE = 0.25\n",
    "\n",
    "DELAY_TIME = 0\n",
    "\n",
    "RES = 12\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "device = 'cuda'\n",
    "ca = CA(CHANNELS=CHANNELS,\n",
    "        FILTERS=FILTERS,\n",
    "        NET_SIZE=NET_SIZE,\n",
    "        RES=RES,\n",
    "        READIN_CHANNELS=READIN_CHANNELS,\n",
    "        READOUT_CHANNELS=READOUT_CHANNELS,\n",
    "        READIN_SCALE=READIN_SCALE,\n",
    "        READOUT_SCALE=READOUT_SCALE,\n",
    "        NUM_READOUT_HEADS=NUM_READOUT_HEADS,\n",
    "        ).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T20:05:44.683143200Z",
     "start_time": "2024-03-04T20:05:44.631143100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule.alpha               9\n",
      "rule.ws.0.weight       576\n",
      "rule.ws.0.bias          16\n",
      "rule.ws.2.weight       144\n",
      "rule.ws.2.bias           9\n",
      "rule.readin.weight      36\n",
      "rule.readin.bias        36\n",
      "rule.readouts.0.weight    54\n",
      "rule.readouts.0.bias     2\n",
      "rule.readouts.1.weight    54\n",
      "rule.readouts.1.bias     2\n",
      "rule.readouts.2.weight    54\n",
      "rule.readouts.2.bias     2\n",
      "rule.readouts.3.weight    54\n",
      "rule.readouts.3.bias     2\n",
      "rule.readouts.4.weight    54\n",
      "rule.readouts.4.bias     2\n",
      "rule.readouts.5.weight    54\n",
      "rule.readouts.5.bias     2\n",
      "rule.readouts.6.weight    54\n",
      "rule.readouts.6.bias     2\n",
      "rule.readouts.7.weight    54\n",
      "rule.readouts.7.bias     2\n",
      "rule.readouts.8.weight    54\n",
      "rule.readouts.8.bias     2\n",
      "rule.readouts.9.weight    54\n",
      "rule.readouts.9.bias     2\n",
      "rule.readouts.10.weight    54\n",
      "rule.readouts.10.bias     2\n",
      "rule.readouts.11.weight    54\n",
      "rule.readouts.11.bias     2\n",
      "rule.readouts.12.weight    54\n",
      "rule.readouts.12.bias     2\n",
      "rule.readouts.13.weight    54\n",
      "rule.readouts.13.bias     2\n",
      "rule.readouts.14.weight    54\n",
      "rule.readouts.14.bias     2\n",
      "rule.readouts.15.weight    54\n",
      "rule.readouts.15.bias     2\n",
      "rule.readouts.16.weight    54\n",
      "rule.readouts.16.bias     2\n",
      "rule.readouts.17.weight    54\n",
      "rule.readouts.17.bias     2\n",
      "rule.readouts.18.weight    54\n",
      "rule.readouts.18.bias     2\n",
      "rule.readouts.19.weight    54\n",
      "rule.readouts.19.bias     2\n",
      "rule.readouts.20.weight    54\n",
      "rule.readouts.20.bias     2\n",
      "rule.readouts.21.weight    54\n",
      "rule.readouts.21.bias     2\n",
      "rule.readouts.22.weight    54\n",
      "rule.readouts.22.bias     2\n",
      "rule.readouts.23.weight    54\n",
      "rule.readouts.23.bias     2\n",
      "rule.readouts.24.weight    54\n",
      "rule.readouts.24.bias     2\n",
      "rule.readouts.25.weight    54\n",
      "rule.readouts.25.bias     2\n",
      "rule.readouts.26.weight    54\n",
      "rule.readouts.26.bias     2\n",
      "rule.readouts.27.weight    54\n",
      "rule.readouts.27.bias     2\n",
      "rule.readouts.28.weight    54\n",
      "rule.readouts.28.bias     2\n",
      "rule.readouts.29.weight    54\n",
      "rule.readouts.29.bias     2\n",
      "rule.readouts.30.weight    54\n",
      "rule.readouts.30.bias     2\n",
      "rule.readouts.31.weight    54\n",
      "rule.readouts.31.bias     2\n",
      "rule.readouts.32.weight    54\n",
      "rule.readouts.32.bias     2\n",
      "rule.readouts.33.weight    54\n",
      "rule.readouts.33.bias     2\n",
      "rule.readouts.34.weight    54\n",
      "rule.readouts.34.bias     2\n",
      "rule.readouts.35.weight    54\n",
      "rule.readouts.35.bias     2\n",
      "rule.readouts.36.weight    54\n",
      "rule.readouts.36.bias     2\n",
      "rule.readouts.37.weight    54\n",
      "rule.readouts.37.bias     2\n",
      "rule.readouts.38.weight    54\n",
      "rule.readouts.38.bias     2\n",
      "rule.readouts.39.weight    54\n",
      "rule.readouts.39.bias     2\n",
      "rule.readouts.40.weight    54\n",
      "rule.readouts.40.bias     2\n",
      "rule.readouts.41.weight    54\n",
      "rule.readouts.41.bias     2\n",
      "rule.readouts.42.weight    54\n",
      "rule.readouts.42.bias     2\n",
      "rule.readouts.43.weight    54\n",
      "rule.readouts.43.bias     2\n",
      "rule.readouts.44.weight    54\n",
      "rule.readouts.44.bias     2\n",
      "rule.readouts.45.weight    54\n",
      "rule.readouts.45.bias     2\n",
      "rule.readouts.46.weight    54\n",
      "rule.readouts.46.bias     2\n",
      "rule.readouts.47.weight    54\n",
      "rule.readouts.47.bias     2\n",
      "rule.readouts.48.weight    54\n",
      "rule.readouts.48.bias     2\n",
      "rule.readouts.49.weight    54\n",
      "rule.readouts.49.bias     2\n",
      "rule.readouts.50.weight    54\n",
      "rule.readouts.50.bias     2\n",
      "rule.readouts.51.weight    54\n",
      "rule.readouts.51.bias     2\n",
      "rule.readouts.52.weight    54\n",
      "rule.readouts.52.bias     2\n",
      "rule.readouts.53.weight    54\n",
      "rule.readouts.53.bias     2\n",
      "rule.readouts.54.weight    54\n",
      "rule.readouts.54.bias     2\n",
      "rule.readouts.55.weight    54\n",
      "rule.readouts.55.bias     2\n",
      "rule.readouts.56.weight    54\n",
      "rule.readouts.56.bias     2\n",
      "rule.readouts.57.weight    54\n",
      "rule.readouts.57.bias     2\n",
      "rule.readouts.58.weight    54\n",
      "rule.readouts.58.bias     2\n",
      "rule.readouts.59.weight    54\n",
      "rule.readouts.59.bias     2\n",
      "rule.readouts.60.weight    54\n",
      "rule.readouts.60.bias     2\n",
      "rule.readouts.61.weight    54\n",
      "rule.readouts.61.bias     2\n",
      "rule.readouts.62.weight    54\n",
      "rule.readouts.62.bias     2\n",
      "rule.readouts.63.weight    54\n",
      "rule.readouts.63.bias     2\n",
      "rule.readouts.64.weight    54\n",
      "rule.readouts.64.bias     2\n",
      "rule.readouts.65.weight    54\n",
      "rule.readouts.65.bias     2\n",
      "rule.readouts.66.weight    54\n",
      "rule.readouts.66.bias     2\n",
      "rule.readouts.67.weight    54\n",
      "rule.readouts.67.bias     2\n",
      "rule.readouts.68.weight    54\n",
      "rule.readouts.68.bias     2\n",
      "rule.readouts.69.weight    54\n",
      "rule.readouts.69.bias     2\n",
      "rule.readouts.70.weight    54\n",
      "rule.readouts.70.bias     2\n",
      "rule.readouts.71.weight    54\n",
      "rule.readouts.71.bias     2\n",
      "rule.readouts.72.weight    54\n",
      "rule.readouts.72.bias     2\n",
      "rule.readouts.73.weight    54\n",
      "rule.readouts.73.bias     2\n",
      "rule.readouts.74.weight    54\n",
      "rule.readouts.74.bias     2\n",
      "rule.readouts.75.weight    54\n",
      "rule.readouts.75.bias     2\n",
      "rule.readouts.76.weight    54\n",
      "rule.readouts.76.bias     2\n",
      "rule.readouts.77.weight    54\n",
      "rule.readouts.77.bias     2\n",
      "rule.readouts.78.weight    54\n",
      "rule.readouts.78.bias     2\n",
      "rule.readouts.79.weight    54\n",
      "rule.readouts.79.bias     2\n",
      "rule.readouts.80.weight    54\n",
      "rule.readouts.80.bias     2\n",
      "rule.readouts.81.weight    54\n",
      "rule.readouts.81.bias     2\n",
      "rule.readouts.82.weight    54\n",
      "rule.readouts.82.bias     2\n",
      "rule.readouts.83.weight    54\n",
      "rule.readouts.83.bias     2\n",
      "rule.readouts.84.weight    54\n",
      "rule.readouts.84.bias     2\n",
      "rule.readouts.85.weight    54\n",
      "rule.readouts.85.bias     2\n",
      "rule.readouts.86.weight    54\n",
      "rule.readouts.86.bias     2\n",
      "rule.readouts.87.weight    54\n",
      "rule.readouts.87.bias     2\n",
      "rule.readouts.88.weight    54\n",
      "rule.readouts.88.bias     2\n",
      "rule.readouts.89.weight    54\n",
      "rule.readouts.89.bias     2\n",
      "rule.readouts.90.weight    54\n",
      "rule.readouts.90.bias     2\n",
      "rule.readouts.91.weight    54\n",
      "rule.readouts.91.bias     2\n",
      "rule.readouts.92.weight    54\n",
      "rule.readouts.92.bias     2\n",
      "rule.readouts.93.weight    54\n",
      "rule.readouts.93.bias     2\n",
      "rule.readouts.94.weight    54\n",
      "rule.readouts.94.bias     2\n",
      "rule.readouts.95.weight    54\n",
      "rule.readouts.95.bias     2\n",
      "rule.readouts.96.weight    54\n",
      "rule.readouts.96.bias     2\n",
      "rule.readouts.97.weight    54\n",
      "rule.readouts.97.bias     2\n",
      "rule.readouts.98.weight    54\n",
      "rule.readouts.98.bias     2\n",
      "rule.readouts.99.weight    54\n",
      "rule.readouts.99.bias     2\n",
      "# CA parameters:       826\n",
      "# readout parameters:  5600\n",
      "# total parameters:   6426\n"
     ]
    }
   ],
   "source": [
    "model_numel = 0\n",
    "rout_numel = 0\n",
    "for n, p in ca.named_parameters():\n",
    "    print(f'{n:<20} {p.numel():>5}')\n",
    "    if 'readouts' in n:\n",
    "        rout_numel += p.numel()\n",
    "    else:\n",
    "        model_numel += p.numel()\n",
    "\n",
    "print(f'{\"# CA parameters:\":<20} {model_numel:>5}')\n",
    "print(f'{\"# readout parameters:\":<20} {rout_numel:>5}')\n",
    "print(f'{\"# total parameters:\":<20} {model_numel + rout_numel:>5}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T20:05:44.699150200Z",
     "start_time": "2024-03-04T20:05:44.679141900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "def forward_pass(ca, sequences, num_readouts=1):\n",
    "    ridx = np.random.choice(POOL.shape[0], BATCH_SIZE)\n",
    "    state = POOL[ridx, ...].cuda()\n",
    "\n",
    "    # for t in range(warmup_time):\n",
    "    #     readin_patch = ca.rule.readin(torch.zeros(BATCH_SIZE, 1, 1).cuda()).reshape(BATCH_SIZE, READIN_CHANNELS, int(READIN_SCALE*RES), int(READIN_SCALE*RES))\n",
    "    #     readin_patch = pad_to(readin_patch, (RES, RES))\n",
    "    #     state[:, -READIN_CHANNELS:, ...] = state[:, -READIN_CHANNELS:, ...] + readin_patch\n",
    "    #     state = ca(state)\n",
    "\n",
    "    readin_res = int(READIN_SCALE*RES)\n",
    "    for t in range(timesteps):\n",
    "        readin_patch = ca.rule.readin(sequences[:, [t], 0]).reshape(BATCH_SIZE, READIN_CHANNELS, readin_res, readin_res)\n",
    "        readin_patch = pad_to(readin_patch, (RES, RES))\n",
    "\n",
    "        # readin_mask = pad_to(-torch.ones(1, READIN_CHANNELS, readin_res//2, readin_res//2), (RES, RES)).cuda() + 1\n",
    "        # readin_mask = pad_to(-torch.ones(1, READIN_CHANNELS, int(readin_res//1.2), int(readin_res//1.2)), (RES, RES)).cuda() + 1\n",
    "        # readin_patch = readin_patch * readin_mask\n",
    "        \n",
    "        state[:, -READIN_CHANNELS:, ...] = state[:, -READIN_CHANNELS:, ...] + readin_patch\n",
    "        state = ca(state)\n",
    "\n",
    "    if np.random.rand() > 0.5:\n",
    "        POOL[ridx] = state.detach().cpu()\n",
    "    else:\n",
    "        POOL[ridx] = ca.seed(RES, BATCH_SIZE)\n",
    "\n",
    "    readout_len = ca.rule.readout_res\n",
    "    l_edge = RES//2 - int(readout_len/2)\n",
    "    r_edge = l_edge + readout_len\n",
    "    t_edge = RES//2 - int(readout_len/2)\n",
    "    b_edge = t_edge + readout_len\n",
    "    readout_patch = state[\n",
    "                    :,\n",
    "                    :READOUT_CHANNELS,\n",
    "                    l_edge : r_edge,\n",
    "                    t_edge : b_edge,\n",
    "                    ]\n",
    "\n",
    "    # readout_mask_res = readin_res * 2\n",
    "    # mask = torch.ones((1, 1, RES, RES)).cuda() - pad_to(torch.ones((1, 1, readout_mask_res, readout_mask_res)).cuda(), (RES, RES))\n",
    "    # readout_patch = (readout_patch * mask).reshape(BATCH_SIZE, -1)\n",
    "    readout_patch = (readout_patch).reshape(BATCH_SIZE, -1)\n",
    "    # readout_patch = F.max_pool2d(readout_patch, 2).reshape(BATCH_SIZE, -1)\n",
    "    # print(f'patch_size: {readout_patch.shape}, weight_size: {ca.rule.readouts[0].weight.shape}')\n",
    "    outs = [l_r(readout_patch) for l_r in ca.rule.readouts[:num_readouts]]\n",
    "\n",
    "\n",
    "    return outs\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T20:05:44.733142900Z",
     "start_time": "2024-03-04T20:05:44.696144400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, Step: 25/250, Loss: 3.5223, Accuracy: 47.79\n",
      "(N, accuracy, loss):\n",
      "(2, 52.3438, 0.6891)\n",
      "(3, 55.4688, 0.6906)\n",
      "(4, 46.8750, 0.6948)\n",
      "(5, 43.7500, 0.6944)\n",
      "(6, 38.2812, 0.6993)\n",
      "(7, 50.0000, 0.6934)\n",
      "Epoch: 1/20, Step: 50/250, Loss: 2.8398, Accuracy: 62.11\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0447)\n",
      "(3, 67.1875, 0.6256)\n",
      "(4, 57.8125, 0.6881)\n",
      "(5, 51.5625, 0.6815)\n",
      "(6, 42.9688, 0.6923)\n",
      "(7, 53.1250, 0.6871)\n",
      "Epoch: 1/20, Step: 75/250, Loss: 1.5582, Accuracy: 77.86\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0072)\n",
      "(3, 98.4375, 0.0287)\n",
      "(4, 96.8750, 0.1433)\n",
      "(5, 71.8750, 0.6087)\n",
      "(6, 49.2188, 0.7141)\n",
      "(7, 50.7812, 0.6957)\n",
      "Epoch: 1/20, Step: 100/250, Loss: 0.4987, Accuracy: 92.71\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0060)\n",
      "(3, 100.0000, 0.0151)\n",
      "(4, 100.0000, 0.0112)\n",
      "(5, 99.2188, 0.0557)\n",
      "(6, 93.7500, 0.2503)\n",
      "(7, 63.2812, 0.6280)\n",
      "Epoch: 1/20, Step: 125/250, Loss: 0.1984, Accuracy: 97.14\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0022)\n",
      "(3, 100.0000, 0.0071)\n",
      "(4, 100.0000, 0.0118)\n",
      "(5, 100.0000, 0.0294)\n",
      "(6, 98.4375, 0.0645)\n",
      "(7, 84.3750, 0.5031)\n",
      "Solved N = 6, starting N = 7 + 1\n",
      "Epoch: 1/20, Step: 150/250, Loss: 0.3416, Accuracy: 95.31\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0035)\n",
      "(3, 100.0000, 0.0097)\n",
      "(4, 100.0000, 0.0133)\n",
      "(5, 100.0000, 0.0297)\n",
      "(6, 99.2188, 0.0378)\n",
      "(7, 96.0938, 0.1365)\n",
      "(8, 71.8750, 0.5772)\n",
      "Epoch: 1/20, Step: 175/250, Loss: 0.1663, Accuracy: 96.88\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0025)\n",
      "(3, 100.0000, 0.0040)\n",
      "(4, 100.0000, 0.0163)\n",
      "(5, 99.2188, 0.0189)\n",
      "(6, 100.0000, 0.0265)\n",
      "(7, 100.0000, 0.0477)\n",
      "(8, 78.9062, 0.5169)\n",
      "Solved N = 7, starting N = 8 + 1\n",
      "Epoch: 1/20, Step: 200/250, Loss: 0.3252, Accuracy: 95.41\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0029)\n",
      "(3, 100.0000, 0.0061)\n",
      "(4, 100.0000, 0.0102)\n",
      "(5, 100.0000, 0.0143)\n",
      "(6, 100.0000, 0.0201)\n",
      "(7, 100.0000, 0.0299)\n",
      "(8, 88.2812, 0.2303)\n",
      "(9, 75.0000, 0.5335)\n",
      "Epoch: 1/20, Step: 225/250, Loss: 0.1902, Accuracy: 97.95\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0037)\n",
      "(3, 100.0000, 0.0080)\n",
      "(4, 100.0000, 0.0051)\n",
      "(5, 100.0000, 0.0093)\n",
      "(6, 99.2188, 0.0227)\n",
      "(7, 99.2188, 0.0480)\n",
      "(8, 99.2188, 0.0595)\n",
      "(9, 85.9375, 0.3486)\n",
      "Solved N = 8, starting N = 9 + 1\n",
      "Epoch: 1/20, Step: 250/250, Loss: 0.3455, Accuracy: 95.31\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0062)\n",
      "(3, 100.0000, 0.0050)\n",
      "(4, 100.0000, 0.0093)\n",
      "(5, 100.0000, 0.0132)\n",
      "(6, 100.0000, 0.0276)\n",
      "(7, 98.4375, 0.0479)\n",
      "(8, 94.5312, 0.1060)\n",
      "(9, 96.8750, 0.0837)\n",
      "(10, 67.9688, 0.6158)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:35<11:05, 35.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/20, Step: 25/250, Loss: 0.2124, Accuracy: 96.79\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0022)\n",
      "(3, 100.0000, 0.0037)\n",
      "(4, 100.0000, 0.0078)\n",
      "(5, 100.0000, 0.0086)\n",
      "(6, 100.0000, 0.0059)\n",
      "(7, 100.0000, 0.0095)\n",
      "(8, 99.2188, 0.0226)\n",
      "(9, 100.0000, 0.0128)\n",
      "(10, 71.8750, 0.5429)\n",
      "Solved N = 9, starting N = 10 + 1\n",
      "Epoch: 2/20, Step: 50/250, Loss: 0.2971, Accuracy: 97.19\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0044)\n",
      "(3, 100.0000, 0.0048)\n",
      "(4, 100.0000, 0.0087)\n",
      "(5, 100.0000, 0.0111)\n",
      "(6, 100.0000, 0.0076)\n",
      "(7, 100.0000, 0.0115)\n",
      "(8, 100.0000, 0.0258)\n",
      "(9, 100.0000, 0.0231)\n",
      "(10, 92.1875, 0.1890)\n",
      "(11, 79.6875, 0.4156)\n",
      "Epoch: 2/20, Step: 75/250, Loss: 0.2113, Accuracy: 98.59\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0059)\n",
      "(3, 100.0000, 0.0042)\n",
      "(4, 100.0000, 0.0051)\n",
      "(5, 100.0000, 0.0071)\n",
      "(6, 100.0000, 0.0120)\n",
      "(7, 100.0000, 0.0095)\n",
      "(8, 100.0000, 0.0112)\n",
      "(9, 100.0000, 0.0124)\n",
      "(10, 97.6562, 0.0697)\n",
      "(11, 88.2812, 0.3410)\n",
      "Epoch: 2/20, Step: 100/250, Loss: 0.1076, Accuracy: 99.30\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0027)\n",
      "(3, 100.0000, 0.0028)\n",
      "(4, 100.0000, 0.0030)\n",
      "(5, 100.0000, 0.0068)\n",
      "(6, 100.0000, 0.0107)\n",
      "(7, 100.0000, 0.0111)\n",
      "(8, 100.0000, 0.0126)\n",
      "(9, 100.0000, 0.0133)\n",
      "(10, 99.2188, 0.0338)\n",
      "(11, 93.7500, 0.2546)\n",
      "Solved N = 10, starting N = 11 + 1\n",
      "Epoch: 2/20, Step: 125/250, Loss: 0.2361, Accuracy: 97.66\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0044)\n",
      "(3, 100.0000, 0.0057)\n",
      "(4, 100.0000, 0.0034)\n",
      "(5, 100.0000, 0.0089)\n",
      "(6, 100.0000, 0.0085)\n",
      "(7, 100.0000, 0.0103)\n",
      "(8, 100.0000, 0.0158)\n",
      "(9, 99.2188, 0.0229)\n",
      "(10, 100.0000, 0.0261)\n",
      "(11, 99.2188, 0.0441)\n",
      "(12, 75.7812, 0.4911)\n",
      "Solved N = 11, starting N = 12 + 1\n",
      "Epoch: 2/20, Step: 150/250, Loss: 0.3824, Accuracy: 97.98\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0049)\n",
      "(3, 100.0000, 0.0071)\n",
      "(4, 100.0000, 0.0050)\n",
      "(5, 100.0000, 0.0145)\n",
      "(6, 100.0000, 0.0094)\n",
      "(7, 100.0000, 0.0112)\n",
      "(8, 100.0000, 0.0127)\n",
      "(9, 100.0000, 0.0192)\n",
      "(10, 99.2188, 0.0397)\n",
      "(11, 98.4375, 0.0688)\n",
      "(12, 96.0938, 0.1422)\n",
      "(13, 82.0312, 0.4441)\n",
      "Epoch: 2/20, Step: 175/250, Loss: 0.2618, Accuracy: 98.76\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0080)\n",
      "(3, 100.0000, 0.0067)\n",
      "(4, 100.0000, 0.0062)\n",
      "(5, 100.0000, 0.0091)\n",
      "(6, 100.0000, 0.0101)\n",
      "(7, 100.0000, 0.0080)\n",
      "(8, 100.0000, 0.0093)\n",
      "(9, 100.0000, 0.0165)\n",
      "(10, 99.2188, 0.0208)\n",
      "(11, 100.0000, 0.0316)\n",
      "(12, 98.4375, 0.0446)\n",
      "(13, 87.5000, 0.3229)\n",
      "Solved N = 12, starting N = 13 + 1\n",
      "Epoch: 2/20, Step: 200/250, Loss: 0.3867, Accuracy: 96.94\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0105)\n",
      "(3, 100.0000, 0.0066)\n",
      "(4, 100.0000, 0.0059)\n",
      "(5, 100.0000, 0.0089)\n",
      "(6, 100.0000, 0.0122)\n",
      "(7, 100.0000, 0.0131)\n",
      "(8, 100.0000, 0.0201)\n",
      "(9, 99.2188, 0.0296)\n",
      "(10, 100.0000, 0.0116)\n",
      "(11, 98.4375, 0.0535)\n",
      "(12, 97.6562, 0.0738)\n",
      "(13, 96.0938, 0.1125)\n",
      "(14, 68.7500, 0.5853)\n",
      "Epoch: 2/20, Step: 225/250, Loss: 0.3187, Accuracy: 97.66\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0077)\n",
      "(3, 100.0000, 0.0069)\n",
      "(4, 100.0000, 0.0047)\n",
      "(5, 100.0000, 0.0078)\n",
      "(6, 100.0000, 0.0122)\n",
      "(7, 100.0000, 0.0061)\n",
      "(8, 100.0000, 0.0120)\n",
      "(9, 100.0000, 0.0157)\n",
      "(10, 100.0000, 0.0176)\n",
      "(11, 99.2188, 0.0484)\n",
      "(12, 99.2188, 0.0401)\n",
      "(13, 100.0000, 0.0301)\n",
      "(14, 71.0938, 0.5697)\n",
      "Solved N = 13, starting N = 14 + 1\n",
      "Epoch: 2/20, Step: 250/250, Loss: 0.5668, Accuracy: 96.21\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0169)\n",
      "(3, 100.0000, 0.0119)\n",
      "(4, 100.0000, 0.0115)\n",
      "(5, 100.0000, 0.0142)\n",
      "(6, 100.0000, 0.0240)\n",
      "(7, 100.0000, 0.0148)\n",
      "(8, 100.0000, 0.0143)\n",
      "(9, 100.0000, 0.0259)\n",
      "(10, 100.0000, 0.0360)\n",
      "(11, 100.0000, 0.0364)\n",
      "(12, 100.0000, 0.0281)\n",
      "(13, 100.0000, 0.0376)\n",
      "(14, 94.5312, 0.1748)\n",
      "(15, 52.3438, 0.7307)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:26<13:29, 44.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/20, Step: 25/250, Loss: 0.4582, Accuracy: 97.32\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0143)\n",
      "(3, 100.0000, 0.0090)\n",
      "(4, 100.0000, 0.0101)\n",
      "(5, 100.0000, 0.0102)\n",
      "(6, 100.0000, 0.0144)\n",
      "(7, 100.0000, 0.0123)\n",
      "(8, 100.0000, 0.0127)\n",
      "(9, 100.0000, 0.0208)\n",
      "(10, 100.0000, 0.0374)\n",
      "(11, 98.4375, 0.0518)\n",
      "(12, 100.0000, 0.0285)\n",
      "(13, 100.0000, 0.0247)\n",
      "(14, 94.5312, 0.1663)\n",
      "(15, 69.5312, 0.5852)\n",
      "Epoch: 3/20, Step: 50/250, Loss: 0.3369, Accuracy: 98.05\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0063)\n",
      "(3, 100.0000, 0.0044)\n",
      "(4, 100.0000, 0.0049)\n",
      "(5, 100.0000, 0.0096)\n",
      "(6, 100.0000, 0.0092)\n",
      "(7, 100.0000, 0.0068)\n",
      "(8, 100.0000, 0.0121)\n",
      "(9, 100.0000, 0.0107)\n",
      "(10, 100.0000, 0.0164)\n",
      "(11, 100.0000, 0.0250)\n",
      "(12, 100.0000, 0.0171)\n",
      "(13, 100.0000, 0.0173)\n",
      "(14, 97.6562, 0.0934)\n",
      "(15, 75.0000, 0.5579)\n",
      "Epoch: 3/20, Step: 75/250, Loss: 0.3303, Accuracy: 97.77\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0178)\n",
      "(3, 100.0000, 0.0096)\n",
      "(4, 100.0000, 0.0066)\n",
      "(5, 100.0000, 0.0097)\n",
      "(6, 100.0000, 0.0085)\n",
      "(7, 100.0000, 0.0119)\n",
      "(8, 100.0000, 0.0112)\n",
      "(9, 99.2188, 0.0346)\n",
      "(10, 100.0000, 0.0206)\n",
      "(11, 100.0000, 0.0291)\n",
      "(12, 100.0000, 0.0109)\n",
      "(13, 100.0000, 0.0192)\n",
      "(14, 98.4375, 0.0984)\n",
      "(15, 71.0938, 0.5629)\n",
      "Solved N = 14, starting N = 15 + 1\n",
      "Epoch: 3/20, Step: 100/250, Loss: 0.7537, Accuracy: 96.82\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0173)\n",
      "(3, 100.0000, 0.0113)\n",
      "(4, 100.0000, 0.0082)\n",
      "(5, 100.0000, 0.0124)\n",
      "(6, 100.0000, 0.0132)\n",
      "(7, 100.0000, 0.0131)\n",
      "(8, 100.0000, 0.0182)\n",
      "(9, 100.0000, 0.0156)\n",
      "(10, 100.0000, 0.0231)\n",
      "(11, 100.0000, 0.0472)\n",
      "(12, 100.0000, 0.0328)\n",
      "(13, 98.4375, 0.0471)\n",
      "(14, 99.2188, 0.0740)\n",
      "(15, 92.9688, 0.2688)\n",
      "(16, 61.7187, 0.7441)\n",
      "Epoch: 3/20, Step: 125/250, Loss: 0.6579, Accuracy: 97.29\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0140)\n",
      "(3, 100.0000, 0.0160)\n",
      "(4, 100.0000, 0.0079)\n",
      "(5, 100.0000, 0.0148)\n",
      "(6, 100.0000, 0.0109)\n",
      "(7, 100.0000, 0.0092)\n",
      "(8, 100.0000, 0.0138)\n",
      "(9, 100.0000, 0.0136)\n",
      "(10, 100.0000, 0.0273)\n",
      "(11, 100.0000, 0.0320)\n",
      "(12, 100.0000, 0.0191)\n",
      "(13, 100.0000, 0.0196)\n",
      "(14, 100.0000, 0.0592)\n",
      "(15, 95.3125, 0.2000)\n",
      "(16, 64.0625, 0.5751)\n",
      "Epoch: 3/20, Step: 150/250, Loss: 0.4503, Accuracy: 97.24\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0111)\n",
      "(3, 100.0000, 0.0105)\n",
      "(4, 100.0000, 0.0060)\n",
      "(5, 100.0000, 0.0137)\n",
      "(6, 100.0000, 0.0154)\n",
      "(7, 100.0000, 0.0109)\n",
      "(8, 100.0000, 0.0148)\n",
      "(9, 100.0000, 0.0107)\n",
      "(10, 98.4375, 0.0417)\n",
      "(11, 100.0000, 0.0251)\n",
      "(12, 98.4375, 0.0280)\n",
      "(13, 98.4375, 0.0419)\n",
      "(14, 99.2188, 0.0719)\n",
      "(15, 93.7500, 0.1714)\n",
      "(16, 70.3125, 0.5748)\n",
      "Epoch: 3/20, Step: 175/250, Loss: 0.4824, Accuracy: 98.18\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0131)\n",
      "(3, 100.0000, 0.0111)\n",
      "(4, 100.0000, 0.0089)\n",
      "(5, 100.0000, 0.0114)\n",
      "(6, 100.0000, 0.0093)\n",
      "(7, 100.0000, 0.0103)\n",
      "(8, 100.0000, 0.0119)\n",
      "(9, 100.0000, 0.0180)\n",
      "(10, 100.0000, 0.0140)\n",
      "(11, 99.2188, 0.0371)\n",
      "(12, 100.0000, 0.0194)\n",
      "(13, 100.0000, 0.0153)\n",
      "(14, 99.2188, 0.0593)\n",
      "(15, 94.5312, 0.1494)\n",
      "(16, 79.6875, 0.5189)\n",
      "Epoch: 3/20, Step: 200/250, Loss: 0.5245, Accuracy: 97.81\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0136)\n",
      "(3, 100.0000, 0.0099)\n",
      "(4, 100.0000, 0.0077)\n",
      "(5, 100.0000, 0.0132)\n",
      "(6, 100.0000, 0.0128)\n",
      "(7, 100.0000, 0.0105)\n",
      "(8, 100.0000, 0.0166)\n",
      "(9, 100.0000, 0.0105)\n",
      "(10, 100.0000, 0.0410)\n",
      "(11, 97.6562, 0.0704)\n",
      "(12, 100.0000, 0.0317)\n",
      "(13, 99.2188, 0.0353)\n",
      "(14, 98.4375, 0.1008)\n",
      "(15, 96.8750, 0.1172)\n",
      "(16, 75.0000, 0.5377)\n",
      "Epoch: 3/20, Step: 225/250, Loss: 0.2751, Accuracy: 98.75\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0071)\n",
      "(3, 100.0000, 0.0097)\n",
      "(4, 100.0000, 0.0065)\n",
      "(5, 100.0000, 0.0112)\n",
      "(6, 100.0000, 0.0077)\n",
      "(7, 100.0000, 0.0078)\n",
      "(8, 100.0000, 0.0091)\n",
      "(9, 100.0000, 0.0140)\n",
      "(10, 99.2188, 0.0383)\n",
      "(11, 98.4375, 0.0431)\n",
      "(12, 100.0000, 0.0261)\n",
      "(13, 99.2188, 0.0329)\n",
      "(14, 99.2188, 0.0422)\n",
      "(15, 98.4375, 0.0807)\n",
      "(16, 86.7188, 0.3830)\n",
      "Solved N = 15, starting N = 16 + 1\n",
      "Epoch: 3/20, Step: 250/250, Loss: 0.5164, Accuracy: 97.22\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0034)\n",
      "(3, 100.0000, 0.0095)\n",
      "(4, 100.0000, 0.0048)\n",
      "(5, 100.0000, 0.0140)\n",
      "(6, 100.0000, 0.0097)\n",
      "(7, 100.0000, 0.0090)\n",
      "(8, 100.0000, 0.0145)\n",
      "(9, 100.0000, 0.0099)\n",
      "(10, 100.0000, 0.0168)\n",
      "(11, 100.0000, 0.0237)\n",
      "(12, 100.0000, 0.0179)\n",
      "(13, 100.0000, 0.0244)\n",
      "(14, 100.0000, 0.0255)\n",
      "(15, 99.2188, 0.0561)\n",
      "(16, 96.0938, 0.1297)\n",
      "(17, 60.1562, 0.7436)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [02:28<14:55, 52.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/20, Step: 25/250, Loss: 0.4446, Accuracy: 97.12\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0127)\n",
      "(3, 100.0000, 0.0150)\n",
      "(4, 100.0000, 0.0065)\n",
      "(5, 100.0000, 0.0151)\n",
      "(6, 100.0000, 0.0113)\n",
      "(7, 100.0000, 0.0083)\n",
      "(8, 100.0000, 0.0193)\n",
      "(9, 100.0000, 0.0116)\n",
      "(10, 100.0000, 0.0211)\n",
      "(11, 100.0000, 0.0234)\n",
      "(12, 100.0000, 0.0121)\n",
      "(13, 100.0000, 0.0170)\n",
      "(14, 99.2188, 0.0409)\n",
      "(15, 97.6562, 0.0919)\n",
      "(16, 94.5312, 0.1897)\n",
      "(17, 62.5000, 0.7093)\n",
      "Epoch: 4/20, Step: 50/250, Loss: 0.3537, Accuracy: 97.66\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0110)\n",
      "(3, 100.0000, 0.0116)\n",
      "(4, 100.0000, 0.0061)\n",
      "(5, 100.0000, 0.0101)\n",
      "(6, 100.0000, 0.0084)\n",
      "(7, 100.0000, 0.0087)\n",
      "(8, 100.0000, 0.0125)\n",
      "(9, 100.0000, 0.0077)\n",
      "(10, 99.2188, 0.0336)\n",
      "(11, 100.0000, 0.0136)\n",
      "(12, 99.2188, 0.0291)\n",
      "(13, 100.0000, 0.0428)\n",
      "(14, 99.2188, 0.0283)\n",
      "(15, 100.0000, 0.0327)\n",
      "(16, 97.6562, 0.0881)\n",
      "(17, 67.1875, 0.5922)\n",
      "Epoch: 4/20, Step: 75/250, Loss: 0.9185, Accuracy: 95.95\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0095)\n",
      "(3, 100.0000, 0.0082)\n",
      "(4, 100.0000, 0.0046)\n",
      "(5, 100.0000, 0.0068)\n",
      "(6, 100.0000, 0.0071)\n",
      "(7, 100.0000, 0.0095)\n",
      "(8, 100.0000, 0.0196)\n",
      "(9, 100.0000, 0.0125)\n",
      "(10, 100.0000, 0.0171)\n",
      "(11, 100.0000, 0.0396)\n",
      "(12, 100.0000, 0.0179)\n",
      "(13, 97.6562, 0.0574)\n",
      "(14, 97.6562, 0.0758)\n",
      "(15, 99.2188, 0.0597)\n",
      "(16, 87.5000, 0.2910)\n",
      "(17, 53.1250, 0.7043)\n",
      "Epoch: 4/20, Step: 100/250, Loss: 0.3235, Accuracy: 98.39\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0084)\n",
      "(3, 100.0000, 0.0115)\n",
      "(4, 100.0000, 0.0082)\n",
      "(5, 100.0000, 0.0109)\n",
      "(6, 100.0000, 0.0061)\n",
      "(7, 100.0000, 0.0088)\n",
      "(8, 100.0000, 0.0090)\n",
      "(9, 100.0000, 0.0047)\n",
      "(10, 99.2188, 0.0266)\n",
      "(11, 100.0000, 0.0162)\n",
      "(12, 100.0000, 0.0130)\n",
      "(13, 100.0000, 0.0145)\n",
      "(14, 100.0000, 0.0304)\n",
      "(15, 100.0000, 0.0465)\n",
      "(16, 98.4375, 0.0482)\n",
      "(17, 76.5625, 0.4602)\n",
      "Solved N = 16, starting N = 17 + 1\n",
      "Epoch: 4/20, Step: 125/250, Loss: 0.9001, Accuracy: 96.78\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0219)\n",
      "(3, 100.0000, 0.0228)\n",
      "(4, 100.0000, 0.0096)\n",
      "(5, 100.0000, 0.0188)\n",
      "(6, 100.0000, 0.0089)\n",
      "(7, 100.0000, 0.0139)\n",
      "(8, 100.0000, 0.0171)\n",
      "(9, 100.0000, 0.0198)\n",
      "(10, 99.2188, 0.0300)\n",
      "(11, 100.0000, 0.0525)\n",
      "(12, 100.0000, 0.0192)\n",
      "(13, 99.2188, 0.0321)\n",
      "(14, 98.4375, 0.0479)\n",
      "(15, 99.2188, 0.0390)\n",
      "(16, 99.2188, 0.0696)\n",
      "(17, 88.2812, 0.2859)\n",
      "(18, 61.7188, 0.7682)\n",
      "Epoch: 4/20, Step: 150/250, Loss: 0.9868, Accuracy: 97.29\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0196)\n",
      "(3, 100.0000, 0.0128)\n",
      "(4, 100.0000, 0.0092)\n",
      "(5, 100.0000, 0.0229)\n",
      "(6, 100.0000, 0.0141)\n",
      "(7, 100.0000, 0.0230)\n",
      "(8, 100.0000, 0.0351)\n",
      "(9, 100.0000, 0.0212)\n",
      "(10, 100.0000, 0.0481)\n",
      "(11, 97.6562, 0.0646)\n",
      "(12, 99.2188, 0.0311)\n",
      "(13, 100.0000, 0.0427)\n",
      "(14, 100.0000, 0.0316)\n",
      "(15, 100.0000, 0.0302)\n",
      "(16, 100.0000, 0.1030)\n",
      "(17, 90.6250, 0.2306)\n",
      "(18, 66.4062, 0.5577)\n",
      "Epoch: 4/20, Step: 175/250, Loss: 0.5500, Accuracy: 98.62\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0114)\n",
      "(3, 100.0000, 0.0149)\n",
      "(4, 100.0000, 0.0061)\n",
      "(5, 100.0000, 0.0118)\n",
      "(6, 100.0000, 0.0077)\n",
      "(7, 100.0000, 0.0080)\n",
      "(8, 100.0000, 0.0151)\n",
      "(9, 100.0000, 0.0065)\n",
      "(10, 100.0000, 0.0193)\n",
      "(11, 99.2188, 0.0496)\n",
      "(12, 100.0000, 0.0119)\n",
      "(13, 100.0000, 0.0134)\n",
      "(14, 100.0000, 0.0276)\n",
      "(15, 100.0000, 0.0233)\n",
      "(16, 100.0000, 0.0285)\n",
      "(17, 92.1875, 0.1942)\n",
      "(18, 85.1562, 0.3960)\n",
      "Epoch: 4/20, Step: 200/250, Loss: 0.5656, Accuracy: 98.58\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0105)\n",
      "(3, 100.0000, 0.0117)\n",
      "(4, 100.0000, 0.0070)\n",
      "(5, 100.0000, 0.0165)\n",
      "(6, 100.0000, 0.0089)\n",
      "(7, 100.0000, 0.0104)\n",
      "(8, 100.0000, 0.0111)\n",
      "(9, 100.0000, 0.0131)\n",
      "(10, 100.0000, 0.0210)\n",
      "(11, 100.0000, 0.0275)\n",
      "(12, 100.0000, 0.0130)\n",
      "(13, 99.2188, 0.0275)\n",
      "(14, 100.0000, 0.0187)\n",
      "(15, 100.0000, 0.0284)\n",
      "(16, 99.2188, 0.0804)\n",
      "(17, 92.9688, 0.1471)\n",
      "(18, 84.3750, 0.4347)\n",
      "Epoch: 4/20, Step: 225/250, Loss: 0.4468, Accuracy: 98.21\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0215)\n",
      "(3, 100.0000, 0.0163)\n",
      "(4, 100.0000, 0.0073)\n",
      "(5, 100.0000, 0.0134)\n",
      "(6, 100.0000, 0.0053)\n",
      "(7, 100.0000, 0.0050)\n",
      "(8, 100.0000, 0.0091)\n",
      "(9, 100.0000, 0.0076)\n",
      "(10, 99.2188, 0.0308)\n",
      "(11, 98.4375, 0.0370)\n",
      "(12, 100.0000, 0.0116)\n",
      "(13, 99.2188, 0.0246)\n",
      "(14, 100.0000, 0.0121)\n",
      "(15, 100.0000, 0.0201)\n",
      "(16, 99.2188, 0.0555)\n",
      "(17, 93.7500, 0.1816)\n",
      "(18, 79.6875, 0.4291)\n",
      "Epoch: 4/20, Step: 250/250, Loss: 0.5215, Accuracy: 98.71\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0155)\n",
      "(3, 100.0000, 0.0231)\n",
      "(4, 100.0000, 0.0070)\n",
      "(5, 100.0000, 0.0105)\n",
      "(6, 100.0000, 0.0076)\n",
      "(7, 100.0000, 0.0074)\n",
      "(8, 99.2188, 0.0232)\n",
      "(9, 100.0000, 0.0132)\n",
      "(10, 100.0000, 0.0159)\n",
      "(11, 99.2188, 0.0324)\n",
      "(12, 100.0000, 0.0155)\n",
      "(13, 100.0000, 0.0167)\n",
      "(14, 100.0000, 0.0195)\n",
      "(15, 100.0000, 0.0282)\n",
      "(16, 98.4375, 0.0408)\n",
      "(17, 100.0000, 0.0560)\n",
      "(18, 81.2500, 0.4508)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [03:36<15:36, 58.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved N = 17, starting N = 18 + 1\n",
      "Epoch: 5/20, Step: 25/250, Loss: 0.8946, Accuracy: 97.09\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0280)\n",
      "(3, 100.0000, 0.0208)\n",
      "(4, 100.0000, 0.0123)\n",
      "(5, 100.0000, 0.0230)\n",
      "(6, 100.0000, 0.0098)\n",
      "(7, 100.0000, 0.0129)\n",
      "(8, 100.0000, 0.0175)\n",
      "(9, 100.0000, 0.0164)\n",
      "(10, 99.2188, 0.0297)\n",
      "(11, 100.0000, 0.0303)\n",
      "(12, 100.0000, 0.0138)\n",
      "(13, 100.0000, 0.0398)\n",
      "(14, 100.0000, 0.0222)\n",
      "(15, 100.0000, 0.0172)\n",
      "(16, 98.4375, 0.0859)\n",
      "(17, 93.7500, 0.1305)\n",
      "(18, 96.0938, 0.1290)\n",
      "(19, 60.1562, 1.0215)\n",
      "Epoch: 5/20, Step: 50/250, Loss: 0.6515, Accuracy: 97.35\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0273)\n",
      "(3, 100.0000, 0.0148)\n",
      "(4, 100.0000, 0.0098)\n",
      "(5, 100.0000, 0.0221)\n",
      "(6, 100.0000, 0.0079)\n",
      "(7, 100.0000, 0.0119)\n",
      "(8, 100.0000, 0.0175)\n",
      "(9, 100.0000, 0.0145)\n",
      "(10, 99.2188, 0.0345)\n",
      "(11, 100.0000, 0.0322)\n",
      "(12, 98.4375, 0.0377)\n",
      "(13, 100.0000, 0.0249)\n",
      "(14, 100.0000, 0.0258)\n",
      "(15, 100.0000, 0.0132)\n",
      "(16, 96.8750, 0.1251)\n",
      "(17, 100.0000, 0.0829)\n",
      "(18, 96.0938, 0.1028)\n",
      "(19, 61.7188, 0.6173)\n",
      "Epoch: 5/20, Step: 75/250, Loss: 0.5136, Accuracy: 98.22\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0303)\n",
      "(3, 100.0000, 0.0103)\n",
      "(4, 100.0000, 0.0060)\n",
      "(5, 100.0000, 0.0101)\n",
      "(6, 100.0000, 0.0060)\n",
      "(7, 100.0000, 0.0081)\n",
      "(8, 100.0000, 0.0069)\n",
      "(9, 100.0000, 0.0085)\n",
      "(10, 100.0000, 0.0167)\n",
      "(11, 100.0000, 0.0216)\n",
      "(12, 100.0000, 0.0144)\n",
      "(13, 100.0000, 0.0143)\n",
      "(14, 100.0000, 0.0160)\n",
      "(15, 100.0000, 0.0141)\n",
      "(16, 96.0938, 0.0832)\n",
      "(17, 99.2188, 0.0567)\n",
      "(18, 99.2188, 0.0521)\n",
      "(19, 74.2188, 0.5088)\n",
      "Solved N = 18, starting N = 19 + 1\n",
      "Epoch: 5/20, Step: 100/250, Loss: 0.9296, Accuracy: 97.00\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0281)\n",
      "(3, 100.0000, 0.0107)\n",
      "(4, 100.0000, 0.0078)\n",
      "(5, 99.2188, 0.0237)\n",
      "(6, 100.0000, 0.0078)\n",
      "(7, 100.0000, 0.0142)\n",
      "(8, 100.0000, 0.0129)\n",
      "(9, 100.0000, 0.0163)\n",
      "(10, 100.0000, 0.0221)\n",
      "(11, 100.0000, 0.0226)\n",
      "(12, 100.0000, 0.0101)\n",
      "(13, 100.0000, 0.0241)\n",
      "(14, 100.0000, 0.0248)\n",
      "(15, 100.0000, 0.0255)\n",
      "(16, 97.6563, 0.1017)\n",
      "(17, 99.2188, 0.0463)\n",
      "(18, 100.0000, 0.0649)\n",
      "(19, 91.4062, 0.2801)\n",
      "(20, 56.2500, 0.6928)\n",
      "Epoch: 5/20, Step: 125/250, Loss: 1.0247, Accuracy: 96.50\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0491)\n",
      "(3, 100.0000, 0.0285)\n",
      "(4, 100.0000, 0.0101)\n",
      "(5, 100.0000, 0.0202)\n",
      "(6, 100.0000, 0.0121)\n",
      "(7, 100.0000, 0.0145)\n",
      "(8, 100.0000, 0.0266)\n",
      "(9, 100.0000, 0.0181)\n",
      "(10, 99.2188, 0.0553)\n",
      "(11, 100.0000, 0.0668)\n",
      "(12, 100.0000, 0.0378)\n",
      "(13, 100.0000, 0.0455)\n",
      "(14, 99.2188, 0.0366)\n",
      "(15, 99.2188, 0.0328)\n",
      "(16, 97.6563, 0.1112)\n",
      "(17, 96.8750, 0.0912)\n",
      "(18, 97.6563, 0.0927)\n",
      "(19, 85.9375, 0.3205)\n",
      "(20, 57.8125, 0.7503)\n",
      "Epoch: 5/20, Step: 150/250, Loss: 0.6615, Accuracy: 97.25\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0295)\n",
      "(3, 100.0000, 0.0171)\n",
      "(4, 100.0000, 0.0065)\n",
      "(5, 100.0000, 0.0149)\n",
      "(6, 100.0000, 0.0075)\n",
      "(7, 100.0000, 0.0099)\n",
      "(8, 100.0000, 0.0130)\n",
      "(9, 100.0000, 0.0085)\n",
      "(10, 100.0000, 0.0190)\n",
      "(11, 100.0000, 0.0278)\n",
      "(12, 100.0000, 0.0146)\n",
      "(13, 100.0000, 0.0204)\n",
      "(14, 100.0000, 0.0130)\n",
      "(15, 100.0000, 0.0185)\n",
      "(16, 97.6563, 0.0752)\n",
      "(17, 98.4375, 0.0480)\n",
      "(18, 100.0000, 0.0346)\n",
      "(19, 94.5312, 0.1753)\n",
      "(20, 57.0312, 0.8130)\n",
      "Epoch: 5/20, Step: 175/250, Loss: 0.9365, Accuracy: 96.67\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0286)\n",
      "(3, 100.0000, 0.0173)\n",
      "(4, 100.0000, 0.0099)\n",
      "(5, 100.0000, 0.0216)\n",
      "(6, 100.0000, 0.0120)\n",
      "(7, 100.0000, 0.0122)\n",
      "(8, 100.0000, 0.0211)\n",
      "(9, 100.0000, 0.0145)\n",
      "(10, 100.0000, 0.0340)\n",
      "(11, 100.0000, 0.0326)\n",
      "(12, 100.0000, 0.0084)\n",
      "(13, 100.0000, 0.0380)\n",
      "(14, 100.0000, 0.0249)\n",
      "(15, 98.4375, 0.0435)\n",
      "(16, 95.3125, 0.1374)\n",
      "(17, 97.6563, 0.0638)\n",
      "(18, 96.8750, 0.1009)\n",
      "(19, 89.0625, 0.2862)\n",
      "(20, 59.3750, 0.7606)\n",
      "Epoch: 5/20, Step: 200/250, Loss: 0.8053, Accuracy: 97.82\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0164)\n",
      "(3, 100.0000, 0.0214)\n",
      "(4, 100.0000, 0.0055)\n",
      "(5, 100.0000, 0.0148)\n",
      "(6, 100.0000, 0.0086)\n",
      "(7, 100.0000, 0.0106)\n",
      "(8, 100.0000, 0.0097)\n",
      "(9, 100.0000, 0.0114)\n",
      "(10, 100.0000, 0.0197)\n",
      "(11, 100.0000, 0.0225)\n",
      "(12, 100.0000, 0.0084)\n",
      "(13, 100.0000, 0.0279)\n",
      "(14, 100.0000, 0.0228)\n",
      "(15, 100.0000, 0.0178)\n",
      "(16, 99.2188, 0.0996)\n",
      "(17, 99.2188, 0.0513)\n",
      "(18, 100.0000, 0.0233)\n",
      "(19, 96.0938, 0.1573)\n",
      "(20, 64.0625, 0.7052)\n",
      "Epoch: 5/20, Step: 225/250, Loss: 0.6321, Accuracy: 97.16\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0447)\n",
      "(3, 99.2188, 0.0234)\n",
      "(4, 100.0000, 0.0103)\n",
      "(5, 100.0000, 0.0134)\n",
      "(6, 100.0000, 0.0084)\n",
      "(7, 100.0000, 0.0109)\n",
      "(8, 100.0000, 0.0148)\n",
      "(9, 100.0000, 0.0126)\n",
      "(10, 100.0000, 0.0108)\n",
      "(11, 100.0000, 0.0221)\n",
      "(12, 99.2188, 0.0390)\n",
      "(13, 100.0000, 0.0228)\n",
      "(14, 100.0000, 0.0284)\n",
      "(15, 99.2188, 0.0247)\n",
      "(16, 100.0000, 0.0369)\n",
      "(17, 98.4375, 0.0463)\n",
      "(18, 98.4375, 0.0451)\n",
      "(19, 92.1875, 0.1818)\n",
      "(20, 59.3750, 0.7434)\n",
      "Epoch: 5/20, Step: 250/250, Loss: 0.5827, Accuracy: 96.88\n",
      "(N, accuracy, loss):\n",
      "(2, 98.4375, 0.0354)\n",
      "(3, 100.0000, 0.0152)\n",
      "(4, 100.0000, 0.0079)\n",
      "(5, 100.0000, 0.0089)\n",
      "(6, 100.0000, 0.0057)\n",
      "(7, 100.0000, 0.0099)\n",
      "(8, 100.0000, 0.0090)\n",
      "(9, 100.0000, 0.0078)\n",
      "(10, 99.2188, 0.0281)\n",
      "(11, 99.2188, 0.0221)\n",
      "(12, 100.0000, 0.0080)\n",
      "(13, 99.2188, 0.0297)\n",
      "(14, 100.0000, 0.0230)\n",
      "(15, 100.0000, 0.0248)\n",
      "(16, 99.2188, 0.0482)\n",
      "(17, 99.2188, 0.0436)\n",
      "(18, 99.2188, 0.0470)\n",
      "(19, 89.0625, 0.2661)\n",
      "(20, 57.8125, 0.7225)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [04:51<16:10, 64.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/20, Step: 25/250, Loss: 0.5837, Accuracy: 97.33\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0171)\n",
      "(3, 100.0000, 0.0107)\n",
      "(4, 100.0000, 0.0067)\n",
      "(5, 100.0000, 0.0078)\n",
      "(6, 100.0000, 0.0060)\n",
      "(7, 100.0000, 0.0089)\n",
      "(8, 100.0000, 0.0223)\n",
      "(9, 100.0000, 0.0090)\n",
      "(10, 100.0000, 0.0105)\n",
      "(11, 100.0000, 0.0104)\n",
      "(12, 100.0000, 0.0090)\n",
      "(13, 100.0000, 0.0107)\n",
      "(14, 100.0000, 0.0189)\n",
      "(15, 100.0000, 0.0152)\n",
      "(16, 100.0000, 0.0420)\n",
      "(17, 97.6563, 0.0747)\n",
      "(18, 100.0000, 0.0461)\n",
      "(19, 97.6563, 0.0940)\n",
      "(20, 53.9062, 0.6914)\n",
      "Epoch: 6/20, Step: 50/250, Loss: 0.7187, Accuracy: 96.79\n",
      "(N, accuracy, loss):\n",
      "(2, 97.6563, 0.0699)\n",
      "(3, 100.0000, 0.0211)\n",
      "(4, 100.0000, 0.0046)\n",
      "(5, 100.0000, 0.0086)\n",
      "(6, 100.0000, 0.0061)\n",
      "(7, 100.0000, 0.0133)\n",
      "(8, 100.0000, 0.0120)\n",
      "(9, 100.0000, 0.0094)\n",
      "(10, 100.0000, 0.0168)\n",
      "(11, 100.0000, 0.0171)\n",
      "(12, 100.0000, 0.0175)\n",
      "(13, 100.0000, 0.0312)\n",
      "(14, 100.0000, 0.0138)\n",
      "(15, 100.0000, 0.0110)\n",
      "(16, 99.2188, 0.0627)\n",
      "(17, 97.6563, 0.0516)\n",
      "(18, 100.0000, 0.0403)\n",
      "(19, 94.5312, 0.1382)\n",
      "(20, 50.0000, 0.6823)\n",
      "Epoch: 6/20, Step: 75/250, Loss: 0.6372, Accuracy: 97.57\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0382)\n",
      "(3, 100.0000, 0.0173)\n",
      "(4, 100.0000, 0.0061)\n",
      "(5, 100.0000, 0.0113)\n",
      "(6, 100.0000, 0.0072)\n",
      "(7, 100.0000, 0.0074)\n",
      "(8, 100.0000, 0.0135)\n",
      "(9, 100.0000, 0.0181)\n",
      "(10, 100.0000, 0.0185)\n",
      "(11, 100.0000, 0.0185)\n",
      "(12, 100.0000, 0.0218)\n",
      "(13, 100.0000, 0.0240)\n",
      "(14, 99.2188, 0.0303)\n",
      "(15, 100.0000, 0.0194)\n",
      "(16, 96.8750, 0.0731)\n",
      "(17, 100.0000, 0.0234)\n",
      "(18, 99.2188, 0.0520)\n",
      "(19, 97.6563, 0.0686)\n",
      "(20, 60.9375, 0.7268)\n",
      "Epoch: 6/20, Step: 100/250, Loss: 0.5320, Accuracy: 97.33\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0137)\n",
      "(3, 100.0000, 0.0089)\n",
      "(4, 100.0000, 0.0043)\n",
      "(5, 100.0000, 0.0076)\n",
      "(6, 100.0000, 0.0045)\n",
      "(7, 100.0000, 0.0089)\n",
      "(8, 100.0000, 0.0104)\n",
      "(9, 100.0000, 0.0083)\n",
      "(10, 100.0000, 0.0103)\n",
      "(11, 100.0000, 0.0244)\n",
      "(12, 99.2188, 0.0155)\n",
      "(13, 100.0000, 0.0202)\n",
      "(14, 100.0000, 0.0094)\n",
      "(15, 99.2188, 0.0250)\n",
      "(16, 99.2188, 0.0374)\n",
      "(17, 99.2188, 0.0328)\n",
      "(18, 100.0000, 0.0277)\n",
      "(19, 97.6563, 0.0992)\n",
      "(20, 54.6875, 0.7332)\n",
      "Epoch: 6/20, Step: 125/250, Loss: 0.4832, Accuracy: 97.04\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0141)\n",
      "(3, 100.0000, 0.0222)\n",
      "(4, 100.0000, 0.0055)\n",
      "(5, 100.0000, 0.0117)\n",
      "(6, 100.0000, 0.0047)\n",
      "(7, 100.0000, 0.0085)\n",
      "(8, 100.0000, 0.0087)\n",
      "(9, 100.0000, 0.0099)\n",
      "(10, 100.0000, 0.0172)\n",
      "(11, 100.0000, 0.0116)\n",
      "(12, 100.0000, 0.0051)\n",
      "(13, 97.6563, 0.0559)\n",
      "(14, 100.0000, 0.0148)\n",
      "(15, 100.0000, 0.0102)\n",
      "(16, 100.0000, 0.0448)\n",
      "(17, 99.2188, 0.0363)\n",
      "(18, 98.4375, 0.0411)\n",
      "(19, 95.3125, 0.1480)\n",
      "(20, 53.1250, 0.9803)\n",
      "Epoch: 6/20, Step: 150/250, Loss: 0.4255, Accuracy: 97.99\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0049)\n",
      "(3, 100.0000, 0.0118)\n",
      "(4, 100.0000, 0.0055)\n",
      "(5, 100.0000, 0.0145)\n",
      "(6, 100.0000, 0.0062)\n",
      "(7, 100.0000, 0.0076)\n",
      "(8, 100.0000, 0.0103)\n",
      "(9, 100.0000, 0.0078)\n",
      "(10, 100.0000, 0.0122)\n",
      "(11, 100.0000, 0.0150)\n",
      "(12, 100.0000, 0.0114)\n",
      "(13, 99.2188, 0.0276)\n",
      "(14, 100.0000, 0.0181)\n",
      "(15, 100.0000, 0.0161)\n",
      "(16, 99.2188, 0.0422)\n",
      "(17, 99.2188, 0.0295)\n",
      "(18, 98.4375, 0.0500)\n",
      "(19, 98.4375, 0.0759)\n",
      "(20, 67.1875, 0.7171)\n",
      "Solved N = 19, starting N = 20 + 1\n",
      "Epoch: 6/20, Step: 175/250, Loss: 1.5474, Accuracy: 95.43\n",
      "(N, accuracy, loss):\n",
      "(2, 93.7500, 0.1412)\n",
      "(3, 100.0000, 0.0312)\n",
      "(4, 100.0000, 0.0124)\n",
      "(5, 100.0000, 0.0334)\n",
      "(6, 100.0000, 0.0175)\n",
      "(7, 100.0000, 0.0086)\n",
      "(8, 100.0000, 0.0212)\n",
      "(9, 100.0000, 0.0183)\n",
      "(10, 100.0000, 0.0254)\n",
      "(11, 98.4375, 0.0375)\n",
      "(12, 100.0000, 0.0240)\n",
      "(13, 99.2188, 0.0327)\n",
      "(14, 100.0000, 0.0180)\n",
      "(15, 100.0000, 0.0136)\n",
      "(16, 98.4375, 0.0592)\n",
      "(17, 100.0000, 0.0287)\n",
      "(18, 99.2188, 0.0455)\n",
      "(19, 97.6562, 0.1076)\n",
      "(20, 78.1250, 0.5027)\n",
      "(21, 43.7500, 1.0828)\n",
      "Epoch: 6/20, Step: 200/250, Loss: 1.1369, Accuracy: 96.88\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0241)\n",
      "(3, 100.0000, 0.0207)\n",
      "(4, 100.0000, 0.0060)\n",
      "(5, 100.0000, 0.0189)\n",
      "(6, 100.0000, 0.0096)\n",
      "(7, 100.0000, 0.0170)\n",
      "(8, 99.2188, 0.0272)\n",
      "(9, 100.0000, 0.0195)\n",
      "(10, 100.0000, 0.0180)\n",
      "(11, 100.0000, 0.0201)\n",
      "(12, 98.4375, 0.0433)\n",
      "(13, 98.4375, 0.0742)\n",
      "(14, 100.0000, 0.0167)\n",
      "(15, 99.2188, 0.0211)\n",
      "(16, 98.4375, 0.0647)\n",
      "(17, 99.2188, 0.0257)\n",
      "(18, 99.2188, 0.0545)\n",
      "(19, 97.6562, 0.0696)\n",
      "(20, 81.2500, 0.4605)\n",
      "(21, 66.4062, 0.6232)\n",
      "Epoch: 6/20, Step: 225/250, Loss: 0.4949, Accuracy: 97.85\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0172)\n",
      "(3, 100.0000, 0.0138)\n",
      "(4, 100.0000, 0.0057)\n",
      "(5, 100.0000, 0.0108)\n",
      "(6, 100.0000, 0.0070)\n",
      "(7, 100.0000, 0.0060)\n",
      "(8, 100.0000, 0.0072)\n",
      "(9, 100.0000, 0.0050)\n",
      "(10, 100.0000, 0.0101)\n",
      "(11, 99.2188, 0.0168)\n",
      "(12, 100.0000, 0.0101)\n",
      "(13, 99.2188, 0.0226)\n",
      "(14, 100.0000, 0.0073)\n",
      "(15, 100.0000, 0.0087)\n",
      "(16, 98.4375, 0.0435)\n",
      "(17, 100.0000, 0.0169)\n",
      "(18, 98.4375, 0.0348)\n",
      "(19, 100.0000, 0.0270)\n",
      "(20, 97.6562, 0.1433)\n",
      "(21, 64.0625, 0.5943)\n",
      "Epoch: 6/20, Step: 250/250, Loss: 1.3402, Accuracy: 98.12\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0279)\n",
      "(3, 100.0000, 0.0118)\n",
      "(4, 100.0000, 0.0057)\n",
      "(5, 100.0000, 0.0181)\n",
      "(6, 100.0000, 0.0136)\n",
      "(7, 100.0000, 0.0085)\n",
      "(8, 100.0000, 0.0128)\n",
      "(9, 100.0000, 0.0126)\n",
      "(10, 100.0000, 0.0101)\n",
      "(11, 100.0000, 0.0243)\n",
      "(12, 100.0000, 0.0168)\n",
      "(13, 100.0000, 0.0255)\n",
      "(14, 100.0000, 0.0137)\n",
      "(15, 100.0000, 0.0103)\n",
      "(16, 100.0000, 0.0206)\n",
      "(17, 99.2188, 0.0242)\n",
      "(18, 98.4375, 0.0507)\n",
      "(19, 98.4375, 0.0584)\n",
      "(20, 98.4375, 0.1066)\n",
      "(21, 67.9688, 0.5524)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [06:08<16:01, 68.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved N = 20, starting N = 21 + 1\n",
      "Epoch: 7/20, Step: 25/250, Loss: 1.1329, Accuracy: 95.65\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0467)\n",
      "(3, 99.2188, 0.0438)\n",
      "(4, 100.0000, 0.0128)\n",
      "(5, 100.0000, 0.0244)\n",
      "(6, 100.0000, 0.0125)\n",
      "(7, 99.2188, 0.0244)\n",
      "(8, 98.4375, 0.0306)\n",
      "(9, 100.0000, 0.0154)\n",
      "(10, 100.0000, 0.0252)\n",
      "(11, 99.2188, 0.0388)\n",
      "(12, 100.0000, 0.0140)\n",
      "(13, 96.8750, 0.0771)\n",
      "(14, 100.0000, 0.0346)\n",
      "(15, 99.2188, 0.0266)\n",
      "(16, 98.4375, 0.0746)\n",
      "(17, 99.2188, 0.0415)\n",
      "(18, 99.2188, 0.0437)\n",
      "(19, 93.7500, 0.1105)\n",
      "(20, 99.2188, 0.1439)\n",
      "(21, 79.6875, 0.4330)\n",
      "(22, 47.6562, 0.8758)\n",
      "Epoch: 7/20, Step: 50/250, Loss: 0.9835, Accuracy: 97.02\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0301)\n",
      "(3, 100.0000, 0.0141)\n",
      "(4, 100.0000, 0.0053)\n",
      "(5, 100.0000, 0.0232)\n",
      "(6, 100.0000, 0.0086)\n",
      "(7, 100.0000, 0.0081)\n",
      "(8, 100.0000, 0.0182)\n",
      "(9, 100.0000, 0.0099)\n",
      "(10, 100.0000, 0.0134)\n",
      "(11, 99.2188, 0.0260)\n",
      "(12, 100.0000, 0.0210)\n",
      "(13, 100.0000, 0.0228)\n",
      "(14, 99.2188, 0.0249)\n",
      "(15, 100.0000, 0.0160)\n",
      "(16, 99.2188, 0.0416)\n",
      "(17, 99.2188, 0.0272)\n",
      "(18, 99.2188, 0.0482)\n",
      "(19, 98.4375, 0.0667)\n",
      "(20, 96.8750, 0.1297)\n",
      "(21, 93.7500, 0.1965)\n",
      "(22, 53.1250, 0.9107)\n",
      "Epoch: 7/20, Step: 75/250, Loss: 0.7913, Accuracy: 97.95\n",
      "(N, accuracy, loss):\n",
      "(2, 98.4375, 0.0502)\n",
      "(3, 100.0000, 0.0129)\n",
      "(4, 100.0000, 0.0079)\n",
      "(5, 100.0000, 0.0151)\n",
      "(6, 100.0000, 0.0062)\n",
      "(7, 100.0000, 0.0062)\n",
      "(8, 100.0000, 0.0240)\n",
      "(9, 100.0000, 0.0113)\n",
      "(10, 100.0000, 0.0103)\n",
      "(11, 99.2188, 0.0272)\n",
      "(12, 100.0000, 0.0178)\n",
      "(13, 98.4375, 0.0357)\n",
      "(14, 100.0000, 0.0127)\n",
      "(15, 100.0000, 0.0167)\n",
      "(16, 100.0000, 0.0239)\n",
      "(17, 97.6562, 0.0673)\n",
      "(18, 100.0000, 0.0227)\n",
      "(19, 98.4375, 0.0641)\n",
      "(20, 99.2188, 0.0815)\n",
      "(21, 95.3125, 0.1596)\n",
      "(22, 70.3125, 0.5954)\n",
      "Epoch: 7/20, Step: 100/250, Loss: 0.7257, Accuracy: 97.62\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0303)\n",
      "(3, 100.0000, 0.0108)\n",
      "(4, 100.0000, 0.0112)\n",
      "(5, 100.0000, 0.0133)\n",
      "(6, 100.0000, 0.0099)\n",
      "(7, 100.0000, 0.0085)\n",
      "(8, 100.0000, 0.0256)\n",
      "(9, 99.2188, 0.0233)\n",
      "(10, 100.0000, 0.0153)\n",
      "(11, 100.0000, 0.0188)\n",
      "(12, 100.0000, 0.0203)\n",
      "(13, 98.4375, 0.0373)\n",
      "(14, 100.0000, 0.0101)\n",
      "(15, 100.0000, 0.0285)\n",
      "(16, 100.0000, 0.0321)\n",
      "(17, 97.6562, 0.0420)\n",
      "(18, 100.0000, 0.0257)\n",
      "(19, 96.8750, 0.0592)\n",
      "(20, 100.0000, 0.0849)\n",
      "(21, 96.0937, 0.1599)\n",
      "(22, 62.5000, 0.6609)\n",
      "Epoch: 7/20, Step: 125/250, Loss: 0.5551, Accuracy: 97.92\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0205)\n",
      "(3, 100.0000, 0.0109)\n",
      "(4, 100.0000, 0.0056)\n",
      "(5, 100.0000, 0.0118)\n",
      "(6, 100.0000, 0.0069)\n",
      "(7, 100.0000, 0.0071)\n",
      "(8, 100.0000, 0.0141)\n",
      "(9, 100.0000, 0.0076)\n",
      "(10, 100.0000, 0.0130)\n",
      "(11, 100.0000, 0.0129)\n",
      "(12, 100.0000, 0.0053)\n",
      "(13, 100.0000, 0.0183)\n",
      "(14, 100.0000, 0.0071)\n",
      "(15, 100.0000, 0.0070)\n",
      "(16, 100.0000, 0.0176)\n",
      "(17, 100.0000, 0.0167)\n",
      "(18, 100.0000, 0.0142)\n",
      "(19, 99.2188, 0.0349)\n",
      "(20, 99.2188, 0.0526)\n",
      "(21, 99.2188, 0.0626)\n",
      "(22, 58.5938, 0.6462)\n",
      "Solved N = 21, starting N = 22 + 1\n",
      "Epoch: 7/20, Step: 150/250, Loss: 0.8966, Accuracy: 96.59\n",
      "(N, accuracy, loss):\n",
      "(2, 98.4375, 0.0494)\n",
      "(3, 99.2188, 0.0307)\n",
      "(4, 100.0000, 0.0192)\n",
      "(5, 100.0000, 0.0241)\n",
      "(6, 100.0000, 0.0211)\n",
      "(7, 100.0000, 0.0101)\n",
      "(8, 100.0000, 0.0173)\n",
      "(9, 100.0000, 0.0214)\n",
      "(10, 100.0000, 0.0122)\n",
      "(11, 100.0000, 0.0329)\n",
      "(12, 100.0000, 0.0060)\n",
      "(13, 98.4375, 0.0401)\n",
      "(14, 100.0000, 0.0158)\n",
      "(15, 100.0000, 0.0190)\n",
      "(16, 100.0000, 0.0175)\n",
      "(17, 96.8750, 0.0864)\n",
      "(18, 99.2188, 0.0362)\n",
      "(19, 99.2188, 0.0382)\n",
      "(20, 99.2188, 0.0605)\n",
      "(21, 98.4375, 0.0564)\n",
      "(22, 75.0000, 0.6020)\n",
      "(23, 60.9375, 0.8984)\n",
      "Epoch: 7/20, Step: 175/250, Loss: 0.7957, Accuracy: 97.44\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0448)\n",
      "(3, 100.0000, 0.0222)\n",
      "(4, 100.0000, 0.0051)\n",
      "(5, 100.0000, 0.0146)\n",
      "(6, 100.0000, 0.0101)\n",
      "(7, 100.0000, 0.0115)\n",
      "(8, 100.0000, 0.0141)\n",
      "(9, 100.0000, 0.0096)\n",
      "(10, 100.0000, 0.0122)\n",
      "(11, 100.0000, 0.0239)\n",
      "(12, 100.0000, 0.0044)\n",
      "(13, 100.0000, 0.0133)\n",
      "(14, 100.0000, 0.0194)\n",
      "(15, 100.0000, 0.0153)\n",
      "(16, 100.0000, 0.0178)\n",
      "(17, 100.0000, 0.0313)\n",
      "(18, 99.2188, 0.0355)\n",
      "(19, 99.2188, 0.0521)\n",
      "(20, 99.2188, 0.0460)\n",
      "(21, 95.3125, 0.1603)\n",
      "(22, 89.0625, 0.2785)\n",
      "(23, 62.5000, 0.8094)\n",
      "Epoch: 7/20, Step: 200/250, Loss: 0.8212, Accuracy: 97.76\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0290)\n",
      "(3, 100.0000, 0.0164)\n",
      "(4, 100.0000, 0.0169)\n",
      "(5, 100.0000, 0.0285)\n",
      "(6, 100.0000, 0.0126)\n",
      "(7, 100.0000, 0.0148)\n",
      "(8, 100.0000, 0.0156)\n",
      "(9, 100.0000, 0.0128)\n",
      "(10, 100.0000, 0.0152)\n",
      "(11, 100.0000, 0.0275)\n",
      "(12, 100.0000, 0.0146)\n",
      "(13, 99.2188, 0.0211)\n",
      "(14, 100.0000, 0.0140)\n",
      "(15, 99.2188, 0.0213)\n",
      "(16, 100.0000, 0.0282)\n",
      "(17, 100.0000, 0.0175)\n",
      "(18, 100.0000, 0.0278)\n",
      "(19, 99.2188, 0.0312)\n",
      "(20, 97.6562, 0.0475)\n",
      "(21, 96.8750, 0.0961)\n",
      "(22, 94.5312, 0.1636)\n",
      "(23, 64.8438, 0.6079)\n",
      "Epoch: 7/20, Step: 225/250, Loss: 0.6778, Accuracy: 98.05\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0328)\n",
      "(3, 100.0000, 0.0144)\n",
      "(4, 100.0000, 0.0097)\n",
      "(5, 100.0000, 0.0265)\n",
      "(6, 100.0000, 0.0119)\n",
      "(7, 100.0000, 0.0124)\n",
      "(8, 100.0000, 0.0119)\n",
      "(9, 100.0000, 0.0223)\n",
      "(10, 100.0000, 0.0159)\n",
      "(11, 100.0000, 0.0216)\n",
      "(12, 100.0000, 0.0156)\n",
      "(13, 99.2188, 0.0329)\n",
      "(14, 100.0000, 0.0109)\n",
      "(15, 100.0000, 0.0065)\n",
      "(16, 100.0000, 0.0195)\n",
      "(17, 99.2188, 0.0290)\n",
      "(18, 100.0000, 0.0204)\n",
      "(19, 99.2188, 0.0361)\n",
      "(20, 100.0000, 0.0359)\n",
      "(21, 100.0000, 0.0523)\n",
      "(22, 96.0938, 0.1222)\n",
      "(23, 63.2812, 0.6138)\n",
      "Epoch: 7/20, Step: 250/250, Loss: 0.6157, Accuracy: 97.98\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0177)\n",
      "(3, 100.0000, 0.0092)\n",
      "(4, 100.0000, 0.0075)\n",
      "(5, 100.0000, 0.0087)\n",
      "(6, 100.0000, 0.0082)\n",
      "(7, 100.0000, 0.0126)\n",
      "(8, 100.0000, 0.0126)\n",
      "(9, 100.0000, 0.0158)\n",
      "(10, 100.0000, 0.0140)\n",
      "(11, 99.2188, 0.0246)\n",
      "(12, 99.2188, 0.0226)\n",
      "(13, 100.0000, 0.0132)\n",
      "(14, 100.0000, 0.0133)\n",
      "(15, 100.0000, 0.0169)\n",
      "(16, 98.4375, 0.0501)\n",
      "(17, 99.2188, 0.0210)\n",
      "(18, 100.0000, 0.0261)\n",
      "(19, 99.2188, 0.0473)\n",
      "(20, 98.4375, 0.0769)\n",
      "(21, 99.2188, 0.0988)\n",
      "(22, 99.2188, 0.0918)\n",
      "(23, 63.2812, 0.5891)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [07:31<15:55, 73.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved N = 22, starting N = 23 + 1\n",
      "Epoch: 8/20, Step: 25/250, Loss: 1.1735, Accuracy: 96.54\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0188)\n",
      "(3, 100.0000, 0.0199)\n",
      "(4, 100.0000, 0.0281)\n",
      "(5, 100.0000, 0.0189)\n",
      "(6, 100.0000, 0.0166)\n",
      "(7, 100.0000, 0.0202)\n",
      "(8, 100.0000, 0.0214)\n",
      "(9, 100.0000, 0.0208)\n",
      "(10, 100.0000, 0.0268)\n",
      "(11, 99.2188, 0.0395)\n",
      "(12, 99.2188, 0.0286)\n",
      "(13, 99.2188, 0.0320)\n",
      "(14, 98.4375, 0.0431)\n",
      "(15, 100.0000, 0.0080)\n",
      "(16, 100.0000, 0.0317)\n",
      "(17, 99.2188, 0.0382)\n",
      "(18, 98.4375, 0.0467)\n",
      "(19, 100.0000, 0.0277)\n",
      "(20, 98.4375, 0.0853)\n",
      "(21, 97.6562, 0.0592)\n",
      "(22, 90.6250, 0.1839)\n",
      "(23, 79.6875, 0.3735)\n",
      "(24, 60.1562, 1.1811)\n",
      "Epoch: 8/20, Step: 50/250, Loss: 0.9399, Accuracy: 97.55\n",
      "(N, accuracy, loss):\n",
      "(2, 97.6562, 0.0651)\n",
      "(3, 100.0000, 0.0113)\n",
      "(4, 100.0000, 0.0103)\n",
      "(5, 100.0000, 0.0124)\n",
      "(6, 100.0000, 0.0075)\n",
      "(7, 100.0000, 0.0095)\n",
      "(8, 100.0000, 0.0076)\n",
      "(9, 100.0000, 0.0153)\n",
      "(10, 100.0000, 0.0101)\n",
      "(11, 100.0000, 0.0206)\n",
      "(12, 100.0000, 0.0096)\n",
      "(13, 99.2188, 0.0276)\n",
      "(14, 100.0000, 0.0117)\n",
      "(15, 100.0000, 0.0108)\n",
      "(16, 100.0000, 0.0142)\n",
      "(17, 99.2188, 0.0270)\n",
      "(18, 100.0000, 0.0160)\n",
      "(19, 100.0000, 0.0295)\n",
      "(20, 99.2188, 0.0697)\n",
      "(21, 98.4375, 0.0569)\n",
      "(22, 92.9688, 0.1779)\n",
      "(23, 92.9688, 0.2066)\n",
      "(24, 64.0625, 0.6526)\n",
      "Epoch: 8/20, Step: 75/250, Loss: 0.7555, Accuracy: 97.59\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0183)\n",
      "(3, 100.0000, 0.0082)\n",
      "(4, 100.0000, 0.0040)\n",
      "(5, 100.0000, 0.0141)\n",
      "(6, 100.0000, 0.0100)\n",
      "(7, 100.0000, 0.0207)\n",
      "(8, 100.0000, 0.0124)\n",
      "(9, 100.0000, 0.0108)\n",
      "(10, 100.0000, 0.0164)\n",
      "(11, 98.4375, 0.0404)\n",
      "(12, 99.2188, 0.0242)\n",
      "(13, 100.0000, 0.0173)\n",
      "(14, 100.0000, 0.0143)\n",
      "(15, 100.0000, 0.0238)\n",
      "(16, 99.2188, 0.0268)\n",
      "(17, 98.4375, 0.0549)\n",
      "(18, 99.2188, 0.0349)\n",
      "(19, 97.6562, 0.0671)\n",
      "(20, 99.2188, 0.0572)\n",
      "(21, 98.4375, 0.0485)\n",
      "(22, 97.6562, 0.0806)\n",
      "(23, 92.9688, 0.1896)\n",
      "(24, 64.0625, 0.6192)\n",
      "Epoch: 8/20, Step: 100/250, Loss: 0.7114, Accuracy: 98.78\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0188)\n",
      "(3, 100.0000, 0.0096)\n",
      "(4, 100.0000, 0.0096)\n",
      "(5, 100.0000, 0.0130)\n",
      "(6, 100.0000, 0.0103)\n",
      "(7, 100.0000, 0.0066)\n",
      "(8, 100.0000, 0.0081)\n",
      "(9, 100.0000, 0.0082)\n",
      "(10, 100.0000, 0.0136)\n",
      "(11, 100.0000, 0.0130)\n",
      "(12, 100.0000, 0.0100)\n",
      "(13, 100.0000, 0.0085)\n",
      "(14, 100.0000, 0.0121)\n",
      "(15, 100.0000, 0.0111)\n",
      "(16, 100.0000, 0.0103)\n",
      "(17, 99.2188, 0.0231)\n",
      "(18, 100.0000, 0.0112)\n",
      "(19, 100.0000, 0.0195)\n",
      "(20, 100.0000, 0.0339)\n",
      "(21, 100.0000, 0.0445)\n",
      "(22, 99.2188, 0.0801)\n",
      "(23, 96.8750, 0.1477)\n",
      "(24, 76.5625, 0.5240)\n",
      "Epoch: 8/20, Step: 125/250, Loss: 0.5860, Accuracy: 98.54\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0244)\n",
      "(3, 100.0000, 0.0084)\n",
      "(4, 100.0000, 0.0083)\n",
      "(5, 100.0000, 0.0084)\n",
      "(6, 100.0000, 0.0080)\n",
      "(7, 100.0000, 0.0117)\n",
      "(8, 100.0000, 0.0058)\n",
      "(9, 100.0000, 0.0165)\n",
      "(10, 100.0000, 0.0142)\n",
      "(11, 100.0000, 0.0217)\n",
      "(12, 100.0000, 0.0102)\n",
      "(13, 100.0000, 0.0173)\n",
      "(14, 100.0000, 0.0099)\n",
      "(15, 100.0000, 0.0116)\n",
      "(16, 99.2188, 0.0237)\n",
      "(17, 97.6562, 0.0431)\n",
      "(18, 100.0000, 0.0107)\n",
      "(19, 100.0000, 0.0326)\n",
      "(20, 98.4375, 0.0556)\n",
      "(21, 100.0000, 0.0280)\n",
      "(22, 98.4375, 0.0758)\n",
      "(23, 95.3125, 0.1348)\n",
      "(24, 78.1250, 0.4213)\n",
      "Epoch: 8/20, Step: 150/250, Loss: 0.5292, Accuracy: 97.96\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0202)\n",
      "(3, 100.0000, 0.0093)\n",
      "(4, 100.0000, 0.0041)\n",
      "(5, 100.0000, 0.0262)\n",
      "(6, 100.0000, 0.0142)\n",
      "(7, 100.0000, 0.0087)\n",
      "(8, 100.0000, 0.0106)\n",
      "(9, 100.0000, 0.0271)\n",
      "(10, 100.0000, 0.0180)\n",
      "(11, 100.0000, 0.0188)\n",
      "(12, 100.0000, 0.0141)\n",
      "(13, 100.0000, 0.0216)\n",
      "(14, 100.0000, 0.0205)\n",
      "(15, 100.0000, 0.0201)\n",
      "(16, 100.0000, 0.0281)\n",
      "(17, 99.2188, 0.0447)\n",
      "(18, 94.5312, 0.1187)\n",
      "(19, 98.4375, 0.0522)\n",
      "(20, 98.4375, 0.0596)\n",
      "(21, 94.5312, 0.1039)\n",
      "(22, 99.2188, 0.0649)\n",
      "(23, 90.6250, 0.1952)\n",
      "(24, 78.1250, 0.4715)\n",
      "Epoch: 8/20, Step: 175/250, Loss: 0.6257, Accuracy: 98.85\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0109)\n",
      "(3, 100.0000, 0.0083)\n",
      "(4, 100.0000, 0.0061)\n",
      "(5, 100.0000, 0.0091)\n",
      "(6, 100.0000, 0.0088)\n",
      "(7, 100.0000, 0.0097)\n",
      "(8, 100.0000, 0.0095)\n",
      "(9, 100.0000, 0.0110)\n",
      "(10, 100.0000, 0.0102)\n",
      "(11, 100.0000, 0.0109)\n",
      "(12, 100.0000, 0.0092)\n",
      "(13, 99.2188, 0.0336)\n",
      "(14, 100.0000, 0.0082)\n",
      "(15, 100.0000, 0.0159)\n",
      "(16, 100.0000, 0.0110)\n",
      "(17, 100.0000, 0.0123)\n",
      "(18, 99.2188, 0.0288)\n",
      "(19, 100.0000, 0.0289)\n",
      "(20, 99.2188, 0.0260)\n",
      "(21, 97.6562, 0.0521)\n",
      "(22, 97.6562, 0.0680)\n",
      "(23, 96.8750, 0.1315)\n",
      "(24, 83.5938, 0.4481)\n",
      "Epoch: 8/20, Step: 200/250, Loss: 0.7918, Accuracy: 98.91\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0080)\n",
      "(3, 100.0000, 0.0068)\n",
      "(4, 100.0000, 0.0071)\n",
      "(5, 100.0000, 0.0104)\n",
      "(6, 100.0000, 0.0083)\n",
      "(7, 100.0000, 0.0091)\n",
      "(8, 100.0000, 0.0095)\n",
      "(9, 100.0000, 0.0084)\n",
      "(10, 100.0000, 0.0123)\n",
      "(11, 100.0000, 0.0233)\n",
      "(12, 100.0000, 0.0059)\n",
      "(13, 100.0000, 0.0130)\n",
      "(14, 100.0000, 0.0093)\n",
      "(15, 100.0000, 0.0149)\n",
      "(16, 100.0000, 0.0219)\n",
      "(17, 100.0000, 0.0183)\n",
      "(18, 100.0000, 0.0139)\n",
      "(19, 99.2188, 0.0296)\n",
      "(20, 99.2188, 0.0352)\n",
      "(21, 97.6562, 0.0727)\n",
      "(22, 98.4375, 0.0585)\n",
      "(23, 96.0937, 0.1397)\n",
      "(24, 84.3750, 0.3661)\n",
      "Epoch: 8/20, Step: 225/250, Loss: 0.3788, Accuracy: 98.78\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0084)\n",
      "(3, 100.0000, 0.0039)\n",
      "(4, 100.0000, 0.0095)\n",
      "(5, 100.0000, 0.0119)\n",
      "(6, 100.0000, 0.0103)\n",
      "(7, 100.0000, 0.0087)\n",
      "(8, 100.0000, 0.0060)\n",
      "(9, 100.0000, 0.0084)\n",
      "(10, 100.0000, 0.0129)\n",
      "(11, 100.0000, 0.0164)\n",
      "(12, 100.0000, 0.0095)\n",
      "(13, 100.0000, 0.0132)\n",
      "(14, 100.0000, 0.0122)\n",
      "(15, 100.0000, 0.0156)\n",
      "(16, 99.2188, 0.0185)\n",
      "(17, 98.4375, 0.0386)\n",
      "(18, 100.0000, 0.0164)\n",
      "(19, 100.0000, 0.0209)\n",
      "(20, 99.2188, 0.0333)\n",
      "(21, 96.8750, 0.0623)\n",
      "(22, 97.6562, 0.0606)\n",
      "(23, 97.6562, 0.0679)\n",
      "(24, 82.8125, 0.3889)\n",
      "Epoch: 8/20, Step: 250/250, Loss: 0.4843, Accuracy: 98.68\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0075)\n",
      "(3, 100.0000, 0.0050)\n",
      "(4, 100.0000, 0.0066)\n",
      "(5, 100.0000, 0.0068)\n",
      "(6, 100.0000, 0.0062)\n",
      "(7, 100.0000, 0.0052)\n",
      "(8, 100.0000, 0.0065)\n",
      "(9, 100.0000, 0.0062)\n",
      "(10, 100.0000, 0.0102)\n",
      "(11, 99.2188, 0.0214)\n",
      "(12, 100.0000, 0.0164)\n",
      "(13, 100.0000, 0.0144)\n",
      "(14, 100.0000, 0.0097)\n",
      "(15, 100.0000, 0.0144)\n",
      "(16, 100.0000, 0.0347)\n",
      "(17, 99.2188, 0.0346)\n",
      "(18, 100.0000, 0.0229)\n",
      "(19, 100.0000, 0.0250)\n",
      "(20, 100.0000, 0.0317)\n",
      "(21, 96.8750, 0.0617)\n",
      "(22, 96.8750, 0.0968)\n",
      "(23, 96.8750, 0.1118)\n",
      "(24, 80.4688, 0.4650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [08:58<15:32, 77.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/20, Step: 25/250, Loss: 0.7877, Accuracy: 98.81\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0149)\n",
      "(3, 100.0000, 0.0043)\n",
      "(4, 100.0000, 0.0125)\n",
      "(5, 100.0000, 0.0134)\n",
      "(6, 100.0000, 0.0120)\n",
      "(7, 100.0000, 0.0152)\n",
      "(8, 100.0000, 0.0111)\n",
      "(9, 100.0000, 0.0129)\n",
      "(10, 100.0000, 0.0165)\n",
      "(11, 100.0000, 0.0156)\n",
      "(12, 100.0000, 0.0102)\n",
      "(13, 100.0000, 0.0115)\n",
      "(14, 99.2188, 0.0196)\n",
      "(15, 100.0000, 0.0155)\n",
      "(16, 100.0000, 0.0134)\n",
      "(17, 99.2188, 0.0322)\n",
      "(18, 100.0000, 0.0238)\n",
      "(19, 100.0000, 0.0273)\n",
      "(20, 100.0000, 0.0248)\n",
      "(21, 100.0000, 0.0320)\n",
      "(22, 95.3125, 0.1035)\n",
      "(23, 98.4375, 0.0804)\n",
      "(24, 80.4688, 0.4254)\n",
      "Solved N = 23, starting N = 24 + 1\n",
      "Epoch: 9/20, Step: 50/250, Loss: 1.4551, Accuracy: 97.59\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0293)\n",
      "(3, 100.0000, 0.0203)\n",
      "(4, 100.0000, 0.0169)\n",
      "(5, 100.0000, 0.0182)\n",
      "(6, 100.0000, 0.0146)\n",
      "(7, 100.0000, 0.0094)\n",
      "(8, 100.0000, 0.0075)\n",
      "(9, 100.0000, 0.0159)\n",
      "(10, 100.0000, 0.0116)\n",
      "(11, 100.0000, 0.0200)\n",
      "(12, 100.0000, 0.0189)\n",
      "(13, 100.0000, 0.0176)\n",
      "(14, 100.0000, 0.0164)\n",
      "(15, 97.6562, 0.0525)\n",
      "(16, 98.4375, 0.0391)\n",
      "(17, 98.4375, 0.0487)\n",
      "(18, 99.2188, 0.0349)\n",
      "(19, 100.0000, 0.0282)\n",
      "(20, 99.2188, 0.0287)\n",
      "(21, 97.6562, 0.0893)\n",
      "(22, 97.6562, 0.0753)\n",
      "(23, 96.8750, 0.1044)\n",
      "(24, 90.6250, 0.3737)\n",
      "(25, 66.4062, 0.8933)\n",
      "Epoch: 9/20, Step: 75/250, Loss: 0.7149, Accuracy: 98.67\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0284)\n",
      "(3, 100.0000, 0.0294)\n",
      "(4, 100.0000, 0.0119)\n",
      "(5, 100.0000, 0.0180)\n",
      "(6, 100.0000, 0.0089)\n",
      "(7, 100.0000, 0.0114)\n",
      "(8, 100.0000, 0.0115)\n",
      "(9, 100.0000, 0.0076)\n",
      "(10, 100.0000, 0.0119)\n",
      "(11, 100.0000, 0.0230)\n",
      "(12, 100.0000, 0.0115)\n",
      "(13, 100.0000, 0.0181)\n",
      "(14, 100.0000, 0.0115)\n",
      "(15, 100.0000, 0.0246)\n",
      "(16, 99.2188, 0.0220)\n",
      "(17, 98.4375, 0.0489)\n",
      "(18, 99.2188, 0.0312)\n",
      "(19, 98.4375, 0.0390)\n",
      "(20, 100.0000, 0.0228)\n",
      "(21, 98.4375, 0.0360)\n",
      "(22, 96.8750, 0.0596)\n",
      "(23, 98.4375, 0.0762)\n",
      "(24, 92.9688, 0.1372)\n",
      "(25, 85.9375, 0.3698)\n",
      "Epoch: 9/20, Step: 100/250, Loss: 0.7978, Accuracy: 98.60\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0128)\n",
      "(3, 100.0000, 0.0152)\n",
      "(4, 100.0000, 0.0123)\n",
      "(5, 100.0000, 0.0129)\n",
      "(6, 100.0000, 0.0091)\n",
      "(7, 100.0000, 0.0089)\n",
      "(8, 100.0000, 0.0124)\n",
      "(9, 100.0000, 0.0132)\n",
      "(10, 100.0000, 0.0164)\n",
      "(11, 99.2188, 0.0283)\n",
      "(12, 100.0000, 0.0135)\n",
      "(13, 100.0000, 0.0173)\n",
      "(14, 100.0000, 0.0149)\n",
      "(15, 99.2188, 0.0271)\n",
      "(16, 100.0000, 0.0242)\n",
      "(17, 98.4375, 0.0535)\n",
      "(18, 99.2188, 0.0420)\n",
      "(19, 98.4375, 0.0376)\n",
      "(20, 98.4375, 0.0583)\n",
      "(21, 100.0000, 0.0259)\n",
      "(22, 99.2188, 0.0557)\n",
      "(23, 99.2188, 0.0420)\n",
      "(24, 91.4062, 0.1745)\n",
      "(25, 83.5938, 0.3798)\n",
      "Epoch: 9/20, Step: 125/250, Loss: 0.5109, Accuracy: 99.12\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0202)\n",
      "(3, 100.0000, 0.0124)\n",
      "(4, 100.0000, 0.0099)\n",
      "(5, 100.0000, 0.0110)\n",
      "(6, 100.0000, 0.0080)\n",
      "(7, 99.2188, 0.0122)\n",
      "(8, 100.0000, 0.0079)\n",
      "(9, 100.0000, 0.0072)\n",
      "(10, 100.0000, 0.0107)\n",
      "(11, 100.0000, 0.0072)\n",
      "(12, 100.0000, 0.0037)\n",
      "(13, 100.0000, 0.0097)\n",
      "(14, 100.0000, 0.0095)\n",
      "(15, 100.0000, 0.0137)\n",
      "(16, 100.0000, 0.0111)\n",
      "(17, 98.4375, 0.0301)\n",
      "(18, 100.0000, 0.0176)\n",
      "(19, 100.0000, 0.0208)\n",
      "(20, 100.0000, 0.0168)\n",
      "(21, 100.0000, 0.0205)\n",
      "(22, 99.2188, 0.0334)\n",
      "(23, 98.4375, 0.0561)\n",
      "(24, 94.5312, 0.1216)\n",
      "(25, 89.8438, 0.2988)\n",
      "Epoch: 9/20, Step: 150/250, Loss: 0.5851, Accuracy: 98.73\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0320)\n",
      "(3, 100.0000, 0.0119)\n",
      "(4, 100.0000, 0.0108)\n",
      "(5, 100.0000, 0.0129)\n",
      "(6, 100.0000, 0.0173)\n",
      "(7, 100.0000, 0.0134)\n",
      "(8, 100.0000, 0.0100)\n",
      "(9, 100.0000, 0.0072)\n",
      "(10, 100.0000, 0.0127)\n",
      "(11, 100.0000, 0.0165)\n",
      "(12, 99.2188, 0.0199)\n",
      "(13, 100.0000, 0.0141)\n",
      "(14, 100.0000, 0.0144)\n",
      "(15, 100.0000, 0.0148)\n",
      "(16, 99.2188, 0.0228)\n",
      "(17, 99.2188, 0.0422)\n",
      "(18, 98.4375, 0.0309)\n",
      "(19, 99.2188, 0.0385)\n",
      "(20, 100.0000, 0.0319)\n",
      "(21, 99.2188, 0.0588)\n",
      "(22, 98.4375, 0.0449)\n",
      "(23, 95.3125, 0.0954)\n",
      "(24, 93.7500, 0.1253)\n",
      "(25, 87.5000, 0.3500)\n",
      "Epoch: 9/20, Step: 175/250, Loss: 0.4639, Accuracy: 99.12\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0095)\n",
      "(3, 100.0000, 0.0090)\n",
      "(4, 100.0000, 0.0053)\n",
      "(5, 100.0000, 0.0133)\n",
      "(6, 100.0000, 0.0073)\n",
      "(7, 100.0000, 0.0113)\n",
      "(8, 100.0000, 0.0085)\n",
      "(9, 100.0000, 0.0070)\n",
      "(10, 100.0000, 0.0147)\n",
      "(11, 100.0000, 0.0101)\n",
      "(12, 100.0000, 0.0081)\n",
      "(13, 100.0000, 0.0104)\n",
      "(14, 100.0000, 0.0119)\n",
      "(15, 100.0000, 0.0158)\n",
      "(16, 100.0000, 0.0096)\n",
      "(17, 100.0000, 0.0214)\n",
      "(18, 99.2188, 0.0232)\n",
      "(19, 99.2188, 0.0307)\n",
      "(20, 100.0000, 0.0193)\n",
      "(21, 99.2188, 0.0432)\n",
      "(22, 96.8750, 0.0641)\n",
      "(23, 98.4375, 0.0658)\n",
      "(24, 96.8750, 0.1127)\n",
      "(25, 89.0625, 0.3370)\n",
      "Epoch: 9/20, Step: 200/250, Loss: 0.5346, Accuracy: 98.67\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0160)\n",
      "(3, 100.0000, 0.0069)\n",
      "(4, 100.0000, 0.0039)\n",
      "(5, 100.0000, 0.0087)\n",
      "(6, 100.0000, 0.0068)\n",
      "(7, 100.0000, 0.0092)\n",
      "(8, 100.0000, 0.0063)\n",
      "(9, 100.0000, 0.0100)\n",
      "(10, 100.0000, 0.0118)\n",
      "(11, 100.0000, 0.0099)\n",
      "(12, 100.0000, 0.0061)\n",
      "(13, 100.0000, 0.0079)\n",
      "(14, 100.0000, 0.0071)\n",
      "(15, 100.0000, 0.0167)\n",
      "(16, 96.8750, 0.0481)\n",
      "(17, 100.0000, 0.0125)\n",
      "(18, 100.0000, 0.0166)\n",
      "(19, 100.0000, 0.0185)\n",
      "(20, 100.0000, 0.0203)\n",
      "(21, 100.0000, 0.0098)\n",
      "(22, 96.8750, 0.0753)\n",
      "(23, 99.2188, 0.0496)\n",
      "(24, 93.7500, 0.1217)\n",
      "(25, 81.2500, 0.3868)\n",
      "Epoch: 9/20, Step: 225/250, Loss: 0.6892, Accuracy: 98.63\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0174)\n",
      "(3, 100.0000, 0.0090)\n",
      "(4, 99.2188, 0.0148)\n",
      "(5, 100.0000, 0.0126)\n",
      "(6, 100.0000, 0.0153)\n",
      "(7, 100.0000, 0.0101)\n",
      "(8, 100.0000, 0.0137)\n",
      "(9, 100.0000, 0.0140)\n",
      "(10, 100.0000, 0.0108)\n",
      "(11, 100.0000, 0.0181)\n",
      "(12, 100.0000, 0.0103)\n",
      "(13, 100.0000, 0.0093)\n",
      "(14, 100.0000, 0.0079)\n",
      "(15, 100.0000, 0.0244)\n",
      "(16, 97.6562, 0.0550)\n",
      "(17, 100.0000, 0.0251)\n",
      "(18, 99.2188, 0.0282)\n",
      "(19, 100.0000, 0.0196)\n",
      "(20, 99.2188, 0.0319)\n",
      "(21, 97.6562, 0.0452)\n",
      "(22, 99.2188, 0.0593)\n",
      "(23, 100.0000, 0.0585)\n",
      "(24, 97.6562, 0.0987)\n",
      "(25, 77.3438, 0.4943)\n",
      "Epoch: 9/20, Step: 250/250, Loss: 0.3899, Accuracy: 98.70\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0064)\n",
      "(3, 100.0000, 0.0060)\n",
      "(4, 100.0000, 0.0066)\n",
      "(5, 100.0000, 0.0088)\n",
      "(6, 100.0000, 0.0076)\n",
      "(7, 100.0000, 0.0118)\n",
      "(8, 100.0000, 0.0120)\n",
      "(9, 100.0000, 0.0080)\n",
      "(10, 100.0000, 0.0106)\n",
      "(11, 100.0000, 0.0097)\n",
      "(12, 100.0000, 0.0127)\n",
      "(13, 100.0000, 0.0106)\n",
      "(14, 100.0000, 0.0057)\n",
      "(15, 100.0000, 0.0047)\n",
      "(16, 100.0000, 0.0119)\n",
      "(17, 99.2188, 0.0353)\n",
      "(18, 100.0000, 0.0144)\n",
      "(19, 99.2188, 0.0486)\n",
      "(20, 98.4375, 0.0555)\n",
      "(21, 97.6562, 0.0586)\n",
      "(22, 94.5312, 0.0905)\n",
      "(23, 98.4375, 0.0701)\n",
      "(24, 95.3125, 0.1459)\n",
      "(25, 85.9375, 0.3273)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [10:29<14:59, 81.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/20, Step: 25/250, Loss: 0.5855, Accuracy: 98.54\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0039)\n",
      "(3, 100.0000, 0.0063)\n",
      "(4, 99.2188, 0.0137)\n",
      "(5, 99.2188, 0.0235)\n",
      "(6, 100.0000, 0.0070)\n",
      "(7, 100.0000, 0.0179)\n",
      "(8, 100.0000, 0.0043)\n",
      "(9, 100.0000, 0.0072)\n",
      "(10, 100.0000, 0.0129)\n",
      "(11, 100.0000, 0.0097)\n",
      "(12, 100.0000, 0.0076)\n",
      "(13, 100.0000, 0.0096)\n",
      "(14, 100.0000, 0.0051)\n",
      "(15, 100.0000, 0.0190)\n",
      "(16, 100.0000, 0.0190)\n",
      "(17, 99.2188, 0.0400)\n",
      "(18, 100.0000, 0.0218)\n",
      "(19, 98.4375, 0.0549)\n",
      "(20, 98.4375, 0.0513)\n",
      "(21, 95.3125, 0.1035)\n",
      "(22, 99.2188, 0.0652)\n",
      "(23, 96.0938, 0.1014)\n",
      "(24, 96.8750, 0.0937)\n",
      "(25, 82.8125, 0.3918)\n",
      "Epoch: 10/20, Step: 50/250, Loss: 0.7299, Accuracy: 98.47\n",
      "(N, accuracy, loss):\n",
      "(2, 98.4375, 0.0384)\n",
      "(3, 100.0000, 0.0091)\n",
      "(4, 96.0938, 0.0810)\n",
      "(5, 100.0000, 0.0163)\n",
      "(6, 100.0000, 0.0148)\n",
      "(7, 100.0000, 0.0091)\n",
      "(8, 100.0000, 0.0133)\n",
      "(9, 100.0000, 0.0047)\n",
      "(10, 100.0000, 0.0092)\n",
      "(11, 99.2188, 0.0229)\n",
      "(12, 100.0000, 0.0070)\n",
      "(13, 100.0000, 0.0121)\n",
      "(14, 100.0000, 0.0038)\n",
      "(15, 98.4375, 0.0404)\n",
      "(16, 99.2188, 0.0226)\n",
      "(17, 100.0000, 0.0161)\n",
      "(18, 100.0000, 0.0117)\n",
      "(19, 99.2188, 0.0325)\n",
      "(20, 99.2188, 0.0291)\n",
      "(21, 100.0000, 0.0157)\n",
      "(22, 100.0000, 0.0196)\n",
      "(23, 96.8750, 0.0968)\n",
      "(24, 92.9688, 0.2234)\n",
      "(25, 83.5938, 0.3908)\n",
      "Epoch: 10/20, Step: 75/250, Loss: 0.7036, Accuracy: 98.40\n",
      "(N, accuracy, loss):\n",
      "(2, 98.4375, 0.0318)\n",
      "(3, 100.0000, 0.0091)\n",
      "(4, 99.2188, 0.0235)\n",
      "(5, 100.0000, 0.0148)\n",
      "(6, 100.0000, 0.0156)\n",
      "(7, 100.0000, 0.0096)\n",
      "(8, 100.0000, 0.0107)\n",
      "(9, 100.0000, 0.0070)\n",
      "(10, 99.2188, 0.0185)\n",
      "(11, 100.0000, 0.0170)\n",
      "(12, 100.0000, 0.0103)\n",
      "(13, 100.0000, 0.0110)\n",
      "(14, 99.2188, 0.0236)\n",
      "(15, 99.2188, 0.0118)\n",
      "(16, 100.0000, 0.0191)\n",
      "(17, 99.2188, 0.0463)\n",
      "(18, 98.4375, 0.0599)\n",
      "(19, 97.6562, 0.0459)\n",
      "(20, 98.4375, 0.0471)\n",
      "(21, 98.4375, 0.0766)\n",
      "(22, 100.0000, 0.0355)\n",
      "(23, 96.0938, 0.1071)\n",
      "(24, 96.0938, 0.1185)\n",
      "(25, 82.0312, 0.4194)\n",
      "Epoch: 10/20, Step: 100/250, Loss: 0.5484, Accuracy: 98.99\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0089)\n",
      "(3, 100.0000, 0.0131)\n",
      "(4, 100.0000, 0.0066)\n",
      "(5, 100.0000, 0.0108)\n",
      "(6, 100.0000, 0.0073)\n",
      "(7, 100.0000, 0.0089)\n",
      "(8, 100.0000, 0.0082)\n",
      "(9, 100.0000, 0.0091)\n",
      "(10, 100.0000, 0.0071)\n",
      "(11, 100.0000, 0.0112)\n",
      "(12, 100.0000, 0.0095)\n",
      "(13, 100.0000, 0.0056)\n",
      "(14, 100.0000, 0.0116)\n",
      "(15, 97.6562, 0.0470)\n",
      "(16, 100.0000, 0.0184)\n",
      "(17, 100.0000, 0.0135)\n",
      "(18, 99.2188, 0.0295)\n",
      "(19, 100.0000, 0.0255)\n",
      "(20, 99.2188, 0.0305)\n",
      "(21, 98.4375, 0.0345)\n",
      "(22, 100.0000, 0.0277)\n",
      "(23, 100.0000, 0.0398)\n",
      "(24, 98.4375, 0.0471)\n",
      "(25, 82.8125, 0.3636)\n",
      "Solved N = 24, starting N = 25 + 1\n",
      "Epoch: 10/20, Step: 125/250, Loss: 0.7291, Accuracy: 97.56\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0167)\n",
      "(3, 99.2188, 0.0181)\n",
      "(4, 100.0000, 0.0136)\n",
      "(5, 100.0000, 0.0149)\n",
      "(6, 100.0000, 0.0147)\n",
      "(7, 100.0000, 0.0165)\n",
      "(8, 100.0000, 0.0173)\n",
      "(9, 100.0000, 0.0117)\n",
      "(10, 100.0000, 0.0111)\n",
      "(11, 100.0000, 0.0152)\n",
      "(12, 100.0000, 0.0227)\n",
      "(13, 100.0000, 0.0168)\n",
      "(14, 100.0000, 0.0160)\n",
      "(15, 100.0000, 0.0345)\n",
      "(16, 100.0000, 0.0219)\n",
      "(17, 100.0000, 0.0278)\n",
      "(18, 99.2188, 0.0269)\n",
      "(19, 100.0000, 0.0302)\n",
      "(20, 100.0000, 0.0294)\n",
      "(21, 98.4375, 0.0564)\n",
      "(22, 99.2188, 0.0552)\n",
      "(23, 98.4375, 0.0601)\n",
      "(24, 98.4375, 0.0835)\n",
      "(25, 85.9375, 0.2564)\n",
      "(26, 60.1562, 0.9893)\n",
      "Epoch: 10/20, Step: 150/250, Loss: 0.8573, Accuracy: 97.34\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0167)\n",
      "(3, 100.0000, 0.0145)\n",
      "(4, 100.0000, 0.0085)\n",
      "(5, 100.0000, 0.0186)\n",
      "(6, 100.0000, 0.0157)\n",
      "(7, 100.0000, 0.0090)\n",
      "(8, 100.0000, 0.0168)\n",
      "(9, 100.0000, 0.0157)\n",
      "(10, 100.0000, 0.0134)\n",
      "(11, 100.0000, 0.0134)\n",
      "(12, 100.0000, 0.0139)\n",
      "(13, 100.0000, 0.0125)\n",
      "(14, 100.0000, 0.0193)\n",
      "(15, 96.8750, 0.0742)\n",
      "(16, 100.0000, 0.0170)\n",
      "(17, 99.2188, 0.0363)\n",
      "(18, 99.2188, 0.0345)\n",
      "(19, 100.0000, 0.0203)\n",
      "(20, 98.4375, 0.0397)\n",
      "(21, 98.4375, 0.0409)\n",
      "(22, 96.0938, 0.0666)\n",
      "(23, 98.4375, 0.0651)\n",
      "(24, 92.1875, 0.1319)\n",
      "(25, 89.0625, 0.2173)\n",
      "(26, 66.4062, 0.6296)\n",
      "Epoch: 10/20, Step: 175/250, Loss: 0.6384, Accuracy: 98.47\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0154)\n",
      "(3, 100.0000, 0.0109)\n",
      "(4, 100.0000, 0.0075)\n",
      "(5, 100.0000, 0.0095)\n",
      "(6, 100.0000, 0.0094)\n",
      "(7, 100.0000, 0.0083)\n",
      "(8, 100.0000, 0.0095)\n",
      "(9, 100.0000, 0.0064)\n",
      "(10, 99.2188, 0.0214)\n",
      "(11, 100.0000, 0.0081)\n",
      "(12, 100.0000, 0.0189)\n",
      "(13, 99.2188, 0.0281)\n",
      "(14, 99.2188, 0.0235)\n",
      "(15, 99.2188, 0.0380)\n",
      "(16, 100.0000, 0.0140)\n",
      "(17, 99.2188, 0.0220)\n",
      "(18, 99.2188, 0.0206)\n",
      "(19, 99.2188, 0.0275)\n",
      "(20, 100.0000, 0.0260)\n",
      "(21, 99.2188, 0.0422)\n",
      "(22, 100.0000, 0.0309)\n",
      "(23, 98.4375, 0.0719)\n",
      "(24, 96.8750, 0.0677)\n",
      "(25, 94.5312, 0.1752)\n",
      "(26, 78.1250, 0.4545)\n",
      "Epoch: 10/20, Step: 200/250, Loss: 0.8753, Accuracy: 98.16\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0328)\n",
      "(3, 100.0000, 0.0090)\n",
      "(4, 100.0000, 0.0074)\n",
      "(5, 100.0000, 0.0076)\n",
      "(6, 100.0000, 0.0060)\n",
      "(7, 100.0000, 0.0072)\n",
      "(8, 100.0000, 0.0060)\n",
      "(9, 100.0000, 0.0080)\n",
      "(10, 100.0000, 0.0116)\n",
      "(11, 100.0000, 0.0068)\n",
      "(12, 100.0000, 0.0107)\n",
      "(13, 100.0000, 0.0058)\n",
      "(14, 100.0000, 0.0048)\n",
      "(15, 100.0000, 0.0133)\n",
      "(16, 100.0000, 0.0227)\n",
      "(17, 99.2188, 0.0201)\n",
      "(18, 100.0000, 0.0123)\n",
      "(19, 100.0000, 0.0218)\n",
      "(20, 100.0000, 0.0192)\n",
      "(21, 99.2188, 0.0320)\n",
      "(22, 99.2188, 0.0289)\n",
      "(23, 100.0000, 0.0285)\n",
      "(24, 97.6562, 0.0922)\n",
      "(25, 87.5000, 0.2830)\n",
      "(26, 71.8750, 0.6133)\n",
      "Epoch: 10/20, Step: 225/250, Loss: 0.9397, Accuracy: 97.66\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0148)\n",
      "(3, 100.0000, 0.0080)\n",
      "(4, 100.0000, 0.0128)\n",
      "(5, 100.0000, 0.0113)\n",
      "(6, 100.0000, 0.0055)\n",
      "(7, 100.0000, 0.0083)\n",
      "(8, 100.0000, 0.0059)\n",
      "(9, 100.0000, 0.0027)\n",
      "(10, 100.0000, 0.0188)\n",
      "(11, 100.0000, 0.0061)\n",
      "(12, 100.0000, 0.0029)\n",
      "(13, 100.0000, 0.0117)\n",
      "(14, 100.0000, 0.0070)\n",
      "(15, 100.0000, 0.0132)\n",
      "(16, 100.0000, 0.0136)\n",
      "(17, 100.0000, 0.0126)\n",
      "(18, 100.0000, 0.0144)\n",
      "(19, 98.4375, 0.0550)\n",
      "(20, 100.0000, 0.0225)\n",
      "(21, 99.2188, 0.0381)\n",
      "(22, 99.2188, 0.0474)\n",
      "(23, 97.6562, 0.1005)\n",
      "(24, 96.8750, 0.0933)\n",
      "(25, 91.4062, 0.2092)\n",
      "(26, 58.5938, 1.0229)\n",
      "Epoch: 10/20, Step: 250/250, Loss: 0.6034, Accuracy: 98.00\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0085)\n",
      "(3, 100.0000, 0.0047)\n",
      "(4, 100.0000, 0.0052)\n",
      "(5, 100.0000, 0.0058)\n",
      "(6, 100.0000, 0.0182)\n",
      "(7, 100.0000, 0.0071)\n",
      "(8, 100.0000, 0.0086)\n",
      "(9, 100.0000, 0.0079)\n",
      "(10, 100.0000, 0.0073)\n",
      "(11, 100.0000, 0.0079)\n",
      "(12, 98.4375, 0.0279)\n",
      "(13, 100.0000, 0.0118)\n",
      "(14, 99.2188, 0.0148)\n",
      "(15, 100.0000, 0.0250)\n",
      "(16, 99.2188, 0.0214)\n",
      "(17, 100.0000, 0.0165)\n",
      "(18, 100.0000, 0.0212)\n",
      "(19, 99.2188, 0.0248)\n",
      "(20, 99.2188, 0.0248)\n",
      "(21, 100.0000, 0.0152)\n",
      "(22, 99.2188, 0.0272)\n",
      "(23, 96.8750, 0.0517)\n",
      "(24, 96.0938, 0.1042)\n",
      "(25, 95.3125, 0.1528)\n",
      "(26, 67.1875, 0.7573)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [12:01<14:10, 85.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/20, Step: 25/250, Loss: 0.7269, Accuracy: 98.16\n",
      "(N, accuracy, loss):\n",
      "(2, 96.8750, 0.0595)\n",
      "(3, 100.0000, 0.0119)\n",
      "(4, 100.0000, 0.0091)\n",
      "(5, 100.0000, 0.0184)\n",
      "(6, 100.0000, 0.0135)\n",
      "(7, 100.0000, 0.0134)\n",
      "(8, 100.0000, 0.0211)\n",
      "(9, 99.2188, 0.0240)\n",
      "(10, 100.0000, 0.0239)\n",
      "(11, 100.0000, 0.0135)\n",
      "(12, 99.2188, 0.0310)\n",
      "(13, 99.2188, 0.0182)\n",
      "(14, 100.0000, 0.0089)\n",
      "(15, 99.2188, 0.0349)\n",
      "(16, 100.0000, 0.0169)\n",
      "(17, 97.6562, 0.0458)\n",
      "(18, 99.2188, 0.0172)\n",
      "(19, 100.0000, 0.0094)\n",
      "(20, 99.2188, 0.0234)\n",
      "(21, 96.8750, 0.0772)\n",
      "(22, 99.2188, 0.0369)\n",
      "(23, 98.4375, 0.0500)\n",
      "(24, 96.8750, 0.1184)\n",
      "(25, 96.0938, 0.1024)\n",
      "(26, 76.5625, 0.5027)\n",
      "Epoch: 11/20, Step: 50/250, Loss: 0.8347, Accuracy: 96.94\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0129)\n",
      "(3, 100.0000, 0.0120)\n",
      "(4, 100.0000, 0.0125)\n",
      "(5, 100.0000, 0.0193)\n",
      "(6, 100.0000, 0.0105)\n",
      "(7, 100.0000, 0.0116)\n",
      "(8, 100.0000, 0.0070)\n",
      "(9, 100.0000, 0.0164)\n",
      "(10, 100.0000, 0.0121)\n",
      "(11, 100.0000, 0.0077)\n",
      "(12, 98.4375, 0.0265)\n",
      "(13, 100.0000, 0.0120)\n",
      "(14, 98.4375, 0.0288)\n",
      "(15, 99.2188, 0.0202)\n",
      "(16, 98.4375, 0.0286)\n",
      "(17, 99.2188, 0.0424)\n",
      "(18, 97.6562, 0.0448)\n",
      "(19, 100.0000, 0.0376)\n",
      "(20, 98.4375, 0.0588)\n",
      "(21, 96.8750, 0.0820)\n",
      "(22, 97.6562, 0.0747)\n",
      "(23, 94.5312, 0.1411)\n",
      "(24, 91.4062, 0.1885)\n",
      "(25, 86.7188, 0.2807)\n",
      "(26, 66.4062, 0.5985)\n",
      "Epoch: 11/20, Step: 75/250, Loss: 0.4930, Accuracy: 98.75\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0275)\n",
      "(3, 100.0000, 0.0118)\n",
      "(4, 100.0000, 0.0071)\n",
      "(5, 99.2188, 0.0236)\n",
      "(6, 100.0000, 0.0091)\n",
      "(7, 100.0000, 0.0047)\n",
      "(8, 100.0000, 0.0045)\n",
      "(9, 100.0000, 0.0094)\n",
      "(10, 100.0000, 0.0063)\n",
      "(11, 100.0000, 0.0042)\n",
      "(12, 100.0000, 0.0092)\n",
      "(13, 100.0000, 0.0053)\n",
      "(14, 100.0000, 0.0038)\n",
      "(15, 100.0000, 0.0052)\n",
      "(16, 100.0000, 0.0112)\n",
      "(17, 100.0000, 0.0072)\n",
      "(18, 100.0000, 0.0151)\n",
      "(19, 100.0000, 0.0110)\n",
      "(20, 100.0000, 0.0100)\n",
      "(21, 100.0000, 0.0166)\n",
      "(22, 98.4375, 0.0509)\n",
      "(23, 99.2188, 0.0209)\n",
      "(24, 98.4375, 0.0599)\n",
      "(25, 98.4375, 0.0624)\n",
      "(26, 75.7812, 0.4379)\n",
      "Solved N = 25, starting N = 26 + 1\n",
      "Epoch: 11/20, Step: 100/250, Loss: 1.3595, Accuracy: 97.18\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0204)\n",
      "(3, 100.0000, 0.0101)\n",
      "(4, 100.0000, 0.0060)\n",
      "(5, 100.0000, 0.0145)\n",
      "(6, 100.0000, 0.0143)\n",
      "(7, 100.0000, 0.0148)\n",
      "(8, 100.0000, 0.0094)\n",
      "(9, 100.0000, 0.0082)\n",
      "(10, 100.0000, 0.0107)\n",
      "(11, 100.0000, 0.0097)\n",
      "(12, 100.0000, 0.0123)\n",
      "(13, 99.2188, 0.0175)\n",
      "(14, 100.0000, 0.0103)\n",
      "(15, 98.4375, 0.0322)\n",
      "(16, 100.0000, 0.0107)\n",
      "(17, 98.4375, 0.0330)\n",
      "(18, 100.0000, 0.0139)\n",
      "(19, 100.0000, 0.0211)\n",
      "(20, 96.0938, 0.0803)\n",
      "(21, 100.0000, 0.0219)\n",
      "(22, 98.4375, 0.0460)\n",
      "(23, 98.4375, 0.0749)\n",
      "(24, 98.4375, 0.0667)\n",
      "(25, 94.5312, 0.1282)\n",
      "(26, 89.0625, 0.2217)\n",
      "(27, 55.4688, 0.9470)\n",
      "Epoch: 11/20, Step: 125/250, Loss: 1.0152, Accuracy: 97.69\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0209)\n",
      "(3, 100.0000, 0.0081)\n",
      "(4, 100.0000, 0.0043)\n",
      "(5, 100.0000, 0.0096)\n",
      "(6, 100.0000, 0.0086)\n",
      "(7, 100.0000, 0.0125)\n",
      "(8, 100.0000, 0.0083)\n",
      "(9, 100.0000, 0.0097)\n",
      "(10, 100.0000, 0.0118)\n",
      "(11, 100.0000, 0.0114)\n",
      "(12, 100.0000, 0.0126)\n",
      "(13, 100.0000, 0.0178)\n",
      "(14, 100.0000, 0.0156)\n",
      "(15, 100.0000, 0.0110)\n",
      "(16, 100.0000, 0.0181)\n",
      "(17, 100.0000, 0.0194)\n",
      "(18, 100.0000, 0.0250)\n",
      "(19, 100.0000, 0.0452)\n",
      "(20, 99.2188, 0.0476)\n",
      "(21, 96.0938, 0.0920)\n",
      "(22, 97.6562, 0.0661)\n",
      "(23, 97.6562, 0.0879)\n",
      "(24, 96.8750, 0.0917)\n",
      "(25, 94.5312, 0.0964)\n",
      "(26, 82.0312, 0.4184)\n",
      "(27, 75.7812, 0.5187)\n",
      "Epoch: 11/20, Step: 150/250, Loss: 0.9884, Accuracy: 98.14\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0189)\n",
      "(3, 100.0000, 0.0212)\n",
      "(4, 100.0000, 0.0065)\n",
      "(5, 100.0000, 0.0127)\n",
      "(6, 100.0000, 0.0170)\n",
      "(7, 100.0000, 0.0104)\n",
      "(8, 100.0000, 0.0148)\n",
      "(9, 100.0000, 0.0128)\n",
      "(10, 100.0000, 0.0171)\n",
      "(11, 99.2188, 0.0274)\n",
      "(12, 100.0000, 0.0149)\n",
      "(13, 100.0000, 0.0091)\n",
      "(14, 100.0000, 0.0194)\n",
      "(15, 99.2188, 0.0210)\n",
      "(16, 100.0000, 0.0160)\n",
      "(17, 100.0000, 0.0157)\n",
      "(18, 99.2188, 0.0277)\n",
      "(19, 100.0000, 0.0131)\n",
      "(20, 98.4375, 0.0551)\n",
      "(21, 99.2188, 0.0322)\n",
      "(22, 99.2188, 0.0509)\n",
      "(23, 98.4375, 0.0497)\n",
      "(24, 96.8750, 0.0578)\n",
      "(25, 93.7500, 0.1373)\n",
      "(26, 88.2812, 0.3127)\n",
      "(27, 79.6875, 0.4861)\n",
      "Epoch: 11/20, Step: 175/250, Loss: 0.6664, Accuracy: 98.53\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0174)\n",
      "(3, 100.0000, 0.0094)\n",
      "(4, 100.0000, 0.0212)\n",
      "(5, 100.0000, 0.0118)\n",
      "(6, 100.0000, 0.0076)\n",
      "(7, 100.0000, 0.0067)\n",
      "(8, 100.0000, 0.0081)\n",
      "(9, 99.2188, 0.0161)\n",
      "(10, 100.0000, 0.0125)\n",
      "(11, 100.0000, 0.0100)\n",
      "(12, 99.2188, 0.0170)\n",
      "(13, 100.0000, 0.0078)\n",
      "(14, 100.0000, 0.0145)\n",
      "(15, 100.0000, 0.0170)\n",
      "(16, 100.0000, 0.0071)\n",
      "(17, 100.0000, 0.0074)\n",
      "(18, 100.0000, 0.0106)\n",
      "(19, 100.0000, 0.0130)\n",
      "(20, 100.0000, 0.0174)\n",
      "(21, 100.0000, 0.0179)\n",
      "(22, 100.0000, 0.0287)\n",
      "(23, 99.2188, 0.0312)\n",
      "(24, 94.5312, 0.0892)\n",
      "(25, 94.5312, 0.0984)\n",
      "(26, 94.5312, 0.1635)\n",
      "(27, 81.2500, 0.4605)\n",
      "Epoch: 11/20, Step: 200/250, Loss: 0.7010, Accuracy: 98.86\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0142)\n",
      "(3, 100.0000, 0.0070)\n",
      "(4, 100.0000, 0.0161)\n",
      "(5, 100.0000, 0.0090)\n",
      "(6, 100.0000, 0.0121)\n",
      "(7, 100.0000, 0.0141)\n",
      "(8, 100.0000, 0.0081)\n",
      "(9, 100.0000, 0.0091)\n",
      "(10, 100.0000, 0.0053)\n",
      "(11, 100.0000, 0.0121)\n",
      "(12, 100.0000, 0.0136)\n",
      "(13, 100.0000, 0.0134)\n",
      "(14, 100.0000, 0.0073)\n",
      "(15, 100.0000, 0.0116)\n",
      "(16, 100.0000, 0.0092)\n",
      "(17, 100.0000, 0.0110)\n",
      "(18, 100.0000, 0.0116)\n",
      "(19, 100.0000, 0.0133)\n",
      "(20, 99.2188, 0.0375)\n",
      "(21, 100.0000, 0.0288)\n",
      "(22, 100.0000, 0.0259)\n",
      "(23, 100.0000, 0.0384)\n",
      "(24, 97.6562, 0.0875)\n",
      "(25, 99.2188, 0.0415)\n",
      "(26, 96.8750, 0.1046)\n",
      "(27, 77.3438, 0.4312)\n",
      "Epoch: 11/20, Step: 225/250, Loss: 0.7557, Accuracy: 98.53\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0197)\n",
      "(3, 100.0000, 0.0079)\n",
      "(4, 100.0000, 0.0205)\n",
      "(5, 100.0000, 0.0179)\n",
      "(6, 100.0000, 0.0091)\n",
      "(7, 100.0000, 0.0132)\n",
      "(8, 100.0000, 0.0119)\n",
      "(9, 100.0000, 0.0140)\n",
      "(10, 100.0000, 0.0110)\n",
      "(11, 100.0000, 0.0189)\n",
      "(12, 100.0000, 0.0095)\n",
      "(13, 100.0000, 0.0186)\n",
      "(14, 100.0000, 0.0075)\n",
      "(15, 100.0000, 0.0136)\n",
      "(16, 99.2188, 0.0259)\n",
      "(17, 99.2188, 0.0242)\n",
      "(18, 100.0000, 0.0063)\n",
      "(19, 100.0000, 0.0176)\n",
      "(20, 97.6562, 0.0864)\n",
      "(21, 99.2188, 0.0288)\n",
      "(22, 96.0938, 0.0639)\n",
      "(23, 99.2188, 0.0429)\n",
      "(24, 97.6562, 0.0646)\n",
      "(25, 99.2188, 0.0370)\n",
      "(26, 93.7500, 0.1935)\n",
      "(27, 80.4688, 0.4273)\n",
      "Epoch: 11/20, Step: 250/250, Loss: 0.9432, Accuracy: 98.77\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0135)\n",
      "(3, 100.0000, 0.0094)\n",
      "(4, 100.0000, 0.0079)\n",
      "(5, 100.0000, 0.0079)\n",
      "(6, 100.0000, 0.0121)\n",
      "(7, 100.0000, 0.0094)\n",
      "(8, 100.0000, 0.0097)\n",
      "(9, 100.0000, 0.0099)\n",
      "(10, 100.0000, 0.0046)\n",
      "(11, 100.0000, 0.0117)\n",
      "(12, 100.0000, 0.0084)\n",
      "(13, 100.0000, 0.0118)\n",
      "(14, 100.0000, 0.0129)\n",
      "(15, 100.0000, 0.0194)\n",
      "(16, 100.0000, 0.0127)\n",
      "(17, 100.0000, 0.0193)\n",
      "(18, 99.2188, 0.0317)\n",
      "(19, 97.6562, 0.0725)\n",
      "(20, 99.2188, 0.0445)\n",
      "(21, 99.2188, 0.0324)\n",
      "(22, 100.0000, 0.0576)\n",
      "(23, 100.0000, 0.0321)\n",
      "(24, 100.0000, 0.0501)\n",
      "(25, 97.6562, 0.0820)\n",
      "(26, 93.7500, 0.1690)\n",
      "(27, 81.2500, 0.4382)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [13:35<13:10, 87.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/20, Step: 25/250, Loss: 1.0383, Accuracy: 97.99\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0319)\n",
      "(3, 100.0000, 0.0075)\n",
      "(4, 100.0000, 0.0280)\n",
      "(5, 100.0000, 0.0123)\n",
      "(6, 100.0000, 0.0104)\n",
      "(7, 100.0000, 0.0068)\n",
      "(8, 100.0000, 0.0066)\n",
      "(9, 100.0000, 0.0068)\n",
      "(10, 100.0000, 0.0075)\n",
      "(11, 100.0000, 0.0110)\n",
      "(12, 100.0000, 0.0106)\n",
      "(13, 100.0000, 0.0095)\n",
      "(14, 99.2188, 0.0115)\n",
      "(15, 100.0000, 0.0129)\n",
      "(16, 100.0000, 0.0144)\n",
      "(17, 100.0000, 0.0141)\n",
      "(18, 100.0000, 0.0072)\n",
      "(19, 100.0000, 0.0091)\n",
      "(20, 98.4375, 0.0365)\n",
      "(21, 100.0000, 0.0326)\n",
      "(22, 98.4375, 0.0550)\n",
      "(23, 97.6562, 0.0470)\n",
      "(24, 98.4375, 0.0385)\n",
      "(25, 94.5312, 0.1185)\n",
      "(26, 85.9375, 0.3038)\n",
      "(27, 75.0000, 0.5215)\n",
      "Epoch: 12/20, Step: 50/250, Loss: 0.8250, Accuracy: 98.38\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0249)\n",
      "(3, 100.0000, 0.0127)\n",
      "(4, 100.0000, 0.0054)\n",
      "(5, 100.0000, 0.0119)\n",
      "(6, 100.0000, 0.0125)\n",
      "(7, 100.0000, 0.0142)\n",
      "(8, 100.0000, 0.0080)\n",
      "(9, 100.0000, 0.0104)\n",
      "(10, 100.0000, 0.0035)\n",
      "(11, 100.0000, 0.0093)\n",
      "(12, 100.0000, 0.0157)\n",
      "(13, 100.0000, 0.0048)\n",
      "(14, 100.0000, 0.0244)\n",
      "(15, 100.0000, 0.0055)\n",
      "(16, 100.0000, 0.0075)\n",
      "(17, 100.0000, 0.0088)\n",
      "(18, 100.0000, 0.0082)\n",
      "(19, 99.2188, 0.0354)\n",
      "(20, 98.4375, 0.0765)\n",
      "(21, 97.6562, 0.0538)\n",
      "(22, 97.6562, 0.0489)\n",
      "(23, 98.4375, 0.0369)\n",
      "(24, 99.2188, 0.0374)\n",
      "(25, 99.2188, 0.0530)\n",
      "(26, 92.1875, 0.2151)\n",
      "(27, 76.5625, 0.4895)\n",
      "Epoch: 12/20, Step: 75/250, Loss: 0.6548, Accuracy: 99.25\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0117)\n",
      "(3, 100.0000, 0.0094)\n",
      "(4, 99.2188, 0.0114)\n",
      "(5, 100.0000, 0.0172)\n",
      "(6, 100.0000, 0.0093)\n",
      "(7, 100.0000, 0.0078)\n",
      "(8, 100.0000, 0.0127)\n",
      "(9, 100.0000, 0.0038)\n",
      "(10, 100.0000, 0.0027)\n",
      "(11, 100.0000, 0.0111)\n",
      "(12, 100.0000, 0.0050)\n",
      "(13, 100.0000, 0.0084)\n",
      "(14, 100.0000, 0.0072)\n",
      "(15, 100.0000, 0.0065)\n",
      "(16, 100.0000, 0.0100)\n",
      "(17, 100.0000, 0.0108)\n",
      "(18, 100.0000, 0.0071)\n",
      "(19, 100.0000, 0.0128)\n",
      "(20, 100.0000, 0.0180)\n",
      "(21, 99.2188, 0.0250)\n",
      "(22, 100.0000, 0.0232)\n",
      "(23, 100.0000, 0.0200)\n",
      "(24, 99.2188, 0.0246)\n",
      "(25, 99.2188, 0.0407)\n",
      "(26, 96.0938, 0.1009)\n",
      "(27, 87.5000, 0.3203)\n",
      "Epoch: 12/20, Step: 100/250, Loss: 0.7418, Accuracy: 98.59\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0141)\n",
      "(3, 100.0000, 0.0080)\n",
      "(4, 99.2188, 0.0413)\n",
      "(5, 100.0000, 0.0176)\n",
      "(6, 100.0000, 0.0091)\n",
      "(7, 100.0000, 0.0155)\n",
      "(8, 100.0000, 0.0059)\n",
      "(9, 100.0000, 0.0027)\n",
      "(10, 100.0000, 0.0142)\n",
      "(11, 100.0000, 0.0131)\n",
      "(12, 100.0000, 0.0087)\n",
      "(13, 100.0000, 0.0129)\n",
      "(14, 100.0000, 0.0080)\n",
      "(15, 99.2188, 0.0349)\n",
      "(16, 100.0000, 0.0099)\n",
      "(17, 100.0000, 0.0158)\n",
      "(18, 99.2188, 0.0180)\n",
      "(19, 97.6562, 0.0470)\n",
      "(20, 100.0000, 0.0156)\n",
      "(21, 93.7500, 0.1648)\n",
      "(22, 99.2188, 0.0238)\n",
      "(23, 98.4375, 0.0472)\n",
      "(24, 98.4375, 0.0392)\n",
      "(25, 99.2188, 0.0376)\n",
      "(26, 95.3125, 0.1294)\n",
      "(27, 83.5938, 0.4417)\n",
      "Epoch: 12/20, Step: 125/250, Loss: 1.0350, Accuracy: 98.14\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0188)\n",
      "(3, 100.0000, 0.0064)\n",
      "(4, 98.4375, 0.0344)\n",
      "(5, 100.0000, 0.0118)\n",
      "(6, 100.0000, 0.0096)\n",
      "(7, 100.0000, 0.0133)\n",
      "(8, 100.0000, 0.0066)\n",
      "(9, 99.2188, 0.0093)\n",
      "(10, 100.0000, 0.0195)\n",
      "(11, 100.0000, 0.0086)\n",
      "(12, 100.0000, 0.0104)\n",
      "(13, 100.0000, 0.0105)\n",
      "(14, 100.0000, 0.0117)\n",
      "(15, 98.4375, 0.0447)\n",
      "(16, 100.0000, 0.0143)\n",
      "(17, 100.0000, 0.0070)\n",
      "(18, 100.0000, 0.0160)\n",
      "(19, 100.0000, 0.0298)\n",
      "(20, 99.2188, 0.0572)\n",
      "(21, 96.8750, 0.0725)\n",
      "(22, 96.8750, 0.0616)\n",
      "(23, 100.0000, 0.0383)\n",
      "(24, 99.2188, 0.0381)\n",
      "(25, 100.0000, 0.0574)\n",
      "(26, 91.4062, 0.1926)\n",
      "(27, 71.8750, 0.5364)\n",
      "Epoch: 12/20, Step: 150/250, Loss: 0.7297, Accuracy: 98.80\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0288)\n",
      "(3, 100.0000, 0.0105)\n",
      "(4, 100.0000, 0.0065)\n",
      "(5, 100.0000, 0.0124)\n",
      "(6, 100.0000, 0.0083)\n",
      "(7, 100.0000, 0.0100)\n",
      "(8, 100.0000, 0.0153)\n",
      "(9, 100.0000, 0.0026)\n",
      "(10, 100.0000, 0.0102)\n",
      "(11, 100.0000, 0.0075)\n",
      "(12, 100.0000, 0.0075)\n",
      "(13, 100.0000, 0.0100)\n",
      "(14, 100.0000, 0.0073)\n",
      "(15, 99.2188, 0.0185)\n",
      "(16, 100.0000, 0.0090)\n",
      "(17, 100.0000, 0.0119)\n",
      "(18, 100.0000, 0.0146)\n",
      "(19, 100.0000, 0.0096)\n",
      "(20, 100.0000, 0.0215)\n",
      "(21, 100.0000, 0.0144)\n",
      "(22, 100.0000, 0.0142)\n",
      "(23, 100.0000, 0.0382)\n",
      "(24, 95.3125, 0.1007)\n",
      "(25, 96.0938, 0.0859)\n",
      "(26, 96.0938, 0.0984)\n",
      "(27, 82.8125, 0.4229)\n",
      "Epoch: 12/20, Step: 175/250, Loss: 0.6023, Accuracy: 98.14\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0061)\n",
      "(3, 100.0000, 0.0113)\n",
      "(4, 98.4375, 0.0220)\n",
      "(5, 100.0000, 0.0110)\n",
      "(6, 100.0000, 0.0075)\n",
      "(7, 100.0000, 0.0089)\n",
      "(8, 100.0000, 0.0165)\n",
      "(9, 98.4375, 0.0337)\n",
      "(10, 99.2188, 0.0227)\n",
      "(11, 100.0000, 0.0145)\n",
      "(12, 97.6562, 0.0377)\n",
      "(13, 100.0000, 0.0039)\n",
      "(14, 98.4375, 0.0355)\n",
      "(15, 99.2188, 0.0431)\n",
      "(16, 99.2188, 0.0319)\n",
      "(17, 98.4375, 0.0366)\n",
      "(18, 99.2188, 0.0243)\n",
      "(19, 96.8750, 0.0876)\n",
      "(20, 97.6562, 0.0483)\n",
      "(21, 99.2188, 0.0289)\n",
      "(22, 98.4375, 0.0512)\n",
      "(23, 94.5312, 0.1054)\n",
      "(24, 99.2188, 0.0389)\n",
      "(25, 98.4375, 0.0597)\n",
      "(26, 92.9688, 0.2326)\n",
      "(27, 85.9375, 0.3238)\n",
      "Epoch: 12/20, Step: 200/250, Loss: 1.0443, Accuracy: 97.93\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0033)\n",
      "(3, 100.0000, 0.0091)\n",
      "(4, 100.0000, 0.0048)\n",
      "(5, 98.4375, 0.0271)\n",
      "(6, 100.0000, 0.0033)\n",
      "(7, 99.2188, 0.0231)\n",
      "(8, 100.0000, 0.0150)\n",
      "(9, 100.0000, 0.0069)\n",
      "(10, 100.0000, 0.0144)\n",
      "(11, 100.0000, 0.0175)\n",
      "(12, 100.0000, 0.0098)\n",
      "(13, 100.0000, 0.0110)\n",
      "(14, 98.4375, 0.0718)\n",
      "(15, 99.2188, 0.0372)\n",
      "(16, 100.0000, 0.0187)\n",
      "(17, 99.2188, 0.0138)\n",
      "(18, 96.8750, 0.0597)\n",
      "(19, 99.2188, 0.0364)\n",
      "(20, 98.4375, 0.0528)\n",
      "(21, 97.6562, 0.0559)\n",
      "(22, 98.4375, 0.0487)\n",
      "(23, 96.8750, 0.0950)\n",
      "(24, 97.6562, 0.0513)\n",
      "(25, 93.7500, 0.1307)\n",
      "(26, 89.8438, 0.2197)\n",
      "(27, 82.8125, 0.4088)\n",
      "Epoch: 12/20, Step: 225/250, Loss: 0.3898, Accuracy: 98.89\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0215)\n",
      "(3, 100.0000, 0.0054)\n",
      "(4, 100.0000, 0.0041)\n",
      "(5, 100.0000, 0.0190)\n",
      "(6, 100.0000, 0.0086)\n",
      "(7, 100.0000, 0.0103)\n",
      "(8, 100.0000, 0.0055)\n",
      "(9, 100.0000, 0.0097)\n",
      "(10, 100.0000, 0.0049)\n",
      "(11, 100.0000, 0.0121)\n",
      "(12, 100.0000, 0.0056)\n",
      "(13, 99.2188, 0.0157)\n",
      "(14, 100.0000, 0.0190)\n",
      "(15, 100.0000, 0.0133)\n",
      "(16, 100.0000, 0.0034)\n",
      "(17, 100.0000, 0.0108)\n",
      "(18, 99.2188, 0.0265)\n",
      "(19, 100.0000, 0.0113)\n",
      "(20, 100.0000, 0.0152)\n",
      "(21, 99.2188, 0.0488)\n",
      "(22, 100.0000, 0.0078)\n",
      "(23, 97.6562, 0.0870)\n",
      "(24, 98.4375, 0.0533)\n",
      "(25, 98.4375, 0.0436)\n",
      "(26, 98.4375, 0.0803)\n",
      "(27, 81.2500, 0.3892)\n",
      "Solved N = 26, starting N = 27 + 1\n",
      "Epoch: 12/20, Step: 250/250, Loss: 1.1020, Accuracy: 97.69\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0117)\n",
      "(3, 100.0000, 0.0121)\n",
      "(4, 100.0000, 0.0186)\n",
      "(5, 100.0000, 0.0104)\n",
      "(6, 100.0000, 0.0106)\n",
      "(7, 100.0000, 0.0081)\n",
      "(8, 100.0000, 0.0124)\n",
      "(9, 100.0000, 0.0109)\n",
      "(10, 100.0000, 0.0087)\n",
      "(11, 100.0000, 0.0109)\n",
      "(12, 100.0000, 0.0039)\n",
      "(13, 100.0000, 0.0114)\n",
      "(14, 100.0000, 0.0069)\n",
      "(15, 100.0000, 0.0131)\n",
      "(16, 99.2188, 0.0157)\n",
      "(17, 100.0000, 0.0104)\n",
      "(18, 100.0000, 0.0124)\n",
      "(19, 100.0000, 0.0108)\n",
      "(20, 100.0000, 0.0257)\n",
      "(21, 99.2188, 0.0243)\n",
      "(22, 99.2188, 0.0311)\n",
      "(23, 96.0938, 0.0826)\n",
      "(24, 98.4375, 0.0359)\n",
      "(25, 95.3125, 0.0842)\n",
      "(26, 96.8750, 0.0848)\n",
      "(27, 96.0938, 0.1052)\n",
      "(28, 57.0312, 1.3885)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [15:13<12:06, 90.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/20, Step: 25/250, Loss: 1.6772, Accuracy: 97.31\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0348)\n",
      "(3, 97.6562, 0.0450)\n",
      "(4, 99.2188, 0.0342)\n",
      "(5, 100.0000, 0.0225)\n",
      "(6, 99.2188, 0.0168)\n",
      "(7, 100.0000, 0.0068)\n",
      "(8, 100.0000, 0.0172)\n",
      "(9, 99.2188, 0.0283)\n",
      "(10, 100.0000, 0.0155)\n",
      "(11, 100.0000, 0.0071)\n",
      "(12, 99.2188, 0.0160)\n",
      "(13, 99.2188, 0.0258)\n",
      "(14, 99.2188, 0.0178)\n",
      "(15, 99.2188, 0.0242)\n",
      "(16, 97.6562, 0.0708)\n",
      "(17, 100.0000, 0.0127)\n",
      "(18, 100.0000, 0.0114)\n",
      "(19, 100.0000, 0.0272)\n",
      "(20, 100.0000, 0.0193)\n",
      "(21, 99.2188, 0.0421)\n",
      "(22, 99.2188, 0.0443)\n",
      "(23, 98.4375, 0.0662)\n",
      "(24, 97.6562, 0.0724)\n",
      "(25, 90.6250, 0.1880)\n",
      "(26, 94.5312, 0.2078)\n",
      "(27, 88.2812, 0.3349)\n",
      "(28, 69.5312, 0.6375)\n",
      "Epoch: 13/20, Step: 50/250, Loss: 0.7976, Accuracy: 98.87\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0220)\n",
      "(3, 98.4375, 0.0415)\n",
      "(4, 100.0000, 0.0093)\n",
      "(5, 100.0000, 0.0091)\n",
      "(6, 100.0000, 0.0069)\n",
      "(7, 99.2188, 0.0139)\n",
      "(8, 100.0000, 0.0074)\n",
      "(9, 100.0000, 0.0063)\n",
      "(10, 100.0000, 0.0056)\n",
      "(11, 100.0000, 0.0096)\n",
      "(12, 100.0000, 0.0177)\n",
      "(13, 100.0000, 0.0095)\n",
      "(14, 100.0000, 0.0123)\n",
      "(15, 100.0000, 0.0062)\n",
      "(16, 100.0000, 0.0074)\n",
      "(17, 100.0000, 0.0079)\n",
      "(18, 100.0000, 0.0073)\n",
      "(19, 99.2188, 0.0324)\n",
      "(20, 99.2188, 0.0252)\n",
      "(21, 100.0000, 0.0157)\n",
      "(22, 100.0000, 0.0139)\n",
      "(23, 99.2188, 0.0338)\n",
      "(24, 100.0000, 0.0207)\n",
      "(25, 98.4375, 0.0415)\n",
      "(26, 97.6562, 0.0875)\n",
      "(27, 96.8750, 0.0892)\n",
      "(28, 82.0312, 0.3682)\n",
      "Epoch: 13/20, Step: 75/250, Loss: 3.0338, Accuracy: 96.61\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0059)\n",
      "(3, 98.4375, 0.0480)\n",
      "(4, 100.0000, 0.0315)\n",
      "(5, 100.0000, 0.0287)\n",
      "(6, 100.0000, 0.0319)\n",
      "(7, 96.8750, 0.0810)\n",
      "(8, 98.4375, 0.0473)\n",
      "(9, 100.0000, 0.0176)\n",
      "(10, 100.0000, 0.0162)\n",
      "(11, 99.2188, 0.0314)\n",
      "(12, 98.4375, 0.0544)\n",
      "(13, 98.4375, 0.0452)\n",
      "(14, 99.2188, 0.0562)\n",
      "(15, 97.6562, 0.0663)\n",
      "(16, 99.2188, 0.0362)\n",
      "(17, 100.0000, 0.0185)\n",
      "(18, 98.4375, 0.0370)\n",
      "(19, 96.8750, 0.0680)\n",
      "(20, 96.8750, 0.0671)\n",
      "(21, 96.0938, 0.0674)\n",
      "(22, 95.3125, 0.1335)\n",
      "(23, 97.6562, 0.0676)\n",
      "(24, 99.2188, 0.0517)\n",
      "(25, 96.0938, 0.0940)\n",
      "(26, 91.4062, 0.1307)\n",
      "(27, 90.6250, 0.2439)\n",
      "(28, 64.0625, 0.6659)\n",
      "Epoch: 13/20, Step: 100/250, Loss: 2.1136, Accuracy: 97.19\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0078)\n",
      "(3, 100.0000, 0.0168)\n",
      "(4, 100.0000, 0.0072)\n",
      "(5, 100.0000, 0.0174)\n",
      "(6, 99.2188, 0.0239)\n",
      "(7, 100.0000, 0.0123)\n",
      "(8, 100.0000, 0.0075)\n",
      "(9, 100.0000, 0.0113)\n",
      "(10, 100.0000, 0.0101)\n",
      "(11, 98.4375, 0.0447)\n",
      "(12, 99.2188, 0.0451)\n",
      "(13, 97.6562, 0.0683)\n",
      "(14, 100.0000, 0.0245)\n",
      "(15, 100.0000, 0.0103)\n",
      "(16, 100.0000, 0.0218)\n",
      "(17, 100.0000, 0.0224)\n",
      "(18, 99.2188, 0.0243)\n",
      "(19, 99.2188, 0.0399)\n",
      "(20, 97.6562, 0.0460)\n",
      "(21, 100.0000, 0.0279)\n",
      "(22, 97.6562, 0.0822)\n",
      "(23, 94.5312, 0.1281)\n",
      "(24, 96.8750, 0.1077)\n",
      "(25, 97.6562, 0.0733)\n",
      "(26, 91.4062, 0.1693)\n",
      "(27, 82.8125, 0.3500)\n",
      "(28, 72.6562, 0.5080)\n",
      "Epoch: 13/20, Step: 125/250, Loss: 1.0913, Accuracy: 97.25\n",
      "(N, accuracy, loss):\n",
      "(2, 97.6562, 0.0515)\n",
      "(3, 99.2188, 0.0255)\n",
      "(4, 100.0000, 0.0142)\n",
      "(5, 100.0000, 0.0124)\n",
      "(6, 100.0000, 0.0153)\n",
      "(7, 100.0000, 0.0220)\n",
      "(8, 97.6562, 0.0514)\n",
      "(9, 100.0000, 0.0162)\n",
      "(10, 100.0000, 0.0246)\n",
      "(11, 100.0000, 0.0189)\n",
      "(12, 100.0000, 0.0156)\n",
      "(13, 98.4375, 0.0506)\n",
      "(14, 98.4375, 0.0666)\n",
      "(15, 99.2188, 0.0453)\n",
      "(16, 98.4375, 0.0343)\n",
      "(17, 100.0000, 0.0241)\n",
      "(18, 99.2188, 0.0507)\n",
      "(19, 98.4375, 0.0486)\n",
      "(20, 98.4375, 0.0400)\n",
      "(21, 99.2188, 0.0442)\n",
      "(22, 96.8750, 0.0789)\n",
      "(23, 95.3125, 0.1032)\n",
      "(24, 96.8750, 0.0992)\n",
      "(25, 91.4062, 0.1580)\n",
      "(26, 89.8438, 0.2134)\n",
      "(27, 96.0938, 0.1054)\n",
      "(28, 75.0000, 0.5126)\n",
      "Epoch: 13/20, Step: 150/250, Loss: 1.2434, Accuracy: 97.48\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0106)\n",
      "(3, 99.2188, 0.0315)\n",
      "(4, 100.0000, 0.0184)\n",
      "(5, 100.0000, 0.0146)\n",
      "(6, 100.0000, 0.0168)\n",
      "(7, 97.6562, 0.0539)\n",
      "(8, 100.0000, 0.0246)\n",
      "(9, 99.2188, 0.0210)\n",
      "(10, 100.0000, 0.0300)\n",
      "(11, 99.2188, 0.0244)\n",
      "(12, 100.0000, 0.0125)\n",
      "(13, 100.0000, 0.0098)\n",
      "(14, 98.4375, 0.0670)\n",
      "(15, 100.0000, 0.0296)\n",
      "(16, 100.0000, 0.0118)\n",
      "(17, 100.0000, 0.0209)\n",
      "(18, 100.0000, 0.0189)\n",
      "(19, 97.6562, 0.0515)\n",
      "(20, 98.4375, 0.0601)\n",
      "(21, 98.4375, 0.0436)\n",
      "(22, 96.8750, 0.0534)\n",
      "(23, 96.0938, 0.1377)\n",
      "(24, 98.4375, 0.0568)\n",
      "(25, 93.7500, 0.2016)\n",
      "(26, 95.3125, 0.1679)\n",
      "(27, 91.4062, 0.2263)\n",
      "(28, 71.8750, 0.5490)\n",
      "Epoch: 13/20, Step: 175/250, Loss: 0.5800, Accuracy: 98.50\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0056)\n",
      "(3, 100.0000, 0.0110)\n",
      "(4, 100.0000, 0.0051)\n",
      "(5, 99.2188, 0.0161)\n",
      "(6, 100.0000, 0.0093)\n",
      "(7, 100.0000, 0.0076)\n",
      "(8, 100.0000, 0.0073)\n",
      "(9, 100.0000, 0.0055)\n",
      "(10, 100.0000, 0.0069)\n",
      "(11, 100.0000, 0.0081)\n",
      "(12, 100.0000, 0.0064)\n",
      "(13, 98.4375, 0.0305)\n",
      "(14, 99.2188, 0.0174)\n",
      "(15, 100.0000, 0.0145)\n",
      "(16, 100.0000, 0.0109)\n",
      "(17, 100.0000, 0.0071)\n",
      "(18, 98.4375, 0.0313)\n",
      "(19, 98.4375, 0.0251)\n",
      "(20, 100.0000, 0.0089)\n",
      "(21, 100.0000, 0.0260)\n",
      "(22, 97.6562, 0.0458)\n",
      "(23, 99.2188, 0.0475)\n",
      "(24, 100.0000, 0.0245)\n",
      "(25, 99.2188, 0.0359)\n",
      "(26, 98.4375, 0.0759)\n",
      "(27, 95.3125, 0.1344)\n",
      "(28, 75.7812, 0.5008)\n",
      "Epoch: 13/20, Step: 200/250, Loss: 0.5760, Accuracy: 98.32\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0095)\n",
      "(3, 100.0000, 0.0099)\n",
      "(4, 100.0000, 0.0223)\n",
      "(5, 100.0000, 0.0077)\n",
      "(6, 100.0000, 0.0086)\n",
      "(7, 99.2188, 0.0157)\n",
      "(8, 100.0000, 0.0099)\n",
      "(9, 100.0000, 0.0039)\n",
      "(10, 100.0000, 0.0062)\n",
      "(11, 100.0000, 0.0047)\n",
      "(12, 99.2188, 0.0201)\n",
      "(13, 97.6562, 0.0588)\n",
      "(14, 97.6562, 0.0431)\n",
      "(15, 100.0000, 0.0175)\n",
      "(16, 100.0000, 0.0136)\n",
      "(17, 99.2188, 0.0245)\n",
      "(18, 98.4375, 0.0610)\n",
      "(19, 100.0000, 0.0122)\n",
      "(20, 100.0000, 0.0145)\n",
      "(21, 98.4375, 0.0399)\n",
      "(22, 98.4375, 0.0405)\n",
      "(23, 99.2188, 0.0202)\n",
      "(24, 100.0000, 0.0189)\n",
      "(25, 97.6562, 0.0598)\n",
      "(26, 96.0938, 0.1119)\n",
      "(27, 97.6562, 0.0579)\n",
      "(28, 75.7812, 0.4468)\n",
      "Epoch: 13/20, Step: 225/250, Loss: 1.2249, Accuracy: 98.03\n",
      "(N, accuracy, loss):\n",
      "(2, 98.4375, 0.0376)\n",
      "(3, 100.0000, 0.0131)\n",
      "(4, 100.0000, 0.0117)\n",
      "(5, 100.0000, 0.0189)\n",
      "(6, 100.0000, 0.0111)\n",
      "(7, 99.2188, 0.0138)\n",
      "(8, 98.4375, 0.0307)\n",
      "(9, 100.0000, 0.0083)\n",
      "(10, 98.4375, 0.0407)\n",
      "(11, 100.0000, 0.0099)\n",
      "(12, 100.0000, 0.0046)\n",
      "(13, 100.0000, 0.0054)\n",
      "(14, 99.2188, 0.0161)\n",
      "(15, 99.2188, 0.0226)\n",
      "(16, 100.0000, 0.0247)\n",
      "(17, 100.0000, 0.0184)\n",
      "(18, 98.4375, 0.0364)\n",
      "(19, 97.6562, 0.0692)\n",
      "(20, 98.4375, 0.0527)\n",
      "(21, 99.2188, 0.0352)\n",
      "(22, 100.0000, 0.0214)\n",
      "(23, 97.6562, 0.0595)\n",
      "(24, 99.2188, 0.0407)\n",
      "(25, 100.0000, 0.0218)\n",
      "(26, 96.0938, 0.1460)\n",
      "(27, 92.9688, 0.1843)\n",
      "(28, 74.2188, 0.5787)\n",
      "Epoch: 13/20, Step: 250/250, Loss: 1.0725, Accuracy: 98.23\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0162)\n",
      "(3, 100.0000, 0.0266)\n",
      "(4, 99.2188, 0.0185)\n",
      "(5, 98.4375, 0.0348)\n",
      "(6, 100.0000, 0.0101)\n",
      "(7, 100.0000, 0.0177)\n",
      "(8, 100.0000, 0.0129)\n",
      "(9, 100.0000, 0.0050)\n",
      "(10, 100.0000, 0.0118)\n",
      "(11, 99.2188, 0.0210)\n",
      "(12, 100.0000, 0.0157)\n",
      "(13, 100.0000, 0.0117)\n",
      "(14, 100.0000, 0.0266)\n",
      "(15, 100.0000, 0.0181)\n",
      "(16, 100.0000, 0.0116)\n",
      "(17, 100.0000, 0.0106)\n",
      "(18, 100.0000, 0.0196)\n",
      "(19, 99.2188, 0.0484)\n",
      "(20, 100.0000, 0.0263)\n",
      "(21, 99.2188, 0.0236)\n",
      "(22, 97.6562, 0.0721)\n",
      "(23, 99.2188, 0.0237)\n",
      "(24, 98.4375, 0.0847)\n",
      "(25, 96.8750, 0.0870)\n",
      "(26, 90.6250, 0.2093)\n",
      "(27, 94.5312, 0.1663)\n",
      "(28, 79.6875, 0.4688)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [16:51<10:52, 93.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/20, Step: 25/250, Loss: 0.6789, Accuracy: 98.70\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0130)\n",
      "(3, 100.0000, 0.0130)\n",
      "(4, 100.0000, 0.0106)\n",
      "(5, 100.0000, 0.0178)\n",
      "(6, 100.0000, 0.0088)\n",
      "(7, 100.0000, 0.0170)\n",
      "(8, 100.0000, 0.0170)\n",
      "(9, 100.0000, 0.0048)\n",
      "(10, 100.0000, 0.0077)\n",
      "(11, 100.0000, 0.0133)\n",
      "(12, 100.0000, 0.0047)\n",
      "(13, 100.0000, 0.0135)\n",
      "(14, 100.0000, 0.0147)\n",
      "(15, 98.4375, 0.0195)\n",
      "(16, 99.2188, 0.0137)\n",
      "(17, 100.0000, 0.0084)\n",
      "(18, 99.2188, 0.0215)\n",
      "(19, 100.0000, 0.0044)\n",
      "(20, 99.2188, 0.0310)\n",
      "(21, 98.4375, 0.0293)\n",
      "(22, 100.0000, 0.0178)\n",
      "(23, 100.0000, 0.0156)\n",
      "(24, 100.0000, 0.0160)\n",
      "(25, 99.2188, 0.0436)\n",
      "(26, 93.7500, 0.1589)\n",
      "(27, 96.8750, 0.0718)\n",
      "(28, 80.4688, 0.3951)\n",
      "Epoch: 14/20, Step: 50/250, Loss: 0.5904, Accuracy: 98.41\n",
      "(N, accuracy, loss):\n",
      "(2, 97.6562, 0.0617)\n",
      "(3, 100.0000, 0.0038)\n",
      "(4, 100.0000, 0.0132)\n",
      "(5, 98.4375, 0.0334)\n",
      "(6, 100.0000, 0.0093)\n",
      "(7, 100.0000, 0.0118)\n",
      "(8, 99.2188, 0.0108)\n",
      "(9, 100.0000, 0.0084)\n",
      "(10, 100.0000, 0.0068)\n",
      "(11, 100.0000, 0.0088)\n",
      "(12, 100.0000, 0.0130)\n",
      "(13, 100.0000, 0.0119)\n",
      "(14, 99.2188, 0.0230)\n",
      "(15, 100.0000, 0.0115)\n",
      "(16, 100.0000, 0.0126)\n",
      "(17, 99.2188, 0.0231)\n",
      "(18, 99.2188, 0.0145)\n",
      "(19, 97.6562, 0.0448)\n",
      "(20, 100.0000, 0.0180)\n",
      "(21, 100.0000, 0.0140)\n",
      "(22, 98.4375, 0.0398)\n",
      "(23, 98.4375, 0.0283)\n",
      "(24, 100.0000, 0.0239)\n",
      "(25, 96.8750, 0.0666)\n",
      "(26, 96.0938, 0.0969)\n",
      "(27, 99.2188, 0.0718)\n",
      "(28, 77.3438, 0.4906)\n",
      "Solved N = 27, starting N = 28 + 1\n",
      "Epoch: 14/20, Step: 75/250, Loss: 1.5022, Accuracy: 96.26\n",
      "(N, accuracy, loss):\n",
      "(2, 96.8750, 0.0574)\n",
      "(3, 100.0000, 0.0126)\n",
      "(4, 100.0000, 0.0198)\n",
      "(5, 99.2188, 0.0359)\n",
      "(6, 100.0000, 0.0123)\n",
      "(7, 100.0000, 0.0256)\n",
      "(8, 98.4375, 0.0384)\n",
      "(9, 100.0000, 0.0247)\n",
      "(10, 100.0000, 0.0177)\n",
      "(11, 99.2188, 0.0407)\n",
      "(12, 100.0000, 0.0118)\n",
      "(13, 100.0000, 0.0162)\n",
      "(14, 99.2188, 0.0377)\n",
      "(15, 96.0938, 0.1209)\n",
      "(16, 98.4375, 0.0359)\n",
      "(17, 100.0000, 0.0142)\n",
      "(18, 96.8750, 0.0857)\n",
      "(19, 99.2188, 0.0296)\n",
      "(20, 100.0000, 0.0157)\n",
      "(21, 95.3125, 0.1214)\n",
      "(22, 96.8750, 0.0839)\n",
      "(23, 97.6562, 0.0584)\n",
      "(24, 97.6562, 0.0636)\n",
      "(25, 98.4375, 0.0420)\n",
      "(26, 92.1875, 0.1492)\n",
      "(27, 93.7500, 0.1211)\n",
      "(28, 85.1562, 0.6372)\n",
      "(29, 54.6875, 1.6562)\n",
      "Epoch: 14/20, Step: 100/250, Loss: 1.1979, Accuracy: 97.21\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0279)\n",
      "(3, 100.0000, 0.0123)\n",
      "(4, 100.0000, 0.0168)\n",
      "(5, 100.0000, 0.0205)\n",
      "(6, 100.0000, 0.0211)\n",
      "(7, 100.0000, 0.0162)\n",
      "(8, 100.0000, 0.0125)\n",
      "(9, 100.0000, 0.0112)\n",
      "(10, 100.0000, 0.0159)\n",
      "(11, 100.0000, 0.0165)\n",
      "(12, 100.0000, 0.0195)\n",
      "(13, 99.2188, 0.0192)\n",
      "(14, 100.0000, 0.0057)\n",
      "(15, 100.0000, 0.0242)\n",
      "(16, 98.4375, 0.0335)\n",
      "(17, 99.2188, 0.0228)\n",
      "(18, 97.6562, 0.0341)\n",
      "(19, 100.0000, 0.0148)\n",
      "(20, 97.6562, 0.0408)\n",
      "(21, 97.6562, 0.0608)\n",
      "(22, 100.0000, 0.0197)\n",
      "(23, 97.6562, 0.0485)\n",
      "(24, 99.2188, 0.0382)\n",
      "(25, 98.4375, 0.0585)\n",
      "(26, 99.2188, 0.0807)\n",
      "(27, 93.7500, 0.1218)\n",
      "(28, 86.7188, 0.3218)\n",
      "(29, 57.0312, 0.8256)\n",
      "Epoch: 14/20, Step: 125/250, Loss: 0.9634, Accuracy: 98.13\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0237)\n",
      "(3, 100.0000, 0.0088)\n",
      "(4, 100.0000, 0.0146)\n",
      "(5, 100.0000, 0.0082)\n",
      "(6, 100.0000, 0.0102)\n",
      "(7, 100.0000, 0.0083)\n",
      "(8, 100.0000, 0.0113)\n",
      "(9, 100.0000, 0.0062)\n",
      "(10, 100.0000, 0.0094)\n",
      "(11, 100.0000, 0.0050)\n",
      "(12, 100.0000, 0.0087)\n",
      "(13, 100.0000, 0.0082)\n",
      "(14, 100.0000, 0.0113)\n",
      "(15, 99.2188, 0.0157)\n",
      "(16, 100.0000, 0.0081)\n",
      "(17, 100.0000, 0.0097)\n",
      "(18, 100.0000, 0.0079)\n",
      "(19, 100.0000, 0.0132)\n",
      "(20, 99.2188, 0.0261)\n",
      "(21, 100.0000, 0.0149)\n",
      "(22, 100.0000, 0.0089)\n",
      "(23, 100.0000, 0.0253)\n",
      "(24, 100.0000, 0.0200)\n",
      "(25, 99.2188, 0.0413)\n",
      "(26, 98.4375, 0.0635)\n",
      "(27, 96.0938, 0.1098)\n",
      "(28, 99.2188, 0.0610)\n",
      "(29, 57.0312, 0.6967)\n",
      "Solved N = 28, starting N = 29 + 1\n",
      "Epoch: 14/20, Step: 150/250, Loss: 1.8545, Accuracy: 96.44\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0228)\n",
      "(3, 100.0000, 0.0148)\n",
      "(4, 100.0000, 0.0108)\n",
      "(5, 99.2188, 0.0262)\n",
      "(6, 100.0000, 0.0114)\n",
      "(7, 100.0000, 0.0189)\n",
      "(8, 100.0000, 0.0161)\n",
      "(9, 100.0000, 0.0126)\n",
      "(10, 99.2188, 0.0216)\n",
      "(11, 100.0000, 0.0162)\n",
      "(12, 99.2188, 0.0164)\n",
      "(13, 100.0000, 0.0113)\n",
      "(14, 99.2188, 0.0293)\n",
      "(15, 100.0000, 0.0114)\n",
      "(16, 100.0000, 0.0108)\n",
      "(17, 98.4375, 0.0368)\n",
      "(18, 98.4375, 0.0423)\n",
      "(19, 98.4375, 0.0278)\n",
      "(20, 100.0000, 0.0200)\n",
      "(21, 99.2188, 0.0492)\n",
      "(22, 100.0000, 0.0107)\n",
      "(23, 97.6562, 0.1001)\n",
      "(24, 100.0000, 0.0171)\n",
      "(25, 97.6562, 0.0768)\n",
      "(26, 94.5312, 0.1448)\n",
      "(27, 100.0000, 0.0185)\n",
      "(28, 94.5312, 0.1072)\n",
      "(29, 60.9375, 0.9169)\n",
      "(30, 60.9375, 1.0680)\n",
      "Epoch: 14/20, Step: 175/250, Loss: 2.0324, Accuracy: 95.80\n",
      "(N, accuracy, loss):\n",
      "(2, 99.2188, 0.0450)\n",
      "(3, 100.0000, 0.0143)\n",
      "(4, 100.0000, 0.0177)\n",
      "(5, 99.2188, 0.0297)\n",
      "(6, 100.0000, 0.0130)\n",
      "(7, 100.0000, 0.0134)\n",
      "(8, 100.0000, 0.0220)\n",
      "(9, 100.0000, 0.0133)\n",
      "(10, 100.0000, 0.0097)\n",
      "(11, 98.4375, 0.0312)\n",
      "(12, 100.0000, 0.0182)\n",
      "(13, 100.0000, 0.0080)\n",
      "(14, 98.4375, 0.0564)\n",
      "(15, 97.6562, 0.0544)\n",
      "(16, 100.0000, 0.0119)\n",
      "(17, 99.2188, 0.0170)\n",
      "(18, 99.2188, 0.0306)\n",
      "(19, 100.0000, 0.0071)\n",
      "(20, 100.0000, 0.0086)\n",
      "(21, 99.2188, 0.0185)\n",
      "(22, 100.0000, 0.0185)\n",
      "(23, 95.3125, 0.0807)\n",
      "(24, 100.0000, 0.0246)\n",
      "(25, 100.0000, 0.0253)\n",
      "(26, 95.3125, 0.0946)\n",
      "(27, 94.5312, 0.1119)\n",
      "(28, 95.3125, 0.1195)\n",
      "(29, 60.9375, 0.8904)\n",
      "(30, 46.0938, 0.9673)\n",
      "Epoch: 14/20, Step: 200/250, Loss: 1.8955, Accuracy: 96.47\n",
      "(N, accuracy, loss):\n",
      "(2, 100.0000, 0.0100)\n",
      "(3, 100.0000, 0.0154)\n",
      "(4, 100.0000, 0.0167)\n",
      "(5, 100.0000, 0.0160)\n",
      "(6, 100.0000, 0.0129)\n",
      "(7, 100.0000, 0.0121)\n",
      "(8, 100.0000, 0.0152)\n",
      "(9, 100.0000, 0.0119)\n",
      "(10, 100.0000, 0.0288)\n",
      "(11, 100.0000, 0.0156)\n",
      "(12, 100.0000, 0.0101)\n",
      "(13, 100.0000, 0.0226)\n",
      "(14, 99.2188, 0.0403)\n",
      "(15, 100.0000, 0.0141)\n",
      "(16, 100.0000, 0.0209)\n",
      "(17, 99.2188, 0.0283)\n",
      "(18, 100.0000, 0.0201)\n",
      "(19, 99.2188, 0.0478)\n",
      "(20, 100.0000, 0.0209)\n",
      "(21, 98.4375, 0.0364)\n",
      "(22, 100.0000, 0.0293)\n",
      "(23, 100.0000, 0.0436)\n",
      "(24, 99.2188, 0.0401)\n",
      "(25, 96.8750, 0.0866)\n",
      "(26, 98.4375, 0.0939)\n",
      "(27, 96.8750, 0.0854)\n",
      "(28, 98.4375, 0.0800)\n",
      "(29, 54.6875, 0.7498)\n",
      "(30, 57.0312, 0.6896)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [18:21<09:53, 84.73s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [97], line 55\u001B[0m\n\u001B[0;32m     53\u001B[0m     loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m discount \u001B[38;5;241m*\u001B[39m criterion(outs[N_i], labels[N_i])\n\u001B[0;32m     54\u001B[0m loss_hist\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n\u001B[1;32m---> 55\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m nn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(ca\u001B[38;5;241m.\u001B[39mparameters(), max_norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2.0\u001B[39m, norm_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)  \u001B[38;5;66;03m# gradient clipping\u001B[39;00m\n\u001B[0;32m     57\u001B[0m optim\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torchstuff\\lib\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torchstuff\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "num_training_steps = 250\n",
    "warmup_time = 0\n",
    "\n",
    "POOL_SIZE = 1000\n",
    "POOL = ca.seed(RES, POOL_SIZE)\n",
    "\n",
    "p_group1 = [p for n, p in ca.rule.named_parameters() if 'readouts' not in n]\n",
    "p_group2 = [p for n, p in ca.rule.named_parameters() if 'readouts' in n]\n",
    "\n",
    "optim = torch.optim.Adam([\n",
    "                {'params': p_group1},\n",
    "                {'params': p_group2, 'weight_decay': 0.1}\n",
    "            ], lr=1e-2, weight_decay=0.)\n",
    "# optim = torch.optim.Adam(ca.parameters(), lr=1e-2, weight_decay=0)\n",
    "\n",
    "# optim = torch.optim.SGD(ca.parameters(), lr=5e-3, momentum=0.1, nesterov=True)\n",
    "\n",
    "# task details\n",
    "# Ns = [2, 3]\n",
    "Ns = list(np.arange(2, 8))\n",
    "num_extra_heads = 1\n",
    "k_factor = 1\n",
    "min_T = 10 + (Ns[-1]) * k_factor + DELAY_TIME\n",
    "max_T = 10 + min_T + 3*Ns[-1] * k_factor\n",
    "\n",
    "loss_hist = []\n",
    "accuracies = []\n",
    "print('Training started...')\n",
    "for i_epoch in tqdm(range(num_epochs)):\n",
    "    for i in range(num_training_steps):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        timesteps = np.random.randint(min_T, max_T)\n",
    "        # np.random.randint(timesteps//5, timesteps//3)\n",
    "        # thinking_time = np.random.randint(10, 30)\n",
    "\n",
    "        sequences, labels = make_batch_Nbit_pair_parity(Ns, timesteps, BATCH_SIZE)\n",
    "        sequences = sequences.to(device)\n",
    "        sequences = sequences.repeat_interleave(k_factor, dim=1)\n",
    "        timesteps = sequences.shape[1]\n",
    "        labels = [l.to(device) for l in labels]\n",
    "\n",
    "        outs = forward_pass(ca=ca, sequences=sequences, num_readouts=len(Ns))\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss = 0.\n",
    "        for N_i in range(len(Ns)):\n",
    "            if N_i == len(Ns) - 1:\n",
    "                discount = 0.1\n",
    "            else:\n",
    "                discount = 1.\n",
    "            loss += discount * criterion(outs[N_i], labels[N_i])\n",
    "        loss_hist.append(loss.item())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(ca.parameters(), max_norm=2.0, norm_type=2)  # gradient clipping\n",
    "        optim.step()\n",
    "\n",
    "        # Test and measure accuracy\n",
    "        correct_N = np.zeros_like(Ns)\n",
    "        total = 0\n",
    "        if (i + 1) % 25 == 0:\n",
    "            with torch.no_grad():\n",
    "                timesteps = np.random.randint(min_T, max_T)\n",
    "                # warmup_time = 50\n",
    "                # warmup_time = np.random.randint(timesteps//3, timesteps)\n",
    "                # thinking_time = np.random.randint(10, 30)\n",
    "\n",
    "                sequences, labels = make_batch_Nbit_pair_parity(Ns, timesteps, BATCH_SIZE)\n",
    "                sequences = sequences.to(device)\n",
    "                sequences = sequences.repeat_interleave(k_factor, dim=1)\n",
    "                timesteps = sequences.shape[1]\n",
    "                labels = [l.to(device) for l in labels]\n",
    "\n",
    "                outs = forward_pass(ca=ca, sequences=sequences, num_readouts=len(Ns))\n",
    "                \n",
    "                loss_N = []\n",
    "                for N_i in range(len(Ns)):\n",
    "                    predicted = torch.max(outs[N_i], 1)[1]\n",
    "                    loss_N.append(criterion(outs[N_i], labels[N_i]).item())\n",
    "\n",
    "                    correct_N[N_i] += (predicted == labels[N_i]).sum()\n",
    "                    total += labels[N_i].size(0)\n",
    "\n",
    "            accuracy = 100 * correct_N / float(total) * len(Ns)\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "            print(f'Epoch: {i_epoch+1}/{num_epochs}, Step: {i+1}/{num_training_steps}, '\n",
    "                  f'Loss: {loss_hist[-1]:.4f}, Accuracy: {np.mean(accuracy):.2f}')\n",
    "            print('(N, accuracy, loss):\\n' + ''.join([f'({Ns[i]}, {accuracy[i]:.4f}, {loss_N[i]:.4f})\\n' for i in range(len(Ns))]), flush=True)\n",
    "            \n",
    "            \n",
    "\n",
    "            if np.mean(accuracy[:-2]) > 98 or len(accuracy < 3):\n",
    "                if accuracy[-2] > 98:\n",
    "                    if len(Ns) == NUM_READOUT_HEADS:\n",
    "                        break\n",
    "                    print(f'Solved N = {Ns[-2]}, starting N = {Ns[-1]} + {num_extra_heads}')\n",
    "                    Ns += [Ns[-1] + i for i in range(1, num_extra_heads+1)]\n",
    "                    min_T = 10 + (Ns[-1]) * k_factor\n",
    "                    max_T = 10 + min_T + 3*Ns[-1] * k_factor\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T20:24:06.488932600Z",
     "start_time": "2024-03-04T20:05:44.718143700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for longer timescales"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct_N = np.zeros_like(Ns)\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    timesteps = np.random.randint(1000, 2000)\n",
    "    \n",
    "    # warmup_time = 50\n",
    "    # warmup_time = np.random.randint(timesteps//3, timesteps)\n",
    "    # thinking_time = np.random.randint(10, 30)\n",
    "\n",
    "    sequences, labels = make_batch_Nbit_pair_parity(Ns, timesteps, BATCH_SIZE)\n",
    "    sequences = sequences.to(device)\n",
    "    sequences = sequences.repeat_interleave(k_factor, dim=1)\n",
    "    timesteps = sequences.shape[1]\n",
    "    labels = [l.to(device) for l in labels]\n",
    "\n",
    "    outs = forward_pass(ca=ca, sequences=sequences, num_readouts=len(Ns))\n",
    "\n",
    "    for N_i in range(len(Ns)):\n",
    "        predicted = torch.max(outs[N_i], 1)[1]\n",
    "\n",
    "        correct_N[N_i] += (predicted == labels[N_i]).sum()\n",
    "        total += labels[N_i].size(0)\n",
    "\n",
    "accuracy = 100 * correct_N / float(total) * len(Ns)\n",
    "accuracies.append(accuracy)\n",
    "\n",
    "print(f'Epoch: {i_epoch+1}/{num_epochs}, Step: {i+1}/{num_training_steps}, '\n",
    "      f'Loss: {loss_hist[-1]:.4f}, Accuracy: {np.mean(accuracy):.2f}')\n",
    "print('({N}, accuracy):\\n' + ''.join([f'({Ns[i]}, {accuracy[i]:.4f})\\n' for i in range(len(Ns))]), flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:24:06.483932500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize in PyGame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# RES = 200\n",
    "# ca.res = RES"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:24:06.485933100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "# pygame stuff\n",
    "######################################\n",
    "RESX, RESY = 1 * RES, 1 * RES\n",
    "# state = ca.initGrid(BS=1)\n",
    "state = torch.cuda.FloatTensor(2 * np.random.rand(1, CHANNELS, RESX, RESY) - 1)\n",
    "\n",
    "pygame.init()\n",
    "size = RESX, RESY\n",
    "\n",
    "win = pygame.display.set_mode((RESX, RESY))\n",
    "\n",
    "screen = pygame.Surface(size)\n",
    "UPSCALE = 60\n",
    "RESXup, RESYup = int(RESX*UPSCALE), int(RESY*UPSCALE)\n",
    "upscaled_screen = pygame.display.set_mode([RESXup, RESYup])\n",
    "FPS_init = 60\n",
    "FPS = int(1*FPS_init)\n",
    "\n",
    "\n",
    "running = True\n",
    "time_ticking = True\n",
    "LMB_trigger = False\n",
    "RMB_trigger = False\n",
    "WHEEL_trigger = False\n",
    "cdim_order = np.arange(0, state.shape[1])\n",
    "\n",
    "do_task = False\n",
    "thinking_time = 0\n",
    "task_ticker = 0\n",
    "t = 0\n",
    "max_readout = 10\n",
    "correct = []\n",
    "\n",
    "clock = pygame.time.Clock()\n",
    "font_h = pygame.font.SysFont(\"Noto Sans\", 24)\n",
    "font = pygame.font.SysFont(\"Noto Sans\", 12)\n",
    "def update_fps(clock, font):\n",
    "    fps = str(int(clock.get_fps()))\n",
    "    fps_text = font.render(fps, 1, pygame.Color(\"white\"))\n",
    "    fps_bg = pygame.Surface((fps_text.get_height(),fps_text.get_width()))  # the size of your rect\n",
    "    fps_bg.set_alpha(50)                # alpha level\n",
    "    fps_bg.fill((255,255,255))           # this fills the entire surface\n",
    "\n",
    "    fps_surf = pygame.Surface((fps_bg.get_height(), fps_bg.get_width()))\n",
    "    fps_surf.blit(fps_bg, (0, 0))\n",
    "    fps_surf.blit(fps_text, (0, 0))\n",
    "    return fps_surf\n",
    "######################################\n",
    "\n",
    "\n",
    "update_rate = 1.\n",
    "ticker = 0.\n",
    "\n",
    "export_imgs = False\n",
    "imgs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "\n",
    "            if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                if event.button == 1:\n",
    "                    LMB_trigger = True\n",
    "                if event.button == 3:\n",
    "                    RMB_trigger = True\n",
    "            if event.type == pygame.MOUSEBUTTONUP:\n",
    "                if event.button == 1:\n",
    "                    LMB_trigger = False\n",
    "                if event.button == 3:\n",
    "                    RMB_trigger = False\n",
    "\n",
    "            if event.type == pygame.MOUSEWHEEL:\n",
    "                WHEEL_trigger = True\n",
    "                direction = -event.y\n",
    "\n",
    "            if event.type == pygame.MOUSEBUTTONUP and event.button == 2:\n",
    "                # scroll through channel dims\n",
    "                cdim_order = np.arange(0, state.shape[1])\n",
    "            if event.type == pygame.KEYDOWN and event.key == pygame.K_e:\n",
    "                export_imgs = not export_imgs\n",
    "            if event.type == pygame.KEYDOWN and event.key == pygame.K_p:\n",
    "                # pause/toggle time\n",
    "                time_ticking = not time_ticking\n",
    "            if event.type == pygame.KEYDOWN and event.key == pygame.K_s:\n",
    "                # start a task\n",
    "                do_task = not do_task\n",
    "                if not do_task:\n",
    "                    FPS = 60\n",
    "                task_ticker = 0\n",
    "                timesteps = 1_000\n",
    "\n",
    "                sequence = generate_binary_sequence(timesteps)\n",
    "                sequence = sequence.to(device)\n",
    "                labels = [torch.stack([get_parity(sequence[_t-N:_t], N) for _t in range(N, len(sequence))]) for N in Ns]\n",
    "                labels = [l.to(device) for l in labels]\n",
    "                sequence = sequence.repeat_interleave(k_factor)\n",
    "                labels = [l.repeat_interleave(k_factor) for l in labels]\n",
    "                timesteps = len(sequence)\n",
    "\n",
    "                correct_N = []\n",
    "\n",
    "                # state = ca.initGrid(BS=1)\n",
    "\n",
    "                ridx = np.random.choice(POOL.shape[0])\n",
    "                state = POOL[[ridx], ...].cuda()\n",
    "\n",
    "\n",
    "            if event.type == pygame.KEYDOWN and event.key == pygame.K_r:\n",
    "                # start from seed\n",
    "                state = ca.initGrid(BS=1)\n",
    "\n",
    "        mouse_pos = pygame.mouse.get_pos()\n",
    "        if LMB_trigger:\n",
    "            state = LMB_make(state, r=r, s=s)\n",
    "        if RMB_trigger:\n",
    "            state = RMB_del(state, r=r, s=s)\n",
    "\n",
    "        if WHEEL_trigger:\n",
    "            cdim_order = WHEEL_permute(cdim_order, direction)\n",
    "            WHEEL_trigger = False\n",
    "\n",
    "        # nx = state[0, cdim_order[0], :, :].cpu().numpy()\n",
    "        nx = min_max(state[0, cdim_order[0:3], :, :].cpu().numpy().transpose(1, 2, 0))\n",
    "        # nx = (state[0, cdim_order[0:3], :, :].cpu().numpy().transpose(1, 2, 0) + 20) / 80\n",
    "        # nx = state[0, cdim_order[0:3], :, :].cpu().numpy().transpose(1, 2, 0)\n",
    "        # nx = min_max(state[0, :, :, :].mean(dim=0).cpu().numpy())\n",
    "        nx = nx * 255.\n",
    "\n",
    "        if time_ticking:\n",
    "\n",
    "            if do_task:\n",
    "                # check if task time is less than the total task length\n",
    "                if task_ticker < (timesteps + warmup_time) and task_ticker < timesteps - Ns[-1]*k_factor - 1:\n",
    "                    \n",
    "                    # if CA has warmed up, inject input\n",
    "                    if task_ticker >= warmup_time:\n",
    "                        t = task_ticker - warmup_time\n",
    "                        readin_res = int(READIN_SCALE*RES)\n",
    "                        readin_patch = ca.rule.readin(sequence[t].unsqueeze(0)).reshape(1, READIN_CHANNELS, readin_res, readin_res)\n",
    "                        readin_patch = pad_to(readin_patch, (RES, RES))\n",
    "                        \n",
    "                        # readin_mask = pad_to(-torch.ones(1, READIN_CHANNELS, readin_res//2, readin_res//2), (RES, RES)).cuda() + 1\n",
    "                        # readin_mask = pad_to(-torch.ones(1, READIN_CHANNELS, int(readin_res//1.2), int(readin_res//1.2)), (RES, RES)).cuda() + 1\n",
    "                        # readin_patch = readin_patch * readin_mask\n",
    "                        \n",
    "                        state[:, -READIN_CHANNELS:, ...] = state[:, -READIN_CHANNELS:, ...] + readin_patch\n",
    "\n",
    "\n",
    "                        # readin_res = int(READIN_SCALE*RES)\n",
    "                        # readin_patch = ca.rule.readin(sequence[t].unsqueeze(0)).reshape(1, READIN_CHANNELS, readin_res, readin_res)\n",
    "                        # readin_patch = pad_to(readin_patch, (RES, RES))\n",
    "                        # state[:, -READIN_CHANNELS:, ...] = state[:, -READIN_CHANNELS:, ...] + readin_patch\n",
    "                    task_ticker += 1\n",
    "                else:\n",
    "                    do_task = False\n",
    "                    t = 0\n",
    "\n",
    "            state = ca.forward(state)\n",
    "            ticker += 1\n",
    "            # if do_task:\n",
    "                # readout_patch = state[...,center-r:center+r+1, center-r:center+r+1].reshape(BATCH_SIZE, -1)\n",
    "                # out = ca.rule.readout(readout_patch)\n",
    "\n",
    "            if export_imgs:\n",
    "                imgs.append(nx)\n",
    "\n",
    "        pygame.surfarray.blit_array(screen, nx)\n",
    "        frame = pygame.transform.scale(screen, (RESXup, RESYup))\n",
    "\n",
    "        upscaled_screen.blit(frame, frame.get_rect())\n",
    "        upscaled_screen.blit(update_fps(clock, font), (10,0))\n",
    "        if do_task:\n",
    "            minimum_wait_time = Ns[-1]*k_factor - thinking_time\n",
    "            eff_time = t - minimum_wait_time\n",
    "\n",
    "            if eff_time >= 0 and eff_time % k_factor == 0: # only do readout on the end of the time-dilation to be the same as training\n",
    "                FPS=10\n",
    "                # readout_patch = state[:, :READOUT_CHANNELS, ...]\n",
    "                # mask = torch.ones((1, 1, RES, RES)).cuda() - pad_to(torch.ones((1, 1, readin_res, readin_res)).cuda(), (RES, RES))\n",
    "                # readout_patch = (readout_patch * mask).reshape(1, -1)\n",
    "                \n",
    "                readout_len = ca.rule.readout_res\n",
    "                l_edge = RES//2 - int(readout_len/2)\n",
    "                r_edge = l_edge + readout_len\n",
    "                t_edge = RES//2 - int(readout_len/2)\n",
    "                b_edge = t_edge + readout_len\n",
    "                readout_patch = state[\n",
    "                                :,\n",
    "                                :READOUT_CHANNELS,\n",
    "                                l_edge : r_edge,\n",
    "                                t_edge : b_edge,\n",
    "                                ]\n",
    "                \n",
    "                # readout_radius = int(RES*READOUT_SCALE*0.5)\n",
    "                # readout_patch = state[:, :READOUT_CHANNELS, RES//2 - readout_radius:RES//2 + readout_radius, RES // 2 - readout_radius:RES // 2 + readout_radius]\n",
    "                \n",
    "                \n",
    "                readout_patch = (readout_patch).reshape(1, -1)\n",
    "        \n",
    "                outs = [l_r(readout_patch) for l_r in ca.rule.readouts[:len(Ns)]]\n",
    "\n",
    "                # each task N has labels of different length that are indexed differently.\n",
    "                t_label_N = [t - N*k_factor - thinking_time + 1 - DELAY_TIME for N in Ns]\n",
    "                # print(f't: {t}, eff_time: {eff_time}, t_label_N: {t_label_N}')\n",
    "                # used for the histograms\n",
    "                label_t = torch.stack([l[t_label_N[il]].cpu() for il, l in enumerate(labels[:max_readout])]).numpy()\n",
    "\n",
    "                \n",
    "                correct_N = []\n",
    "                for N_i in range(len(Ns)):\n",
    "                    predicted = torch.max(outs[N_i], 1)[1][0]\n",
    "                    correct_N.append((predicted == labels[N_i][t_label_N[N_i]]).sum().cpu().numpy())\n",
    "                    \n",
    "\n",
    "                if len(correct) < 1000:\n",
    "                    correct.append(correct_N)\n",
    "                else:\n",
    "                    correct = [correct_N] + correct[1:]\n",
    "\n",
    "            if eff_time >= 0:\n",
    "                # plot the histograms\n",
    "                graph_surf = plot_classification_scores(\n",
    "                    F.softmax(\n",
    "                        torch.stack(outs)[:max_readout, ...].squeeze(1).cpu(), dim=1\n",
    "                    ).numpy(), label_t, width=RESXup//6, height=int(len(label_t) * RESYup//10))\n",
    "                upscaled_screen.blit(graph_surf, (0,30))\n",
    "                upscaled_screen.blit(print_something(100 * np.mean(correct)), (10,20))\n",
    "\n",
    "        pygame.display.flip()\n",
    "        clock.tick(FPS)\n",
    "\n",
    "pygame.quit()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T20:24:52.496346300Z",
     "start_time": "2024-03-04T20:24:25.306641800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 900x900 with 25 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2UAAAN6CAYAAAAO9uEdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABD00lEQVR4nO3deZgVBL3/8S+yCLI44C5KggsIVy8Cyg81QwKlREJSScUANa4mlVdcWA0e19TUqyKKg2FhiV6XrstNadFrppaZv5+IAWluSCiCsYjBwPz+8Do5so1nzpmvI6/X88zz3M4cfD6n53uneXtgaFBZWVkZAAAApNgmewAAAMDWTJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUbcapp54anTt3jhdeeGGjn+/Tp0+MGTMmIiIqKytj1qxZceyxx8ZBBx0UX/7yl+PSSy+NlStX1uVkqObT3PC6deti2rRp0a9fvzjwwANj4MCB8fOf/7wu58IGPs0Nf9KoUaOiT58+pZwHW/Rpbnj16tWx//77R8eOHat9HHDAAXU5Gar5tF+Hn3/++Tj11FOja9euceihh8aFF14Y7777bl3NrbdE2RasW7cuxo4dG2vWrNns88rLy2Py5MnRu3fvmDJlSpxxxhnxwAMPxKhRo6KysrKO1sKGanrD11xzTVx//fVxwgknxC233BKHHnpoXHDBBfHAAw/U0VLYuJre8Mf9/Oc/j9mzZ5dwFdRcTW943rx5sX79+rjmmmti1qxZVR933HFHHS2FjavpDc+ZMye++c1vxnbbbRc33nhjnHfeefHkk0/G2WefXUdL6y9RtgUtW7aMBQsWxJQpUzb5nPXr18e0adNiyJAhMXr06Dj00EPjpJNOiu9///vx1FNPxZw5c+pwMVRXkxtetWpVzJw5M4YNGxYjR46MXr16xZgxY+KQQw6JmTNn1uFa2FBNbvjjFi9eHJdeemnsuuuuJV4GNVPTG37ppZeicePGcdRRR0XXrl2rPg488MA6WgobV9MbvvLKK2P//fePm266KQ4//PAYPHhwXHTRRbFo0aJ444036mht/STKtmD//fePQYMGRXl5+SbjauXKlTFw4MAYMGBAtcfbt28fEeEISVWTG952221j1qxZMWLEiGqPN27c+FO9OwGlUJMb/rgJEybEYYcdFr169aqDdbBlNb3hl156KfbZZ59o3LhxHa6DLavJDS9btix+//vfx0knnRQNGzasevyoo46Kxx9/PPbcc8+6mlsvibIaGD9+fLRp02aTb9u2atUqJk6cGN27d6/2+KOPPhoREfvuu2+d7IRN2dINN2rUKDp16hQ77rhjVFZWxjvvvBO33HJL/O53v4uTTz45YTFUt6Ub/sjdd98dL774YkycOLEO18GW1eSG//znP8c222wTI0aMiK5du8YhhxwSF110kT+fzmfClm543rx5UVlZGTvssEOMHj06DjrooDjooIPivPPOi7///e8Ji+sXUVYDrVq1ismTJ8f8+fNr/Ntnnnvuubj11lujb9++oox0n+aGH3jggTj88MPjmmuuiSOOOCK++tWv1tFK2LSa3PDChQvj8ssvj+9///vRpk2bOl4Im7elG16/fn3Mnz8/Xn311ejXr1/ceuutceaZZ8aDDz4YI0eOjPXr1yeshn/a0g0vXbo0IiLGjRsXTZs2jZtuuikuuOCCePzxx91wDYiyGurTp08MHDgwysvL48UXX9zsc5999tkYOXJktGvXLi699NI6WgibV9Mb/td//deYOXNmXHzxxTF37tz4xje+Ef/4xz/qcCls3OZuuLKyMsaNGxdf+tKX4uijj05aCJu3pRu+5ZZb4u67746TTz45Dj744DjttNNi0qRJ8cc//jGeeOKJpNXwT5u74bVr10ZERJcuXeLSSy+NXr16xUknnRSTJk2K559/Pp588smMyfWGKPsUJkyYEK1bt44xY8Zs8rcePPTQQzFixIjYfffdY8aMGVFWVla3I2EzanLDX/jCF+Lggw+OE088Ma666qqYP39+PPLII3W8FDZuUzd8xx13xLx582LcuHFRUVERFRUVVT/5tqKiwr+h5TNjUzfcsGHD6NmzZ+y9997Vnt+7d++I+PC3hsFnwaZuuHnz5hERceSRR1Z7/he/+MWI+PDPTLJpouxT2H777WPSpEkxf/78mDp16gafLy8vj9GjR0fXrl3jjjvuiJ122ilhJWzapm743Xffjfvuu2+Dv0fko78b529/+1ud7oRN2dQNP/LII7Fs2bI4/PDDo0uXLtGlS5e4//77Y+HChdGlS5ca/9ZzKLVN3fDixYvjrrvu2uDr7QcffBAREa1bt67TnbApm7rhvfbaKyJig3/pW1FRERERTZs2rbON9ZEo+5T69u0bAwYMiGnTplX93tmIiDvvvDOuuuqq6N+/f0yfPj1atmyZuBI2bWM3/P7778eYMWPi7rvvrvbcj367TMeOHet8J2zKxm548uTJ8Z//+Z/VPo488sjYaaed4j//8z/jxBNPTF4N/7SxG16zZk1MnDgxZs2aVe25Dz/8cGyzzTYb/DAxyLSxG957772jbdu28dBDD1V77q9+9auIiOjRo0ed76xPGmUPqI8mTpwYTz/9dCxZsiQiIt555524/PLLo23btjF06NCYO3dutee3a9fOHzrnM+WTN7znnnvGoEGDYsqUKbHNNtvEAQccEHPmzImpU6fG4YcfHkcccUTyYqjukzfcoUOHDZ5TVlYWTZo0qXrHFz5LNvZ1+Gtf+1rceuut0aRJk+jatWv88Y9/jJtvvjlOPvnkjd44ZPrkDTdo0CAuuOCCOOecc+Kcc86JE044IV555ZW45ppr4uijj47OnTsnL/5s805ZAcrKymLSpElV//nxxx+PDz74IBYuXBinnHJKDBkypNrHY489lrYVNuaTNxwRcfHFF8e3v/3tuOeee2LkyJHxs5/9LL75zW/G1KlTo0GDBjlDYRM2dsNQn2zq6/BZZ50V999/f4wcOTLuv//++O53vxvjxo3LGQmbsbEb7t+/f0ydOjXefPPNOPPMM+OWW26Jb3zjG3H11VfnjKxHGlR+9CehAQAAqHPeKQMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARI1q+sTv7DWklDtK6tFVL2dPqJUJjTtmTyjYqW/dkT2hytfaDcieULA3176XPaFW6vNfh/jc357MnlDl5C8clz2hYHP/sTh7Qq103Xa37AkFm/HaPdkTqpxSj2/4tYq/Z0+olfcqVmVPKNicxc9kT4iIiCPafjl7QsF6Nto5e0Kt/HbtouwJBXvqrcdq9DzvlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJGtX0ie9U/qOUO0rqnG07ZU+oldcaVmZP+Fz4R+W67AkFW1nxQfaEWhnRrGP2hM+FRtEge0LBjtu2ffaEWtl+ff397/6z5Kx/1N9/F/yTbXfInlArrRrtkj2h3htdsXP2hILNbPh+9oRaWVe5PntCydXfr44AAACfA6IMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASNSopk/80a1HlXJHSfUb8Z/ZE2rlpHW7Z0/4XLiuWfaCwm238/bZE2rlocUNsid8LnzjgybZEwrW59cjsifUyvVf+VH2hM+FsyoXZk8o2A8+2Ct7Qq0ctO+i7An13nfXvpg9oWDHNOuUPaFWbjowe0HpeacMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASNSgsrKyMnsEAADA1so7ZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRthmnnnpqdO7cOV544YWNfr5Pnz4xZsyYeOaZZ6Jjx46b/LjxxhvreDl8qKY3/JG77rorjjnmmOjatWt85StfiTvuuCMqKyvrai5s4NPc8Pr162P69OnRr1+/OOCAA6J///5x++23u2HqzKf9mvuRRYsWRY8ePeKZZ57Z4HOvvPJKjBw5Mrp37x49e/aMcePGxfLly4u+HT5Sijuuyee3dqJsC9atWxdjx46NNWvWbPI5Xbp0iVmzZm3w0atXr2jRokUcc8wxdbgYqqvJDUdE3H333TFx4sTo1atXTJ06Nfr37x8XX3xx3HbbbXW0FDaupjd8xRVXxJVXXhmHHnpoTJ06NYYNGxZTp06Nyy+/vI6WQs3v9SMLFy6MESNGxIoVKzb43PLly2P48OGxdOnSuPLKK2P06NExe/bsOOecc4q8Gqor5h3X5POIsi1q2bJlLFiwIKZMmbLJ57Ro0SK6du1a7WPJkiXx1FNPxaWXXhrt27evw8VQXU1uOCLinnvuiW7dusWECROiV69e8b3vfa/q3TLIVJMbXrp0acycOTNOPPHEmDx5chx++OFx0kknxQ9+8IP4yU9+Ei+//HIdLmZrVtOvuevXr4977rknBg8eHMuWLdvoc372s5/F8uXLY9q0afHlL385TjzxxLj66qvjySefjGeffbYU8yEiinfHNblzPiTKtmD//fePQYMGRXl5ecyZM6dGv+aDDz6ISy65JHr37h39+/cv8ULYvJre8Jo1a6Jly5bVHmvdunW89957JV4Im1eTG3711Vdj3bp1ceSRR1Z7/OCDD47169fHE088URdTocZfc+fNmxeTJk2KQYMGxZVXXrnR5/z2t7+N7t27R5s2baoe++IXvxjNmzeP//mf/yn6dvhIse64JnfOh0RZDYwfPz7atGlT47dxZ8yYEW+//XaMGzeuDtbBltXkhocNGxZPPvlk/PznP48VK1bEE088Effdd1987Wtfq+O1sKEt3fBH37QuXLiw2uOvv/56RES8+eabpR8J/6smX3N32223mD17dowdOzaaNm260ee8/PLLG/xum2222Sb22GOPePXVV4s9G6opxh3X5M75kCirgVatWsXkyZNj/vz5W3wbd82aNfGTn/wkvvrVr8YXvvCFOloIm1eTG/7KV74SAwcOjAsuuCB69OgRZ5xxRnTr1s2/XOAzYUs3vNdee0W3bt3ixhtvjNmzZ8eKFSti7ty5MX78+GjSpEm8//77CavZWtXka25ZWVnsuuuum/3nLF++PJo3b77B482bN4+VK1cWZStsSjHuuCZ3zodEWQ316dMnBg4cGOXl5fHiiy9u8nm/+MUvYsmSJXHGGWfU4TrYsi3d8FlnnRW/+MUv4vzzz4+f/OQnMWHChJgzZ05873vf89Pr+EzY0g3fcMMN0b179xg1alT06NEjhg0bFkOGDIkddtghtttuu4TFbM1q+n3DljRo0GCDxyorKzf6OBRbse6YLRNln8KECROidevWMWbMmE2+jfvII4/EvvvuG506darjdbBlm7rh5557Ln7729/GuHHj4owzzohDDjkkTj311PjBD34Qv/rVr+Kxxx7LGw0fs7mvwzvuuGPcdNNN8Yc//CEeeuihePLJJ2Pw4MHx9ttvx/bbb5+0mK1ZTb5v2JwWLVps9B2x999/f4M/AwylUts7pmZE2aew/fbbx6RJk2L+/PkxderUDT6/du3aePLJJ/1wDz6zNnXDb731VkREdOvWrdrzDz744IiIWLBgQd2NhM3Y3Nfhhx56KP785z9Hq1atYp999okmTZrESy+9FOvWrYvOnTsnLWZrtqXvG7akffv2VX8u8iPr16+PN998M/bZZ59izYTNqu0dUzOi7FPq27dvDBgwIKZNmxZLly6t9rn58+fH6tWro3v37knrYMs2dsMdOnSIiNjgRyw/99xzERGxxx571O1I2IxNfR2eOnVqTJs2rdpzZ8yYEa1atYqePXvW9UyIiM1/37Alhx12WPzhD3+o9uueeOKJWLVqVRx22GHFngqbVJs7pmZEWQEmTpwYZWVlsXr16mqPz58/PyIi9t5774xZUGOfvOHOnTvH0UcfHVdccUVMmzYtnnnmmbjjjjvi/PPPjy5dukS/fv2SF0N1G/s6fOqpp8bDDz8cN910Uzz99NNx0UUXxYMPPhjnnntutGjRInEtW7tNfd+wJSeffHJsu+22MWLEiJg9e3bcfffdcf7558cRRxwRBx10UInWwsYVesfUjCgrQFlZWUyaNGmDx5csWRIR4c8u8Jm3sRu++uqrY/jw4XHnnXfG6aefHrfffnsMHjw4fvKTn0Tjxo1zhsImbOyGhwwZEmPHjo377rsvzjzzzHjhhRfihz/8YZx00kk5I+F/ber7hi1p06ZN/PjHP47WrVvHeeedF9dee230798/rr322uKPhC0o9I6pmQaVfqwaAABAGu+UAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAECiRjV9Yq/de5dwRmlt37BZ9oRaWbTmvewJBfu/i5/KnlDlX3bpmT2hYF9oskP2hFrZtkHD7AkFu/f1B7InVOmzx1HZEwr25j/ezZ5QK0du1yF7QsFuee3u7AlV+u1xdPaEgv1l9eLsCbWyV7OdsicU7Ddvzs6eEBERp35hcPaEgr2zfnX2hFr5+7r6u/+ptx6r0fO8UwYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkalTTJx7TuG0pd5RUq/UNsifUyvKmbbInfC70bLpn9oSCrYn12RNqZY/YNnvC50KXRq2zJxRs+PqdsifUyj2Vf8+e8LnQf5v6ewf/2mj77Am18n+3aZI9od67aq93sycUbPaCPbIn1MpX/vWN7Akl550yAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASNSopk9c3KCilDtKapf1jbMn1MpRzZZmT/hcaBtNsicUrGE0yJ5QK+cevzJ7wudC97X192vZ803q7/+GRESM+Uf9/frxWfJig9XZEwr256b1++vwpfu9nj2h3vvZK3tmTyjYzMpXsyfUylMv7Z49oWA31fB53ikDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEjWorKyszB4BAACwtfJOGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUfcypp54anTt3jhdeeGGjn+/Tp0+MGTNmg8cXLVoUPXr0iGeeeWaDzz3zzDMxdOjQOPjgg+Owww6LUaNGxWuvvVb07RBRmhv+5S9/GYMHD46uXbvGkUceGddff32sWbOm6NshojQ3/HG33357dOzYMd58882i7IWPK8X9nnjiidGxY8cNPp5//vliz4eS3PDixYtj9OjR0bNnz+jWrVsMHz485s6dW/Tt9Z0o+4R169bF2LFja/xN58KFC2PEiBGxYsWKDT73pz/9KU477bRo3bp1XH311TFx4sR444034uSTT46lS5cWezpERHFv+PHHH49Ro0ZFp06d4qabborTTz89fvSjH8XFF19c7NlQpZg3/HGvvvpqXHPNNcWYCJtUzPtdv359zJ8/P04//fSYNWtWtY9999232NMhIop7wytXroxTTjkl5s6dG5MnT44f/vCHsWrVqhgxYkS8/fbbxZ5er4myT2jZsmUsWLAgpkyZstnnrV+/Pu65554YPHhwLFu2bKPPueWWW6JDhw7xH//xH/GlL30p+vfvH7feemssW7Ys7rvvvlLMh6Lf8IEHHhiXXXZZHHrooTF06NA47bTT4t57743333+/FPOhqDf8kXXr1sWYMWOirKysiEthQ8W837/+9a+xevXq6N27d3Tt2rXaR/PmzUsxH4p6wzNmzIhly5bF7bffHv37948jjzwybrrppmjSpEn8/ve/L8X8ekuUfcL+++8fgwYNivLy8pgzZ84mnzdv3ryYNGlSDBo0KK688sqNPufAAw+MYcOGxTbb/PO/5p133jlatGgRr7/+etG3Q0Rxb/iKK66IK664otpjjRs3jnXr1kVFRUVRd8NHinnDH5k+fXosWbIkRo4cWey5UE0x7/fPf/5zRER06tSpJFthY4p5w48++mgcffTRsfPOO1c9ttNOO8UTTzwRAwYMKPr2+kyUbcT48eOjTZs2m33rdrfddovZs2fH2LFjo2nTpht9zre//e04/vjjqz329NNPx9///vfYb7/9ir4bPlKsG27Xrl106NAhIiJWrFgRjzzySNx2221x7LHHRqtWrUq2H4p1wxERCxYsiBtvvDEuu+yyaNasWakmQ5Vi3e9LL70ULVu2jMsuuyx69uwZBxxwQHzrW9+KV155pZTzoSg3vHbt2nj55ZejQ4cOcd1118Xhhx8eXbp0iaFDh8a8efNK/RLqHVG2Ea1atYrJkyfH/PnzN/nWbVlZWey6666f6p+7dOnSmDhxYuy6664xaNCgIiyFjSv2DS9evDh69OgR3/3ud6Nly5bxne98p5hzYQPFuuGKioq48MIL44QTTohDDjmkFFNhA8W635deeilWrFgRrVu3jilTpsQll1wSr732WpxyyimxePHiUkyHiCjODS9fvjwqKipixowZ8cwzz8Qll1wS1157bbz33nvxzW9+0w1/gijbhD59+sTAgQOjvLw8XnzxxVr/8xYvXhzDhg2Ld999N2644Qa/F5ySK+YNN2vWLGbMmBE33nhjlJWVxde//vX4y1/+UqSlsHHFuOGbb745li9fHqNHjy7yOti8YtzveeedFz/96U/jwgsvjB49esTXvva1mD59eqxYsSJ+/OMfF3kxVFfbG167dm3V/11eXh69e/eOo446KqZNmxarVq2KmTNnFnNuvSfKNmPChAnRunXrGDNmTK1+BPi8efNiyJAhsXjx4igvL48DDzywiCth04p1w61atYpevXpFv3794rbbbovKysqYMWNG8YbCJtTmhufOnRs333xzXHzxxdGkSZOoqKiI9evXR8SHf0B93bp1pZgMVWr7NXj//feP7t27V3tszz33jL333rvqz5tBKdXmhj96A6Jnz57V3ozYfffdY++9946XXnqpqFvrO1G2Gdtvv31MmjQp5s+fH1OnTi3on/HUU0/FSSedFJWVlTFz5szo1q1bkVfCptXmhisqKuLhhx/e4O8S2X777aNdu3axaNGiYk6FjarNDf/qV7+KtWvXxvDhw6NLly7RpUuXGD9+fERE9OvXL4YPH16CxfBPtbnftWvXxr333rvRv4/sgw8+iNatWxdpJWxabW64ZcuWscMOO2w05ioqKjb7Z4G3Ro2yB3zW9e3bNwYMGBDTpk2Lxo0bf6pfO3fu3DjrrLNijz32iOnTp8cuu+xSopWwaYXecKNGjeKqq66K9u3bx2233Vb1+FtvvRUvv/xyDB06tBRzYQOF3vCJJ54YvXv3rvbYY489FjfeeGNMnTo19tprr+IOhY0o9H4bN24cN9xwQ+y+++5xxx13VD3+4osvxuuvvx5nnHFGKebCBmrzvfARRxwRs2fPjqVLl0abNm0iIuKVV16Jv/71r3HCCSeUYm695Z2yGpg4cWKUlZXF6tWrP9WvGz9+fFRUVMSoUaNi0aJF8fzzz1d9+JH41KVCb3jUqFHx5JNPxoQJE+J3v/td3H///TFs2LAoKyuL0047rURrYUOF3PAuu+wSBxxwQLWPtm3bRkTEfvvtV/WTRaHUCv0afPbZZ8ezzz4bY8aMiSeffDLuuuuu+Ld/+7fo2LFjHHfccSVaCxuqzQ03aNAgTj/99PjlL38Z//3f/x1nnnlm7Lrrrhv8hPKtnSirgbKyspg0adKn+jVvvPFGzJ07N9auXRvf+973YsiQIdU+brrpptKMhY0o5IYjIr7+9a/HddddF3Pnzo1vf/vbccUVV8RBBx0Ud911V+ywww7FHwqbUOgNw2dBofd7/PHHxzXXXBPz58+Ps88+O6699tro06dPzJgxIxo18pudqDuF3vCee+4Zd955Z+yyyy5x/vnnx8SJE6NTp07x05/+NFq0aFH8ofVYg8rKysrsEQAAAFsr75QBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQKIa/82DZS32KeWOkurcas/sCbWyQ8PtsicU7IE3HsqeUKX/nl/JnlCwF1e9mT2hVka2PDB7QsEmvnZH9oQq3/zC4OwJBdsrmmZPqJXxj56VPaFg23b8YvaEKufs9Y3sCQX7W+UH2RNq5dbj6+9fS9vyhz/PnhAR9ft+LzpoUfaEWpn4p12yJxRsyqt31eh53ikDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEjWq6RN/3bpzKXeU1PXbNM6eUCvjmq3KnvC58K21rbMnFKxr23XZE2rlN0sbZE/4XJjYvP5+LTh3xT+yJ9TKut/+PHtC4Tp+MXtBla+srsyeULDHmjbLnlArt9/VMHtCwUb9MHvBhwasXp89oWCdfr04e0KtHN96l+wJJeedMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEjUqKZP/Pk2LUq5o6SOXtMge0Kt/CiaZE8o2OXZAz7m4ng1e0LBvru0Q/aEWnm7YWX2hM+Fe1bumD2hYLMm7ZY9oVYeGf9W9oSCHXd69oJ/mtl0bfaEgv1u1V+zJ9TKbtu2zp5QsFHZA/7XC03q7/djX9q2Y/aEWvnTmrezJ5Scd8oAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARA0qKysrs0cAAABsrbxTBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlH3PqqadG586d44UXXtjo5/v06RNjxozZ4PFFixZFjx494plnnqn2eMeOHTf5ceqpp5bkNbB1K/YNR0Q8++yzcfLJJ0e3bt2id+/ecckll8TKlSuLvh0iSnPDv/nNb+L444+PAw44IL74xS+6YUrm09xvZWVlzJo1K4499tg46KCD4stf/nJceumlG9zmK6+8EiNHjozu3btHz549Y9y4cbF8+fKSvxa2TqW44Y+sXbs2TjjhhLjhhhtKtr8+E2WfsG7duhg7dmysWbOmRs9fuHBhjBgxIlasWLHB52bNmrXBx+mnnx4REd/4xjeKuhs+Uswbnj9/fowYMSKaNGkS1113XZx99tnxX//1X3HeeecVezZUKeYNz549O84666zYbrvt4rrrrosJEybEs88+G8OGDYuKiopiT4ca3295eXlMnjw5evfuHVOmTIkzzjgjHnjggRg1alRUVlZGRMTy5ctj+PDhsXTp0rjyyitj9OjRMXv27DjnnHPq4JWwtSrmDX/kgw8+iHPPPTf+3//7f6WcXq81yh7wWdOyZctYsGBBTJkyJf793/99k89bv3593HfffXHllVdu8jldu3at9p/feuutuOuuu+KUU06JY445pliToZpi3vCDDz4YDRo0iClTpkTz5s0jIqKioiImTZoUCxcujLZt2xZ9PxTzhm+44YbYZ599ory8PJo0aRIRET169Ii+ffvGvffeGyeeeGLR97N1q8n9rl+/PqZNmxZDhgyJ0aNHR0TEoYceGmVlZXHOOefEnDlz4oADDoif/exnsXz58rj//vujTZs2ERGxyy67xMiRI+PZZ5+NHj161NnrYutRzBuO+PB33EyePDnefvvtOnsN9ZF3yj5h//33j0GDBkV5eXnMmTNnk8+bN29eTJo0KQYNGrTZbwg+7oorroimTZvGueeeW6y5sIFi3vCaNWuiUaNG0axZs6rHWrduHRER7733XlF3w0eKecOvvPJKHH744VVBFhGxww47RIcOHeI3v/lN0bdDTe535cqVMXDgwBgwYEC1x9u3bx8REW+88UZERPz2t7+N7t27VwVZRMQXv/jFaN68efzP//xPiV4BW7ti3nBExFlnnRVt27aNe++9t3SjPwdE2UaMHz8+2rRps9m3bnfbbbeYPXt2jB07Npo2bbrFf+Zzzz0XjzzySJx77rnRokWLYk+Gaop1w8cff3w0aNAgLr/88li2bFnVvznbb7/9olOnTqV8CWzlinXDrVu3joULF1Z7bO3atbFo0aJ48803i74bIrZ8v61atYqJEydG9+7dqz3+6KOPRkTEvvvuGxERL7/8ctU3uR/ZZpttYo899ohXX321NOMhinfDEREzZ86Mm2++2e+u2QJRthGtWrWKyZMnx/z582PKlCkbfU5ZWVnsuuuuNf5nTp8+Pdq2bRsDBw4s1kzYpGLd8D777BOjR4+OmTNnxv/5P/8nBgwYEKtWrYpp06ZFw4YNSzEdIqJ4Nzx48OB49NFHY9q0abF06dJ46623Yvz48bFy5cpYvXp1KaZDje73k5577rm49dZbo2/fvlXf0C5fvrzqt45/XPPmzf2wGkqqWDcc8eEPvmPLRNkm9OnTJwYOHBjl5eXx4osv1uqftWjRovj1r38dw4YNi0aN/DE+6kYxbviWW26JyZMnx0knnRQzZsyIa6+9NrbbbrsYPnx4LFmypMiLobpi3PB3vvOd+Na3vhXXX3999OrVK4466qho3rx59O3bt9pvy4Vi+zT3++yzz8bIkSOjXbt2cemll1b7XIMGDTZ4fmVl5UYfh2Iq1g1TM6JsMyZMmBCtW7eOMWPG1PingG3Mo48+Gg0aNPDDPahztbnhioqKmDp1ahx77LFx0UUXRa9eveKrX/1qzJgxI95+++2YPn16iVbDP9X263CjRo3ivPPOiz/+8Y/x0EMPxe9+97v4/ve/H2+//XaUlZUVfzB8TE3u96GHHooRI0bE7rvvHjNmzKh2ly1atNjoO2Lvv/9+tGzZslSzoUptb5iaE2Wbsf3228ekSZNi/vz5MXXq1IL/OY899lj06NEjdtxxxyKugy2rzQ0vXbo0Vq9eHd26dav2+I477hjt27ePBQsWFHMqbFRtvw7//ve/jyeeeCK23Xbb2GeffaJVq1ZRUVER8+bNi86dO5dgMfzTlu63vLw8Ro8eHV27do077rgjdtppp2qfb9++fbz++uvVHlu/fn28+eabsc8++5R0O0TU/oapOVG2BX379o0BAwZU/XmET6uysjJeeOGFDb6xhbpS6A3vsMMOUVZWFn/84x+rPb506dJ49dVXY4899ij2VNio2nwd/sUvfhETJ06MtWvXVj12zz33xPLly6Nfv37Fngob2NT93nnnnXHVVVdF//79Y/r06Rt95+uwww6LP/zhD9V+3RNPPBGrVq2Kww47rE72Q21umJoTZTUwceLEKCsrK+gPhb/11luxYsUK/0aLVIXccMOGDeM73/lOPPjgg3HRRRfFU089FQ8//HCMGDEiGjZsGKeddloJF0N1hX4d/sY3vhFLliyJMWPGxFNPPRUzZsyIiy++OI455hh/xxN15pP3+84778Tll18ebdu2jaFDh8bcuXPj+eefr/r46Bvfk08+ObbddtsYMWJEzJ49O+6+++44//zz44gjjoiDDjoo8yWxlSn0hqk5P3WiBsrKymLSpEkxatSoT/1r33333Yj48KfYQJZCb3jo0KHRsmXL+NGPfhT33ntvtG7dOnr06BFTpkzxThl1qtAb3m+//eKWW26JH/7wh3HmmWfGjjvuGGeeeWb827/9W4mWwoY+eb+PP/54fPDBB7Fw4cI45ZRTNnj+5ZdfHoMHD442bdrEj3/847jsssvivPPOi+bNm0f//v3jggsuqOuXwFau0Bum5hpUVlZWZo8AAADYWvntiwAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQqMZ/efTPdtvwL4arLw7b/W/ZE2rl7nd2y55QsNGvz8yeUOWu3U7OnlCwf2n+XvaEWpm3six7QsGO+9tPsydUmdexf/aEgj2xcsfsCbUysNMb2RMKtvOvHs+eUKU+fx3uf8yS7Am1csXs+vv/g5e99tn4Onxb26HZEwo2ZFTD7Am18s2py7InFOye1/+rRs/zThkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQqFFNnzhuzYul3FFSpyzpnD2hVi5f9OvsCQUbnT3gY6Y2fCd7QsHar22VPaFWHq94KXtCwY7LHvAxl36wXfaEgu3SaF32hFoZtaAse0LB7soe8DETK+ZnTyjY3Y+2zZ5QK6+tfTN7QsEuyx7wv/7UeG32hII1u74ye0KtvNng79kTSs47ZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJCoUU2fOHnbLqXcUVIXrZyTPaFWeuy0b/aEz4XjGuySPaFg/7Xu7ewJtfKl5h2yJ3wutGnQJHtCwZ5c87fsCbXSvnFZ9oTPhcbbNMyeULCb9l+WPaFWjvjT6uwJ9V6Lyvr7XsbaBtkLauevqxZnTyi5+ntdAAAAnwOiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACBRg8rKysrsEQAAAFsr75QBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRNnHnHrqqdG5c+d44YUXNvr5Pn36xJgxYyIiorKyMmbNmhXHHntsHHTQQfHlL385Lr300li5cmW1X/PMM8/E0KFD4+CDD47DDjssRo0aFa+99lrJXwtbp1Lc8C9/+csYPHhwdO3aNY488si4/vrrY82aNSV/LWydSnHDH3f77bdHx44d48033yzJfrZupbjfE088MTp27LjBx/PPP1/ql8NWqBQ3vHjx4hg9enT07NkzunXrFsOHD4+5c+eW/LXUN6LsE9atWxdjx47d4jed5eXlMXny5Ojdu3dMmTIlzjjjjHjggQdi1KhRUVlZGRERf/rTn+K0006L1q1bx9VXXx0TJ06MN954I04++eRYunRpXbwctkLFvOHHH388Ro0aFZ06dYqbbropTj/99PjRj34UF198cV28FLZSxbzhj3v11VfjmmuuKdVsiIji3u/69etj/vz5cfrpp8esWbOqfey777518XLYChXzhleuXBmnnHJKzJ07NyZPnhw//OEPY9WqVTFixIh4++236+Ll1BuNsgd81rRs2TIWLFgQU6ZMiX//93/f6HPWr18f06ZNiyFDhsTo0aMjIuLQQw+NsrKyOOecc2LOnDlxwAEHxC233BIdOnSI//iP/4httvmwf7t16xa9e/eO++67L04//fQ6e11sPYp9wwceeGBcdtllVc9ZtmxZ3HzzzTF27NjYbrvt6ux1sfUo5g1/ZN26dTFmzJgoKyuLv/3tb3XyOtg6FfN+//rXv8bq1aujd+/e0bVr1zp8FWzNinnDM2bMiGXLlsV///d/x8477xwREf/yL/8SgwcPjt///vcxYMCAOntdn3XeKfuE/fffPwYNGhTl5eUxZ86cjT5n5cqVMXDgwA0OqX379hER8cYbb0RExIEHHhjDhg2rCrKIiJ133jlatGgRr7/+eoleAVu7Yt7wFVdcEVdccUW15zRu3DjWrVsXFRUVJVgPxb3hj0yfPj2WLFkSI0eOLM1o+F/FvN8///nPERHRqVOnEi6G6op5w48++mgcffTRVUEWEbHTTjvFE088Icg+QZRtxPjx46NNmzabfOu2VatWMXHixOjevXu1xx999NGIiKrfUvDtb387jj/++GrPefrpp+Pvf/977LfffiVaD8W74Xbt2kWHDh0iImLFihXxyCOPxG233RbHHntstGrVqsSvgq1ZsW44ImLBggVx4403xmWXXRbNmjUr7XCI4t3vSy+9FC1btozLLrssevbsGQcccEB861vfildeeaX0L4KtWjFueO3atfHyyy9Hhw4d4rrrrovDDz88unTpEkOHDo158+bVyeuoT0TZRrRq1SomT54c8+fPjylTptTo1zz33HNx6623Rt++fTf5+7yXLl0aEydOjF133TUGDRpUxMVQXbFvePHixdGjR4/47ne/Gy1btozvfOc7pZgNVYp1wxUVFXHhhRfGCSecEIccckgpJ0OVYt3vSy+9FCtWrIjWrVvHlClT4pJLLonXXnstTjnllFi8eHEpXwJbuWLc8PLly6OioiJmzJgRzzzzTFxyySVx7bXXxnvvvRff/OY33fAniLJN6NOnTwwcODDKy8vjxRdf3Oxzn3322Rg5cmS0a9cuLr300o0+Z/HixTFs2LB4991344YbbojmzZuXYjZUKeYNN2vWLGbMmBE33nhjlJWVxde//vX4y1/+UqrpEBHFueGbb745li9fXvVnHqCuFON+zzvvvPjpT38aF154YfTo0SO+9rWvxfTp02PFihXx4x//uNQvga1cbW947dq1VZ8vLy+P3r17x1FHHRXTpk2LVatWxcyZM0u6v74RZZsxYcKEaN26dYwZM2aTP4HmoYceihEjRsTuu+8eM2bMiLKysg2eM2/evBgyZEgsXrw4ysvL48ADDyzxcvhQsW64VatW0atXr+jXr1/cdtttUVlZGTNmzCjteIja3fDcuXPj5ptvjosvvjiaNGkSFRUVsX79+oj48A+pr1u3rq5eBlup2n4N3n///Tf47WF77rln7L333lV/3gxKqTY3/NEbED179qz2ZsTuu+8ee++9d7z00ksl31+fiLLN2H777WPSpEkxf/78mDp16gafLy8vj9GjR0fXrl3jjjvuiJ122mmD5zz11FNx0kknRWVlZcycOTO6detWF9MhImp3wxUVFfHwww9v8HeJbL/99tGuXbtYtGhRyfdDbW74V7/6VaxduzaGDx8eXbp0iS5dusT48eMjIqJfv34xfPjwunoZbKVqc79r166Ne++9d6N/H9kHH3wQrVu3LuV0iIja3XDLli1jhx122GjMVVRURNOmTUu6vb7xI/G3oG/fvjFgwICYNm1aNG7cuOrxO++8M6666qr4yle+EldeeWU0adJkg187d+7cOOuss2KPPfaI6dOnxy677FKX0yEiCr/hRo0axVVXXRXt27eP2267rerxt956K15++eUYOnRonb0Gtm6F3vCJJ54YvXv3rvbYY489FjfeeGNMnTo19tprrzpYz9au0Ptt3Lhx3HDDDbH77rvHHXfcUfX4iy++GK+//nqcccYZdfYa2LrV5nvhI444ImbPnh1Lly6NNm3aRETEK6+8En/961/jhBNOqLPXUB+IshqYOHFiPP3007FkyZKIiHjnnXfi8ssvj7Zt28bQoUM3eCehXbt20aZNmxg/fnxUVFTEqFGjYtGiRdXeWWjTpk20a9euTl8HW69Cb3jUqFExbty4mDBhQnz1q1+Nt99+O6ZMmRJlZWVx2mmnZbwUtlKF3PAuu+yywb8MW7BgQURE7LfffrHHHnvUzXi2eoV+DT777LNj/PjxMWbMmDj22GNj4cKFcf3110fHjh3juOOOy3gpbKVqc8O//OUv4/TTT4+zzz471q5dG9dee23suuuuG/yE8q2dKKuBsrKymDRpUowaNSoiIh5//PH44IMPYuHChXHKKads8PzLL788Dj744KoD/d73vrfBc4477rgN/v4nKJVCbnjw4MHx9a9/Pbbbbru49dZb48EHH4ymTZvGEUccEaNHj44ddtihrl8GW7FCbxg+Cwq93+OPPz6aNWsW06dPj7PPPjuaNWsW/fr1i3PPPTcaNfItHHWn0Bvec889484774yrr746zj///GjYsGEceuihMW7cuGjRokVdv4zPtAaVlZWV2SMAAAC2Vn7QBwAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkqvHfPLjPjt1KuaOkrmjUKXtCrXzlOw2zJxSs+fifZE+oMnuXIdkTCrZsm/p7AxERPXddnD2hYF/406+yJ1R5+YCjsicU7A9LdsqeUCvHnPBe9oSCtbz+oewJVa7dc2j2hIIt36Z+/7Wug2J59oSC/etrD2RPiIiIv33pS9kTCvaLv+yZPaFW9lv3fvaEgh36t3tr9DzvlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAiUQZAABAIlEGAACQSJQBAAAkEmUAAACJGtX0iY/vs30pd5TUr19vkD2hVv7vDauyJxTs0PHZC/6paYN12RMKtnfDD7In1MofFu2SPaFgX8ge8DE3rGiTPaFgXbep31+Hn57VIntCwfpdn73gn55qsCJ7QsGOX9M8e0Kt7Lx3/f3v/rPiq/MqsicUbFysz55QK7vvujx7Qsl5pwwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASNarpE6ct2q2UO0rq1tXPZ0+olcrKyuwJBVuUPeBjrmuyJntCwQ5q0DJ7Qq10X7sue8LnQqvK+vvv0e7aZmn2hFo5rlGb7AmfC6f/o2n2hII91rT+/m9xRET/Tk2yJ9R7ZzVsnz2hYF97fnL2hFqZ/S/jsycUbK8aPq/+/i88AADA54AoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEgkygAAABKJMgAAgESiDAAAIJEoAwAASCTKAAAAEokyAACARKIMAAAgkSgDAABIJMoAAAASiTIAAIBEogwAACCRKAMAAEjUoLKysjJ7BAAAwNbKO2UAAACJRBkAAEAiUQYAAJBIlAEAACQSZQAAAIlEGQAAQCJRBgAAkEiUAQAAJBJlAAAAif4/0bkIECeN5H0AAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_heads = [ca.rule.readouts[i].weight.data.abs().sum(dim=0) for i in range(len(Ns))]\n",
    "# n_heads = [ca.rule.readouts[i].weight.data[1] for i in range(len(Ns))]\n",
    "n_heads = [mat.reshape(READOUT_CHANNELS, ca.rule.readout_res, ca.rule.readout_res).cpu().mean(dim=0) for mat in n_heads]\n",
    "n_heads = torch.stack(n_heads).numpy()\n",
    "\n",
    "fig, axes = plt.subplots(int(np.sqrt(len(n_heads))), int(np.sqrt(len(n_heads))), figsize=(9, 9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "vmin = n_heads.min()\n",
    "vmax = n_heads.max()\n",
    "for i, ax in enumerate(axes):\n",
    "    n_head = n_heads[i]\n",
    "    im = ax.imshow(n_head, vmin=vmin, vmax=vmax)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'N{i + 2}')\n",
    "    # if i == 0:\n",
    "    #     plt.colorbar(im, ax=ax, fraction=0.04)\n",
    "        \n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T20:24:56.353130500Z",
     "start_time": "2024-03-04T20:24:54.524130Z"
    }
   },
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(-0.5, 2.5, 2.5, -0.5)"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.mean(n_heads, axis=0)); plt.axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T20:24:56.417130900Z",
     "start_time": "2024-03-04T20:24:56.349130400Z"
    }
   },
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x1d433ef07c0>]"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ca.rule.alpha.detach().cpu().numpy(), 'o-')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T20:24:56.548133600Z",
     "start_time": "2024-03-04T20:24:56.417130900Z"
    }
   },
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [103], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m filters \u001B[38;5;241m=\u001B[39m [ca\u001B[38;5;241m.\u001B[39mrule\u001B[38;5;241m.\u001B[39mfilters[i]\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(ca\u001B[38;5;241m.\u001B[39mrule\u001B[38;5;241m.\u001B[39mfilters))]\n\u001B[0;32m      2\u001B[0m filters \u001B[38;5;241m=\u001B[39m [mat\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m3\u001B[39m)\u001B[38;5;241m.\u001B[39mcpu() \u001B[38;5;28;01mfor\u001B[39;00m mat \u001B[38;5;129;01min\u001B[39;00m filters]\n\u001B[1;32m----> 3\u001B[0m filters \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# fig, axes = plt.subplots(int(np.sqrt(len(filters))), int(np.sqrt(len(filters))), figsize=(7, 7))\u001B[39;00m\n\u001B[0;32m      6\u001B[0m fig, axes \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39msubplots(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m7\u001B[39m, \u001B[38;5;241m7\u001B[39m))\n",
      "\u001B[1;31mRuntimeError\u001B[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "filters = [ca.rule.filters[i].data for i in range(len(ca.rule.filters))]\n",
    "filters = [mat.reshape(3, 3).cpu() for mat in filters]\n",
    "filters = torch.stack(filters).numpy()\n",
    "\n",
    "# fig, axes = plt.subplots(int(np.sqrt(len(filters))), int(np.sqrt(len(filters))), figsize=(7, 7))\n",
    "fig, axes = plt.subplots(1, 2, figsize=(7, 7))\n",
    "axes = axes.flatten()\n",
    "\n",
    "vmin = filters.min()\n",
    "vmax = filters.max()\n",
    "for i, ax in enumerate(axes):\n",
    "    filter = filters[i]\n",
    "    im = ax.imshow(filter, vmin=vmin, vmax=vmax)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'N{i + 2}')\n",
    "    plt.colorbar(im, ax=ax, fraction=0.04)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T20:24:56.586134500Z",
     "start_time": "2024-03-04T20:24:56.549131400Z"
    }
   },
   "execution_count": 103
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(state.reshape(-1).cpu().numpy(), 25); # plt.yscale('log')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T20:24:58.456134700Z",
     "start_time": "2024-03-04T20:24:58.316132200Z"
    }
   },
   "execution_count": 104
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:24:06.494932600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:24:06.495932700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
